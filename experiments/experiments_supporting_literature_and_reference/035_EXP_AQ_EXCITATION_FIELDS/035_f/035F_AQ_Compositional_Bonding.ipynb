{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 035F: AQ Compositional Bonding\n",
        "\n",
        "**AKIRA Project - Oscar Goldman - Shogu Research Group @ Datamutant.ai**\n",
        "\n",
        "---\n",
        "\n",
        "## Core Hypothesis\n",
        "\n",
        "Action Quanta (AQ) are irreducible action discrimination primitives. When multiple AQ combine\n",
        "in context, they form **bonded states** - composite patterns that encode multiple action\n",
        "discriminations simultaneously.\n",
        "\n",
        "**Key Prediction**: If AQ are compositional primitives:\n",
        "1. Prompts with N AQ components should activate patterns that **decompose** into N component signatures\n",
        "2. The bonded pattern should show higher similarity to its components than to unrelated AQ\n",
        "3. Component AQ patterns should be **detectable** within the bonded representation\n",
        "\n",
        "---\n",
        "\n",
        "## What Are True AQ?\n",
        "\n",
        "AQ are the minimum patterns enabling discrimination between action alternatives:\n",
        "\n",
        "| AQ | Discrimination | Action Enabled |\n",
        "|:---|:---------------|:---------------|\n",
        "| THREAT_PRESENT | threat vs no-threat | FLEE vs STAY |\n",
        "| PROXIMITY | near vs far | ENGAGE vs OBSERVE |\n",
        "| DIRECTION | toward vs away | INTERCEPT vs EVADE |\n",
        "| URGENCY | immediate vs delayed | ACT_NOW vs PLAN |\n",
        "| AGENT_INTENT | hostile vs friendly | DEFEND vs COOPERATE |\n",
        "| RESOURCE_STATE | scarce vs abundant | CONSERVE vs EXPEND |\n",
        "\n",
        "These are NOT output categories like \"compute number\" or \"answer boolean\".\n",
        "They are **action primitives** - the minimum information needed to choose an action.\n",
        "\n",
        "---\n",
        "\n",
        "## Experimental Design\n",
        "\n",
        "1. **Single AQ prompts**: Activate only one discrimination (e.g., just THREAT_PRESENT)\n",
        "2. **Bonded AQ prompts**: Activate multiple discriminations (e.g., THREAT + PROXIMITY + DIRECTION)\n",
        "3. **Analysis**: Test if bonded patterns decompose into detectable component signatures\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers torch numpy scikit-learn matplotlib seaborn scipy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass, field\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if DEVICE == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. AQ Component Definitions\n",
        "\n",
        "Each AQ is defined by:\n",
        "- The discrimination it enables\n",
        "- Marker words/phrases that activate it\n",
        "- The action choice it enables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core AQ Components - each is an irreducible action discrimination\n",
        "AQ_COMPONENTS = {\n",
        "    \"THREAT\": {\n",
        "        \"discrimination\": \"threat vs no-threat\",\n",
        "        \"action_enabled\": \"FLEE vs STAY\",\n",
        "        \"markers\": [\"danger\", \"threat\", \"attack\", \"predator\", \"enemy\", \"fire\", \"flood\", \n",
        "                    \"collapse\", \"explosion\", \"gunfire\", \"intruder\", \"poison\", \"tsunami\"],\n",
        "        \"neutral\": [\"object\", \"item\", \"thing\", \"element\", \"entity\", \"matter\"]\n",
        "    },\n",
        "    \"PROXIMITY\": {\n",
        "        \"discrimination\": \"near vs far\",\n",
        "        \"action_enabled\": \"ENGAGE vs OBSERVE\",\n",
        "        \"markers\": [\"approaching\", \"nearby\", \"close\", \"immediate\", \"at the door\", \n",
        "                    \"right behind\", \"within reach\", \"meters away\", \"closing in\"],\n",
        "        \"neutral\": [\"somewhere\", \"located\", \"positioned\", \"exists\", \"present\"]\n",
        "    },\n",
        "    \"DIRECTION\": {\n",
        "        \"discrimination\": \"toward vs away\",\n",
        "        \"action_enabled\": \"INTERCEPT vs EVADE\",\n",
        "        \"markers\": [\"coming toward\", \"heading your way\", \"approaching you\", \"moving closer\",\n",
        "                    \"advancing\", \"bearing down\", \"en route to your position\"],\n",
        "        \"neutral\": [\"moving\", \"traveling\", \"going\", \"proceeding\", \"in motion\"]\n",
        "    },\n",
        "    \"URGENCY\": {\n",
        "        \"discrimination\": \"immediate vs delayed\",\n",
        "        \"action_enabled\": \"ACT_NOW vs PLAN\",\n",
        "        \"markers\": [\"now\", \"immediately\", \"right now\", \"this instant\", \"without delay\",\n",
        "                    \"urgent\", \"emergency\", \"critical\", \"time-sensitive\"],\n",
        "        \"neutral\": [\"eventually\", \"sometime\", \"when possible\", \"at some point\"]\n",
        "    },\n",
        "    \"AGENT_INTENT\": {\n",
        "        \"discrimination\": \"hostile vs friendly\",\n",
        "        \"action_enabled\": \"DEFEND vs COOPERATE\",\n",
        "        \"markers\": [\"aggressive\", \"hostile\", \"attacking\", \"malicious\", \"threatening\",\n",
        "                    \"violent\", \"armed\", \"hunting\", \"stalking\"],\n",
        "        \"neutral\": [\"present\", \"there\", \"existing\", \"around\", \"nearby\"]\n",
        "    },\n",
        "    \"RESOURCE\": {\n",
        "        \"discrimination\": \"scarce vs abundant\",\n",
        "        \"action_enabled\": \"CONSERVE vs EXPEND\",\n",
        "        \"markers\": [\"running low\", \"almost out\", \"last remaining\", \"dwindling\",\n",
        "                    \"limited supply\", \"rationing\", \"scarce\", \"depleted\"],\n",
        "        \"neutral\": [\"available\", \"present\", \"existing\", \"there\", \"some\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Defined {len(AQ_COMPONENTS)} AQ components:\")\n",
        "for aq, info in AQ_COMPONENTS.items():\n",
        "    print(f\"  {aq}: {info['discrimination']} -> {info['action_enabled']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prompt Generation\n",
        "\n",
        "Generate three types of prompts:\n",
        "1. **Single AQ**: Activates exactly one discrimination\n",
        "2. **Double AQ**: Activates exactly two discriminations (bonded)\n",
        "3. **Triple AQ**: Activates exactly three discriminations (bonded)\n",
        "\n",
        "Control: Each bonded prompt explicitly combines markers from its component AQ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_single_aq_prompts(aq_name: str, n: int = 100) -> List[str]:\n",
        "    \"\"\"Generate prompts that activate exactly one AQ.\n",
        "    \n",
        "    Args:\n",
        "        aq_name: Name of the AQ component\n",
        "        n: Number of prompts to generate\n",
        "        \n",
        "    Returns:\n",
        "        List of prompts activating only this AQ\n",
        "    \"\"\"\n",
        "    assert aq_name in AQ_COMPONENTS, f\"Unknown AQ: {aq_name}\"\n",
        "    \n",
        "    aq = AQ_COMPONENTS[aq_name]\n",
        "    markers = aq[\"markers\"]\n",
        "    \n",
        "    # Templates designed to activate ONLY this AQ\n",
        "    templates = {\n",
        "        \"THREAT\": [\n",
        "            \"There is {m} detected. What should you do?\",\n",
        "            \"A {m} has been identified. Your response:\",\n",
        "            \"Warning: {m} present. Action required:\",\n",
        "            \"Alert: {m} in the area. You should\",\n",
        "            \"Notice: {m} reported. The appropriate action is\",\n",
        "        ],\n",
        "        \"PROXIMITY\": [\n",
        "            \"Something is {m}. Your response:\",\n",
        "            \"The object is {m}. What do you do?\",\n",
        "            \"Location update: {m}. Action:\",\n",
        "            \"Status: target is {m}. You should\",\n",
        "            \"Report: item detected {m}. Response:\",\n",
        "        ],\n",
        "        \"DIRECTION\": [\n",
        "            \"Movement detected: {m}. Your action:\",\n",
        "            \"The object is {m}. Response:\",\n",
        "            \"Tracking shows {m}. You should\",\n",
        "            \"Vector analysis: {m}. Action needed:\",\n",
        "            \"Motion: {m}. What do you do?\",\n",
        "        ],\n",
        "        \"URGENCY\": [\n",
        "            \"This requires action {m}. You should\",\n",
        "            \"Response needed {m}. Action:\",\n",
        "            \"Timeline: {m}. Your response:\",\n",
        "            \"Priority: act {m}. You must\",\n",
        "            \"Timing: {m}. What do you do?\",\n",
        "        ],\n",
        "        \"AGENT_INTENT\": [\n",
        "            \"The entity appears {m}. Your response:\",\n",
        "            \"Behavior analysis: {m}. Action:\",\n",
        "            \"Intent detected: {m}. You should\",\n",
        "            \"The agent is {m}. What do you do?\",\n",
        "            \"Assessment: entity is {m}. Response:\",\n",
        "        ],\n",
        "        \"RESOURCE\": [\n",
        "            \"Supplies are {m}. Your action:\",\n",
        "            \"Resource status: {m}. Response:\",\n",
        "            \"Inventory shows {m}. You should\",\n",
        "            \"Current stock is {m}. Action needed:\",\n",
        "            \"Materials are {m}. What do you do?\",\n",
        "        ],\n",
        "    }\n",
        "    \n",
        "    prompts = []\n",
        "    np.random.seed(hash(aq_name) % 2**32)\n",
        "    \n",
        "    for i in range(n):\n",
        "        template = templates[aq_name][i % len(templates[aq_name])]\n",
        "        marker = markers[i % len(markers)]\n",
        "        prompts.append(template.format(m=marker))\n",
        "    \n",
        "    return prompts\n",
        "\n",
        "\n",
        "def generate_bonded_prompts(aq_names: List[str], n: int = 100) -> List[str]:\n",
        "    \"\"\"Generate prompts that activate multiple AQ simultaneously (bonded state).\n",
        "    \n",
        "    Args:\n",
        "        aq_names: List of AQ components to combine\n",
        "        n: Number of prompts to generate\n",
        "        \n",
        "    Returns:\n",
        "        List of bonded prompts\n",
        "    \"\"\"\n",
        "    for name in aq_names:\n",
        "        assert name in AQ_COMPONENTS, f\"Unknown AQ: {name}\"\n",
        "    \n",
        "    # Bonded templates that combine multiple AQ\n",
        "    if set(aq_names) == {\"THREAT\", \"PROXIMITY\"}:\n",
        "        templates = [\n",
        "            \"A {t} is {p}. What should you do?\",\n",
        "            \"Warning: {t} detected {p}. Your response:\",\n",
        "            \"Alert: {t} {p}. Action required:\",\n",
        "            \"{t} confirmed {p}. You should\",\n",
        "            \"Danger: {t} is {p}. Response:\",\n",
        "        ]\n",
        "    elif set(aq_names) == {\"THREAT\", \"DIRECTION\"}:\n",
        "        templates = [\n",
        "            \"A {t} is {d}. What should you do?\",\n",
        "            \"Warning: {t} {d}. Your response:\",\n",
        "            \"Alert: {t} detected {d}. Action:\",\n",
        "            \"{t} is {d}. You should\",\n",
        "            \"Danger: {t} {d}. Response:\",\n",
        "        ]\n",
        "    elif set(aq_names) == {\"THREAT\", \"URGENCY\"}:\n",
        "        templates = [\n",
        "            \"A {t} requires response {u}. What do you do?\",\n",
        "            \"{t} detected - act {u}. Your response:\",\n",
        "            \"Warning: {t}, respond {u}. Action:\",\n",
        "            \"{t} present, action needed {u}. You should\",\n",
        "            \"Alert: {t}, {u}. Response:\",\n",
        "        ]\n",
        "    elif set(aq_names) == {\"PROXIMITY\", \"DIRECTION\"}:\n",
        "        templates = [\n",
        "            \"Object is {p} and {d}. What should you do?\",\n",
        "            \"Target {p}, {d}. Your response:\",\n",
        "            \"Status: {p} and {d}. Action:\",\n",
        "            \"Tracking: {p}, {d}. You should\",\n",
        "            \"Location: {p}, movement {d}. Response:\",\n",
        "        ]\n",
        "    elif set(aq_names) == {\"THREAT\", \"PROXIMITY\", \"DIRECTION\"}:\n",
        "        templates = [\n",
        "            \"A {t} is {p} and {d}. What should you do?\",\n",
        "            \"Warning: {t} {p}, {d}. Your response:\",\n",
        "            \"Alert: {t} detected {p}, {d}. Action:\",\n",
        "            \"{t} confirmed {p} and {d}. You should\",\n",
        "            \"Danger: {t} {p}, {d}. Response:\",\n",
        "        ]\n",
        "    elif set(aq_names) == {\"THREAT\", \"PROXIMITY\", \"URGENCY\"}:\n",
        "        templates = [\n",
        "            \"A {t} is {p}, respond {u}. What do you do?\",\n",
        "            \"Warning: {t} {p} - act {u}. Response:\",\n",
        "            \"{t} detected {p}, action needed {u}. You should\",\n",
        "            \"Alert: {t} {p}, {u}. Action:\",\n",
        "            \"Danger: {t} {p}, respond {u}. Your response:\",\n",
        "        ]\n",
        "    elif set(aq_names) == {\"THREAT\", \"AGENT_INTENT\", \"PROXIMITY\"}:\n",
        "        templates = [\n",
        "            \"A {a} {t} is {p}. What should you do?\",\n",
        "            \"Warning: {a} {t} detected {p}. Response:\",\n",
        "            \"Alert: {a} {t} {p}. Action:\",\n",
        "            \"{a} {t} confirmed {p}. You should\",\n",
        "            \"Danger: {a} {t} is {p}. Your response:\",\n",
        "        ]\n",
        "    else:\n",
        "        # Generic bonded template\n",
        "        templates = [\n",
        "            \"Situation: \" + \", \".join([f\"{{{n[0].lower()}}}\" for n in aq_names]) + \". What should you do?\",\n",
        "        ]\n",
        "    \n",
        "    prompts = []\n",
        "    np.random.seed(hash(tuple(sorted(aq_names))) % 2**32)\n",
        "    \n",
        "    for i in range(n):\n",
        "        template = templates[i % len(templates)]\n",
        "        \n",
        "        # Get markers for each component\n",
        "        format_dict = {}\n",
        "        for name in aq_names:\n",
        "            key = name[0].lower()  # First letter as key\n",
        "            markers = AQ_COMPONENTS[name][\"markers\"]\n",
        "            format_dict[key] = markers[i % len(markers)]\n",
        "        \n",
        "        try:\n",
        "            prompts.append(template.format(**format_dict))\n",
        "        except KeyError:\n",
        "            # Fallback for complex combinations\n",
        "            parts = [f\"{AQ_COMPONENTS[n]['markers'][i % len(AQ_COMPONENTS[n]['markers'])]}\" for n in aq_names]\n",
        "            prompts.append(f\"Situation: {', '.join(parts)}. What should you do?\")\n",
        "    \n",
        "    return prompts\n",
        "\n",
        "\n",
        "# Test prompt generation\n",
        "print(\"=== Single AQ Examples ===\")\n",
        "for aq in [\"THREAT\", \"PROXIMITY\", \"DIRECTION\"]:\n",
        "    prompts = generate_single_aq_prompts(aq, n=3)\n",
        "    print(f\"\\n{aq}:\")\n",
        "    for p in prompts:\n",
        "        print(f\"  - {p}\")\n",
        "\n",
        "print(\"\\n=== Bonded AQ Examples ===\")\n",
        "bonded = generate_bonded_prompts([\"THREAT\", \"PROXIMITY\"], n=3)\n",
        "print(\"\\nTHREAT + PROXIMITY:\")\n",
        "for p in bonded:\n",
        "    print(f\"  - {p}\")\n",
        "\n",
        "bonded = generate_bonded_prompts([\"THREAT\", \"PROXIMITY\", \"DIRECTION\"], n=3)\n",
        "print(\"\\nTHREAT + PROXIMITY + DIRECTION:\")\n",
        "for p in bonded:\n",
        "    print(f\"  - {p}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Loading and Activation Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Configuration for compositional bonding experiment.\"\"\"\n",
        "    \n",
        "    models: Dict[str, str] = field(default_factory=lambda: {\n",
        "        \"gpt2-medium\": \"gpt2-medium\",\n",
        "        \"pythia-1.4b\": \"EleutherAI/pythia-1.4b\",\n",
        "    })\n",
        "    \n",
        "    # Prompts per condition\n",
        "    prompts_per_condition: int = 100\n",
        "    \n",
        "    # Statistical parameters\n",
        "    n_bootstrap: int = 1000\n",
        "    random_seed: int = 42\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        np.random.seed(self.random_seed)\n",
        "        torch.manual_seed(self.random_seed)\n",
        "\n",
        "\n",
        "config = ExperimentConfig()\n",
        "print(f\"Models: {list(config.models.keys())}\")\n",
        "print(f\"Prompts per condition: {config.prompts_per_condition}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(model_name: str) -> Tuple[AutoModelForCausalLM, AutoTokenizer, int]:\n",
        "    \"\"\"Load model and tokenizer.\n",
        "    \n",
        "    Args:\n",
        "        model_name: HuggingFace model identifier\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (model, tokenizer, num_layers)\n",
        "    \"\"\"\n",
        "    print(f\"Loading {model_name}...\")\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    \n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
        "        device_map=\"auto\" if DEVICE == \"cuda\" else None,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "    model.eval()\n",
        "    \n",
        "    # Get number of layers\n",
        "    if hasattr(model.config, 'n_layer'):\n",
        "        n_layers = model.config.n_layer\n",
        "    elif hasattr(model.config, 'num_hidden_layers'):\n",
        "        n_layers = model.config.num_hidden_layers\n",
        "    else:\n",
        "        n_layers = 24  # Default\n",
        "    \n",
        "    print(f\"  Layers: {n_layers}\")\n",
        "    print(f\"  Hidden size: {model.config.hidden_size}\")\n",
        "    \n",
        "    return model, tokenizer, n_layers\n",
        "\n",
        "\n",
        "def extract_activations(model: AutoModelForCausalLM, \n",
        "                        tokenizer: AutoTokenizer,\n",
        "                        prompts: List[str],\n",
        "                        layers: List[int]) -> Dict[int, np.ndarray]:\n",
        "    \"\"\"Extract activations from specified layers.\n",
        "    \n",
        "    Args:\n",
        "        model: The language model\n",
        "        tokenizer: The tokenizer\n",
        "        prompts: List of prompts\n",
        "        layers: Which layers to extract from\n",
        "        \n",
        "    Returns:\n",
        "        Dict mapping layer index to activation matrix (n_prompts x hidden_size)\n",
        "    \"\"\"\n",
        "    activations = {layer: [] for layer in layers}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for prompt in tqdm(prompts, desc=\"Extracting\", leave=False):\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "            \n",
        "            outputs = model(**inputs, output_hidden_states=True)\n",
        "            hidden_states = outputs.hidden_states\n",
        "            \n",
        "            for layer in layers:\n",
        "                # Use last token representation\n",
        "                layer_act = hidden_states[layer][0, -1, :].cpu().numpy().astype(np.float32)\n",
        "                activations[layer].append(layer_act)\n",
        "    \n",
        "    # Convert to arrays\n",
        "    for layer in layers:\n",
        "        activations[layer] = np.array(activations[layer])\n",
        "    \n",
        "    return activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Decomposition Analysis\n",
        "\n",
        "Test whether bonded states decompose into their component signatures using:\n",
        "\n",
        "1. **Component Similarity**: Do bonded patterns show higher similarity to their\n",
        "   component AQ than to unrelated AQ?\n",
        "\n",
        "2. **Linear Probe Detection**: Can we detect the presence of each component AQ\n",
        "   within the bonded representation using a linear classifier?\n",
        "\n",
        "3. **Residual Analysis**: After subtracting component directions, what remains?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_aq_centroids(activations_dict: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"Compute centroid (mean) for each AQ category.\n",
        "    \n",
        "    Args:\n",
        "        activations_dict: Dict mapping AQ name to activation matrix\n",
        "        \n",
        "    Returns:\n",
        "        Dict mapping AQ name to centroid vector\n",
        "    \"\"\"\n",
        "    centroids = {}\n",
        "    for name, acts in activations_dict.items():\n",
        "        centroids[name] = np.mean(acts, axis=0)\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def component_similarity_test(bonded_acts: np.ndarray,\n",
        "                              component_centroids: List[np.ndarray],\n",
        "                              unrelated_centroids: List[np.ndarray]) -> Dict[str, float]:\n",
        "    \"\"\"Test if bonded patterns are more similar to components than unrelated AQ.\n",
        "    \n",
        "    Args:\n",
        "        bonded_acts: Activations from bonded prompts (n_prompts x hidden_size)\n",
        "        component_centroids: Centroids of the component AQ\n",
        "        unrelated_centroids: Centroids of unrelated AQ (controls)\n",
        "        \n",
        "    Returns:\n",
        "        Dict with similarity metrics\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    # Mean bonded pattern\n",
        "    bonded_mean = np.mean(bonded_acts, axis=0).reshape(1, -1)\n",
        "    \n",
        "    # Similarity to components\n",
        "    component_sims = []\n",
        "    for centroid in component_centroids:\n",
        "        sim = cosine_similarity(bonded_mean, centroid.reshape(1, -1))[0, 0]\n",
        "        component_sims.append(sim)\n",
        "    \n",
        "    # Similarity to unrelated\n",
        "    unrelated_sims = []\n",
        "    for centroid in unrelated_centroids:\n",
        "        sim = cosine_similarity(bonded_mean, centroid.reshape(1, -1))[0, 0]\n",
        "        unrelated_sims.append(sim)\n",
        "    \n",
        "    results[\"mean_component_sim\"] = np.mean(component_sims)\n",
        "    results[\"mean_unrelated_sim\"] = np.mean(unrelated_sims)\n",
        "    results[\"sim_difference\"] = results[\"mean_component_sim\"] - results[\"mean_unrelated_sim\"]\n",
        "    \n",
        "    # Statistical test\n",
        "    if len(component_sims) > 1 and len(unrelated_sims) > 1:\n",
        "        t_stat, p_val = stats.ttest_ind(component_sims, unrelated_sims)\n",
        "        results[\"t_statistic\"] = t_stat\n",
        "        results[\"p_value\"] = p_val\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def linear_probe_detection(single_aq_acts: Dict[str, np.ndarray],\n",
        "                           bonded_acts: np.ndarray,\n",
        "                           component_names: List[str]) -> Dict[str, Dict]:\n",
        "    \"\"\"Train linear probes to detect each AQ, test on bonded patterns.\n",
        "    \n",
        "    If AQ are compositional, a probe trained to detect AQ_X should also\n",
        "    detect AQ_X within bonded patterns containing AQ_X.\n",
        "    \n",
        "    Args:\n",
        "        single_aq_acts: Dict mapping AQ name to activations from single-AQ prompts\n",
        "        bonded_acts: Activations from bonded prompts\n",
        "        component_names: Names of AQ that are present in the bonded prompts\n",
        "        \n",
        "    Returns:\n",
        "        Dict with probe results for each AQ\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    all_aq_names = list(single_aq_acts.keys())\n",
        "    \n",
        "    for target_aq in all_aq_names:\n",
        "        # Build binary classification: target_aq vs all others\n",
        "        positive_acts = single_aq_acts[target_aq]\n",
        "        negative_acts = np.vstack([single_aq_acts[aq] for aq in all_aq_names if aq != target_aq])\n",
        "        \n",
        "        # Subsample negative to balance\n",
        "        n_pos = len(positive_acts)\n",
        "        if len(negative_acts) > n_pos:\n",
        "            idx = np.random.choice(len(negative_acts), n_pos, replace=False)\n",
        "            negative_acts = negative_acts[idx]\n",
        "        \n",
        "        X = np.vstack([positive_acts, negative_acts])\n",
        "        y = np.array([1] * len(positive_acts) + [0] * len(negative_acts))\n",
        "        \n",
        "        # Train probe\n",
        "        probe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        \n",
        "        # Cross-validation accuracy\n",
        "        cv_scores = cross_val_score(probe, X, y, cv=5)\n",
        "        \n",
        "        # Fit on all data\n",
        "        probe.fit(X, y)\n",
        "        \n",
        "        # Predict on bonded\n",
        "        bonded_probs = probe.predict_proba(bonded_acts)[:, 1]\n",
        "        \n",
        "        is_component = target_aq in component_names\n",
        "        \n",
        "        results[target_aq] = {\n",
        "            \"cv_accuracy\": np.mean(cv_scores),\n",
        "            \"cv_std\": np.std(cv_scores),\n",
        "            \"bonded_detection_prob\": np.mean(bonded_probs),\n",
        "            \"bonded_detection_std\": np.std(bonded_probs),\n",
        "            \"is_component\": is_component,\n",
        "            \"expected_detection\": \"HIGH\" if is_component else \"LOW\"\n",
        "        }\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define experimental conditions\n",
        "SINGLE_AQ = [\"THREAT\", \"PROXIMITY\", \"DIRECTION\", \"URGENCY\", \"AGENT_INTENT\", \"RESOURCE\"]\n",
        "\n",
        "BONDED_CONDITIONS = [\n",
        "    [\"THREAT\", \"PROXIMITY\"],\n",
        "    [\"THREAT\", \"DIRECTION\"],\n",
        "    [\"THREAT\", \"URGENCY\"],\n",
        "    [\"PROXIMITY\", \"DIRECTION\"],\n",
        "    [\"THREAT\", \"PROXIMITY\", \"DIRECTION\"],\n",
        "    [\"THREAT\", \"PROXIMITY\", \"URGENCY\"],\n",
        "    [\"THREAT\", \"AGENT_INTENT\", \"PROXIMITY\"],\n",
        "]\n",
        "\n",
        "print(f\"Single AQ conditions: {len(SINGLE_AQ)}\")\n",
        "print(f\"Bonded conditions: {len(BONDED_CONDITIONS)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment_for_model(model_name: str, model_path: str) -> Dict:\n",
        "    \"\"\"Run full experiment for one model.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Display name\n",
        "        model_path: HuggingFace path\n",
        "        \n",
        "    Returns:\n",
        "        Dict with all results\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running experiment for: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Load model\n",
        "    model, tokenizer, n_layers = load_model(model_path)\n",
        "    \n",
        "    # Select layers to probe (early, middle, late)\n",
        "    layers = [0, n_layers // 4, n_layers // 2, 3 * n_layers // 4, n_layers - 1]\n",
        "    print(f\"Probing layers: {layers}\")\n",
        "    \n",
        "    results = {\n",
        "        \"model\": model_name,\n",
        "        \"layers\": layers,\n",
        "        \"layer_results\": {}\n",
        "    }\n",
        "    \n",
        "    # Generate prompts\n",
        "    print(\"\\nGenerating prompts...\")\n",
        "    single_prompts = {aq: generate_single_aq_prompts(aq, config.prompts_per_condition) \n",
        "                     for aq in SINGLE_AQ}\n",
        "    bonded_prompts = {tuple(cond): generate_bonded_prompts(cond, config.prompts_per_condition)\n",
        "                     for cond in BONDED_CONDITIONS}\n",
        "    \n",
        "    # Extract activations for single AQ\n",
        "    print(\"\\nExtracting single AQ activations...\")\n",
        "    single_activations = {}  # {layer: {aq_name: activations}}\n",
        "    for layer in layers:\n",
        "        single_activations[layer] = {}\n",
        "    \n",
        "    for aq_name, prompts in single_prompts.items():\n",
        "        print(f\"  {aq_name}...\")\n",
        "        acts = extract_activations(model, tokenizer, prompts, layers)\n",
        "        for layer in layers:\n",
        "            single_activations[layer][aq_name] = acts[layer]\n",
        "    \n",
        "    # Extract activations for bonded conditions\n",
        "    print(\"\\nExtracting bonded activations...\")\n",
        "    bonded_activations = {}  # {layer: {condition: activations}}\n",
        "    for layer in layers:\n",
        "        bonded_activations[layer] = {}\n",
        "    \n",
        "    for condition, prompts in bonded_prompts.items():\n",
        "        print(f\"  {' + '.join(condition)}...\")\n",
        "        acts = extract_activations(model, tokenizer, prompts, layers)\n",
        "        for layer in layers:\n",
        "            bonded_activations[layer][condition] = acts[layer]\n",
        "    \n",
        "    # Analyze each layer\n",
        "    print(\"\\nAnalyzing decomposition...\")\n",
        "    for layer in layers:\n",
        "        print(f\"\\nLayer {layer}:\")\n",
        "        layer_results = {\n",
        "            \"similarity_tests\": {},\n",
        "            \"probe_tests\": {}\n",
        "        }\n",
        "        \n",
        "        # Compute centroids for single AQ\n",
        "        centroids = compute_aq_centroids(single_activations[layer])\n",
        "        \n",
        "        # Test each bonded condition\n",
        "        for condition, acts in bonded_activations[layer].items():\n",
        "            condition_name = \" + \".join(condition)\n",
        "            \n",
        "            # Component vs unrelated similarity\n",
        "            component_centroids = [centroids[aq] for aq in condition]\n",
        "            unrelated_aq = [aq for aq in SINGLE_AQ if aq not in condition]\n",
        "            unrelated_centroids = [centroids[aq] for aq in unrelated_aq]\n",
        "            \n",
        "            sim_results = component_similarity_test(acts, component_centroids, unrelated_centroids)\n",
        "            layer_results[\"similarity_tests\"][condition_name] = sim_results\n",
        "            \n",
        "            print(f\"  {condition_name}: comp_sim={sim_results['mean_component_sim']:.3f}, \"\n",
        "                  f\"unrel_sim={sim_results['mean_unrelated_sim']:.3f}, \"\n",
        "                  f\"diff={sim_results['sim_difference']:.4f}\")\n",
        "            \n",
        "            # Linear probe detection\n",
        "            probe_results = linear_probe_detection(\n",
        "                single_activations[layer], acts, list(condition)\n",
        "            )\n",
        "            layer_results[\"probe_tests\"][condition_name] = probe_results\n",
        "        \n",
        "        results[\"layer_results\"][layer] = layer_results\n",
        "    \n",
        "    # Cleanup\n",
        "    del model\n",
        "    gc.collect()\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "# Run for all models\n",
        "all_results = {}\n",
        "for model_name, model_path in config.models.items():\n",
        "    try:\n",
        "        all_results[model_name] = run_experiment_for_model(model_name, model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {model_name}: {e}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_similarity_analysis(results: Dict) -> None:\n",
        "    \"\"\"Plot component vs unrelated similarity across layers.\"\"\"\n",
        "    \n",
        "    n_models = len(results)\n",
        "    fig, axes = plt.subplots(1, n_models, figsize=(7 * n_models, 5))\n",
        "    if n_models == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for ax, (model_name, model_results) in zip(axes, results.items()):\n",
        "        layers = model_results[\"layers\"]\n",
        "        \n",
        "        # Collect similarity differences per layer\n",
        "        layer_diffs = {layer: [] for layer in layers}\n",
        "        \n",
        "        for layer in layers:\n",
        "            for cond_name, sim_res in model_results[\"layer_results\"][layer][\"similarity_tests\"].items():\n",
        "                layer_diffs[layer].append(sim_res[\"sim_difference\"])\n",
        "        \n",
        "        # Plot\n",
        "        means = [np.mean(layer_diffs[l]) for l in layers]\n",
        "        stds = [np.std(layer_diffs[l]) for l in layers]\n",
        "        \n",
        "        ax.errorbar(layers, means, yerr=stds, marker='o', capsize=5, linewidth=2, markersize=8)\n",
        "        ax.axhline(y=0, color='r', linestyle='--', alpha=0.5, label='No difference')\n",
        "        ax.set_xlabel('Layer', fontsize=12)\n",
        "        ax.set_ylabel('Component - Unrelated Similarity', fontsize=12)\n",
        "        ax.set_title(f'{model_name}\\nComponent Similarity Advantage', fontsize=14)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('035F_similarity_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if all_results:\n",
        "    plot_similarity_analysis(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_probe_detection(results: Dict) -> None:\n",
        "    \"\"\"Plot linear probe detection rates.\"\"\"\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        layers = model_results[\"layers\"]\n",
        "        \n",
        "        # Use the last layer (most processed)\n",
        "        final_layer = layers[-1]\n",
        "        probe_data = model_results[\"layer_results\"][final_layer][\"probe_tests\"]\n",
        "        \n",
        "        # Collect detection rates\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        axes = axes.flatten()\n",
        "        \n",
        "        for idx, (condition_name, aq_results) in enumerate(probe_data.items()):\n",
        "            if idx >= len(axes):\n",
        "                break\n",
        "            \n",
        "            ax = axes[idx]\n",
        "            \n",
        "            aq_names = list(aq_results.keys())\n",
        "            detection_probs = [aq_results[aq][\"bonded_detection_prob\"] for aq in aq_names]\n",
        "            is_component = [aq_results[aq][\"is_component\"] for aq in aq_names]\n",
        "            \n",
        "            colors = ['green' if ic else 'gray' for ic in is_component]\n",
        "            \n",
        "            bars = ax.bar(range(len(aq_names)), detection_probs, color=colors)\n",
        "            ax.set_xticks(range(len(aq_names)))\n",
        "            ax.set_xticklabels([aq[:4] for aq in aq_names], rotation=45, ha='right')\n",
        "            ax.set_ylabel('Detection Probability')\n",
        "            ax.set_title(f'{condition_name}')\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
        "        \n",
        "        # Remove empty subplots\n",
        "        for idx in range(len(probe_data), len(axes)):\n",
        "            axes[idx].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'{model_name} - Layer {final_layer}\\nAQ Detection in Bonded States\\n(Green = component AQ, Gray = unrelated AQ)', \n",
        "                     fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'035F_probe_detection_{model_name}.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "if all_results:\n",
        "    plot_probe_detection(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_detection_summary(results: Dict) -> None:\n",
        "    \"\"\"Summary plot: component vs non-component detection rates.\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(1, len(results), figsize=(6 * len(results), 5))\n",
        "    if len(results) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for ax, (model_name, model_results) in zip(axes, results.items()):\n",
        "        layers = model_results[\"layers\"]\n",
        "        \n",
        "        component_rates = []\n",
        "        noncomponent_rates = []\n",
        "        \n",
        "        for layer in layers:\n",
        "            layer_comp = []\n",
        "            layer_noncomp = []\n",
        "            \n",
        "            for condition_name, aq_results in model_results[\"layer_results\"][layer][\"probe_tests\"].items():\n",
        "                for aq_name, res in aq_results.items():\n",
        "                    if res[\"is_component\"]:\n",
        "                        layer_comp.append(res[\"bonded_detection_prob\"])\n",
        "                    else:\n",
        "                        layer_noncomp.append(res[\"bonded_detection_prob\"])\n",
        "            \n",
        "            component_rates.append(np.mean(layer_comp))\n",
        "            noncomponent_rates.append(np.mean(layer_noncomp))\n",
        "        \n",
        "        ax.plot(layers, component_rates, 'g-o', label='Component AQ', linewidth=2, markersize=8)\n",
        "        ax.plot(layers, noncomponent_rates, 'gray', marker='s', linestyle='--', \n",
        "                label='Non-component AQ', linewidth=2, markersize=8)\n",
        "        ax.axhline(y=0.5, color='r', linestyle=':', alpha=0.5, label='Chance')\n",
        "        \n",
        "        ax.set_xlabel('Layer', fontsize=12)\n",
        "        ax.set_ylabel('Mean Detection Probability', fontsize=12)\n",
        "        ax.set_title(f'{model_name}\\nAQ Decomposition Evidence', fontsize=14)\n",
        "        ax.legend()\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('035F_detection_summary.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if all_results:\n",
        "    plot_detection_summary(all_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Statistical Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_effect_sizes(results: Dict) -> None:\n",
        "    \"\"\"Compute and report effect sizes for compositional bonding.\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STATISTICAL SUMMARY: AQ COMPOSITIONAL BONDING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        print(f\"\\n### {model_name} ###\")\n",
        "        \n",
        "        final_layer = model_results[\"layers\"][-1]\n",
        "        \n",
        "        # Similarity analysis\n",
        "        print(f\"\\nSimilarity Analysis (Layer {final_layer}):\")\n",
        "        sim_tests = model_results[\"layer_results\"][final_layer][\"similarity_tests\"]\n",
        "        \n",
        "        all_diffs = []\n",
        "        for cond_name, res in sim_tests.items():\n",
        "            diff = res[\"sim_difference\"]\n",
        "            all_diffs.append(diff)\n",
        "            p_val = res.get(\"p_value\", np.nan)\n",
        "            sig = \"*\" if p_val < 0.05 else \"\"\n",
        "            print(f\"  {cond_name}: diff = {diff:.4f} {sig}\")\n",
        "        \n",
        "        mean_diff = np.mean(all_diffs)\n",
        "        print(f\"  Mean difference: {mean_diff:.4f}\")\n",
        "        \n",
        "        # Probe detection analysis\n",
        "        print(f\"\\nProbe Detection Analysis (Layer {final_layer}):\")\n",
        "        probe_tests = model_results[\"layer_results\"][final_layer][\"probe_tests\"]\n",
        "        \n",
        "        all_comp_rates = []\n",
        "        all_noncomp_rates = []\n",
        "        \n",
        "        for cond_name, aq_results in probe_tests.items():\n",
        "            for aq_name, res in aq_results.items():\n",
        "                if res[\"is_component\"]:\n",
        "                    all_comp_rates.append(res[\"bonded_detection_prob\"])\n",
        "                else:\n",
        "                    all_noncomp_rates.append(res[\"bonded_detection_prob\"])\n",
        "        \n",
        "        mean_comp = np.mean(all_comp_rates)\n",
        "        mean_noncomp = np.mean(all_noncomp_rates)\n",
        "        \n",
        "        # Cohen's d\n",
        "        pooled_std = np.sqrt((np.std(all_comp_rates)**2 + np.std(all_noncomp_rates)**2) / 2)\n",
        "        if pooled_std > 0:\n",
        "            cohens_d = (mean_comp - mean_noncomp) / pooled_std\n",
        "        else:\n",
        "            cohens_d = 0\n",
        "        \n",
        "        # t-test\n",
        "        t_stat, p_val = stats.ttest_ind(all_comp_rates, all_noncomp_rates)\n",
        "        \n",
        "        print(f\"  Component AQ detection: {mean_comp:.3f} +/- {np.std(all_comp_rates):.3f}\")\n",
        "        print(f\"  Non-component AQ detection: {mean_noncomp:.3f} +/- {np.std(all_noncomp_rates):.3f}\")\n",
        "        print(f\"  Difference: {mean_comp - mean_noncomp:.3f}\")\n",
        "        print(f\"  Cohen's d: {cohens_d:.3f}\")\n",
        "        print(f\"  t-statistic: {t_stat:.3f}, p-value: {p_val:.6f}\")\n",
        "        \n",
        "        # Interpretation\n",
        "        print(f\"\\nInterpretation:\")\n",
        "        if mean_diff > 0.01 and cohens_d > 0.5 and p_val < 0.05:\n",
        "            print(f\"  SUPPORTS compositional bonding hypothesis.\")\n",
        "            print(f\"  Bonded states show detectable component signatures.\")\n",
        "        elif mean_diff > 0 and cohens_d > 0.2:\n",
        "            print(f\"  WEAK evidence for compositional bonding.\")\n",
        "            print(f\"  Some component detection, but effect is small.\")\n",
        "        else:\n",
        "            print(f\"  DOES NOT support compositional bonding hypothesis.\")\n",
        "            print(f\"  No significant difference in component vs non-component detection.\")\n",
        "\n",
        "\n",
        "if all_results:\n",
        "    compute_effect_sizes(all_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusions\n",
        "\n",
        "This experiment tests whether AQ are **compositional primitives** by examining\n",
        "whether bonded states (multiple AQ in one prompt) decompose into detectable\n",
        "component signatures.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "1. **Similarity Analysis**: Do bonded patterns show higher similarity to their\n",
        "   component AQ centroids than to unrelated AQ?\n",
        "   - Positive difference = evidence for compositional structure\n",
        "   \n",
        "2. **Linear Probe Detection**: Can we detect the presence of each component AQ\n",
        "   within the bonded representation?\n",
        "   - Component detection > non-component detection = evidence for decomposition\n",
        "\n",
        "**Implications for AKIRA Theory:**\n",
        "\n",
        "If compositional bonding is confirmed:\n",
        "- AQ function as **irreducible primitives** that combine to form complex action\n",
        "  representations\n",
        "- The belief field processes AQ compositionally, maintaining component information\n",
        "- This supports the \"superposition to crystallization\" model where multiple AQ\n",
        "  can coexist and be independently detected\n",
        "\n",
        "If compositional bonding is NOT confirmed:\n",
        "- AQ may be **emergent patterns** rather than compositional primitives\n",
        "- Bonding may create genuinely new representations rather than preserving components\n",
        "- Alternative models needed for how multiple action discriminations combine"
      ]
    }
  ]
}
