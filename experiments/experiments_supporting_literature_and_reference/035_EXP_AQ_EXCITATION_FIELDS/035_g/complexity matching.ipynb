{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 035G: Zipf Complexity Matching in Belief States\n",
        "\n",
        "**AKIRA Project - Oscar Goldman - Shogu Research Group @ Datamutant.ai**\n",
        "\n",
        "---\n",
        "\n",
        "## Core Hypothesis\n",
        "\n",
        "Prompts have an **expected complexity** encoded in their Zipf distribution:\n",
        "\n",
        "- **High-frequency words** (the, is, a) = LOW information, LOW complexity\n",
        "- **Low-frequency words** (quasar, eigenvalue, crystallization) = HIGH information, HIGH complexity\n",
        "\n",
        "The LLM might be **matching** the complexity of its response to the complexity\n",
        "implied by the prompt's Zipf distribution.\n",
        "\n",
        "---\n",
        "\n",
        "## Zipf's Law Recap\n",
        "\n",
        "```\n",
        "Word frequency follows: f(r) ~ r^(-alpha)\n",
        "\n",
        "Rank 1:    'the'     (~7% of all text)\n",
        "Rank 10:   'it'      (~1%)\n",
        "Rank 100:  'world'   (~0.1%)\n",
        "Rank 1000: 'quantum' (~0.01%)\n",
        "```\n",
        "\n",
        "**Information content is inversely related to frequency:**\n",
        "- Common words: structural glue, low information\n",
        "- Rare words: content carriers, high information\n",
        "\n",
        "---\n",
        "\n",
        "## Experimental Design\n",
        "\n",
        "1. Create prompts with varying Zipf complexity profiles\n",
        "2. Measure the prompt's complexity (mean/median Zipf rank)\n",
        "3. Generate responses\n",
        "4. Measure response complexity\n",
        "5. Test: Does response complexity correlate with prompt complexity?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers torch numpy matplotlib seaborn scipy wordfreq -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass, field\n",
        "from scipy import stats\n",
        "from wordfreq import word_frequency, zipf_frequency\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if DEVICE == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Zipf Complexity Measurement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_text(text: str) -> List[str]:\n",
        "    \"\"\"Simple tokenization - extract words.\"\"\"\n",
        "    # Remove punctuation, lowercase, split on whitespace\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text.lower())\n",
        "    words = text.split()\n",
        "    return [w for w in words if len(w) > 1]  # Skip single chars\n",
        "\n",
        "\n",
        "def get_zipf_scores(words: List[str], lang: str = 'en') -> List[float]:\n",
        "    \"\"\"Get Zipf frequency scores for a list of words.\n",
        "    \n",
        "    Zipf scale: 0 (not in corpus) to ~7 (most common like 'the')\n",
        "    Higher = more common = less information\n",
        "    \n",
        "    We invert this for 'complexity': lower Zipf score = higher complexity\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for word in words:\n",
        "        z = zipf_frequency(word, lang)\n",
        "        scores.append(z)\n",
        "    return scores\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ZipfMetrics:\n",
        "    \"\"\"Zipf-based complexity metrics for text.\"\"\"\n",
        "    \n",
        "    mean_zipf: float = 0.0  # Mean Zipf frequency (higher = more common)\n",
        "    median_zipf: float = 0.0\n",
        "    min_zipf: float = 0.0  # Rarest word\n",
        "    max_zipf: float = 0.0  # Most common word\n",
        "    std_zipf: float = 0.0  # Variance in word frequency\n",
        "    \n",
        "    # Derived complexity measures\n",
        "    complexity: float = 0.0  # Higher = more complex (inverted mean Zipf)\n",
        "    information_density: float = 0.0  # Sum of (max_zipf - zipf) for all words\n",
        "    rare_word_ratio: float = 0.0  # Fraction of words with Zipf < 3\n",
        "    \n",
        "    n_words: int = 0\n",
        "    n_unique: int = 0\n",
        "    \n",
        "    @staticmethod\n",
        "    def from_text(text: str) -> 'ZipfMetrics':\n",
        "        \"\"\"Compute Zipf metrics from text.\"\"\"\n",
        "        words = tokenize_text(text)\n",
        "        if not words:\n",
        "            return ZipfMetrics()\n",
        "        \n",
        "        zipf_scores = get_zipf_scores(words)\n",
        "        \n",
        "        # Filter out zeros (unknown words)\n",
        "        known_scores = [z for z in zipf_scores if z > 0]\n",
        "        if not known_scores:\n",
        "            return ZipfMetrics(n_words=len(words), n_unique=len(set(words)))\n",
        "        \n",
        "        metrics = ZipfMetrics()\n",
        "        metrics.mean_zipf = np.mean(known_scores)\n",
        "        metrics.median_zipf = np.median(known_scores)\n",
        "        metrics.min_zipf = np.min(known_scores)\n",
        "        metrics.max_zipf = np.max(known_scores)\n",
        "        metrics.std_zipf = np.std(known_scores)\n",
        "        \n",
        "        # Complexity: invert the Zipf scale (higher = more complex)\n",
        "        # Max Zipf is ~7, so complexity = 7 - mean_zipf\n",
        "        metrics.complexity = 7.0 - metrics.mean_zipf\n",
        "        \n",
        "        # Information density: sum of \"surprisal\" for each word\n",
        "        metrics.information_density = sum(7.0 - z for z in known_scores) / len(known_scores)\n",
        "        \n",
        "        # Rare word ratio (Zipf < 3 is quite rare)\n",
        "        metrics.rare_word_ratio = sum(1 for z in known_scores if z < 3) / len(known_scores)\n",
        "        \n",
        "        metrics.n_words = len(words)\n",
        "        metrics.n_unique = len(set(words))\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "\n",
        "# Test\n",
        "test_simple = \"The cat sat on the mat.\"\n",
        "test_complex = \"The quantum eigenstate underwent crystallographic decoherence during thermodynamic equilibration.\"\n",
        "\n",
        "m_simple = ZipfMetrics.from_text(test_simple)\n",
        "m_complex = ZipfMetrics.from_text(test_complex)\n",
        "\n",
        "print(\"Simple text:\")\n",
        "print(f\"  Mean Zipf: {m_simple.mean_zipf:.2f}, Complexity: {m_simple.complexity:.2f}\")\n",
        "print(f\"  Rare word ratio: {m_simple.rare_word_ratio:.2f}\")\n",
        "\n",
        "print(\"\\nComplex text:\")\n",
        "print(f\"  Mean Zipf: {m_complex.mean_zipf:.2f}, Complexity: {m_complex.complexity:.2f}\")\n",
        "print(f\"  Rare word ratio: {m_complex.rare_word_ratio:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Long Prompt Generation\n",
        "\n",
        "Create long prompts with controlled Zipf complexity profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompts at different complexity levels\n",
        "# Each should be substantial (100+ words) to establish clear complexity profile\n",
        "\n",
        "COMPLEXITY_PROMPTS = {\n",
        "    \"low\": [\n",
        "        # Simple, everyday language, common words\n",
        "        \"\"\"I want to tell you about my day. I woke up in the morning and got out of bed. \n",
        "        I went to the kitchen and made some food. I had eggs and toast for my meal. \n",
        "        Then I got ready for work. I put on my clothes and got my bag. I went out \n",
        "        the door and walked to my car. The weather was good and the sun was out. \n",
        "        I drove to work and it took about thirty minutes. When I got there I went \n",
        "        to my desk and started working. I had a lot of things to do. I worked on \n",
        "        my computer and talked to some people. At lunch I went out to get some food. \n",
        "        After lunch I had a meeting with my team. We talked about our work for the week.\n",
        "        What do you think about this kind of day? What should I do next?\"\"\",\n",
        "        \n",
        "        \"\"\"The dog ran in the park. It was a big dog with brown fur. The dog liked to \n",
        "        play with a ball. The owner threw the ball and the dog ran to get it. Other \n",
        "        dogs were in the park too. Some dogs were big and some were small. The dogs \n",
        "        played together and had fun. It was a nice day with good weather. The sun \n",
        "        was warm but not too hot. People sat on the grass and watched the dogs play. \n",
        "        Some people had food and water for their dogs. The park was a good place for \n",
        "        dogs to run and play. After a while the dogs got tired. They lay down in the \n",
        "        shade under the trees. The owners gave them water to drink. Everyone had a \n",
        "        good time at the park. What else could happen at the park?\"\"\",\n",
        "        \n",
        "        \"\"\"I need to go to the store to buy some things. I need milk, bread, eggs, and \n",
        "        butter. I also want to get some fruit like apples and bananas. Maybe I will \n",
        "        get some meat for dinner. I like chicken and fish. I should also get some \n",
        "        vegetables like carrots and peas. I need to make a list so I do not forget \n",
        "        anything. The store is not far from my house. I can walk there in ten minutes. \n",
        "        Or I can take the car if I am buying a lot of things. The store has good \n",
        "        prices and nice workers. I like to go there every week to get what I need. \n",
        "        Sometimes I find new things to try. Last week I got a new kind of cheese \n",
        "        that was very good. What should I buy at the store today?\"\"\",\n",
        "    ],\n",
        "    \n",
        "    \"medium\": [\n",
        "        # Mix of common and moderately technical language\n",
        "        \"\"\"The economic situation in modern cities presents several interesting challenges \n",
        "        that urban planners must carefully consider. Housing affordability has become \n",
        "        a significant concern for middle-class families who struggle to find adequate \n",
        "        accommodation within reasonable commuting distance of employment centers. \n",
        "        Transportation infrastructure requires substantial investment to maintain \n",
        "        efficient movement of people and goods throughout metropolitan areas. \n",
        "        Environmental sustainability goals often conflict with economic development \n",
        "        objectives, creating difficult tradeoffs for policy makers. Community \n",
        "        organizations advocate for preserving neighborhood character while developers \n",
        "        seek profitable construction opportunities. Municipal governments must balance \n",
        "        these competing interests while managing limited budgets and responding to \n",
        "        citizen demands for improved services. What approaches might help resolve \n",
        "        these urban planning challenges?\"\"\",\n",
        "        \n",
        "        \"\"\"Understanding climate patterns requires examining multiple interconnected \n",
        "        atmospheric and oceanic systems operating across different temporal scales. \n",
        "        Seasonal variations in temperature and precipitation result from Earth's \n",
        "        axial tilt and orbital characteristics around the Sun. Regional weather \n",
        "        phenomena like monsoons and hurricanes develop through complex interactions \n",
        "        between warm ocean surfaces and atmospheric circulation patterns. Long-term \n",
        "        climate trends reflect changes in greenhouse gas concentrations, solar \n",
        "        radiation, and feedback mechanisms within the Earth system. Scientists \n",
        "        use sophisticated computer models to simulate these processes and generate \n",
        "        projections of future conditions under various emissions scenarios. \n",
        "        Observational networks including satellites, weather stations, and ocean \n",
        "        buoys provide essential data for calibrating and validating these models. \n",
        "        How should we interpret climate predictions given inherent uncertainties?\"\"\",\n",
        "        \n",
        "        \"\"\"The development of artificial intelligence technologies has progressed \n",
        "        remarkably over recent decades, transforming numerous industries and raising \n",
        "        important societal questions. Machine learning algorithms can now recognize \n",
        "        patterns in vast datasets that would overwhelm human analysts. Natural \n",
        "        language processing enables computers to understand and generate human text \n",
        "        with increasing sophistication. Computer vision systems identify objects and \n",
        "        activities in images and video streams with impressive accuracy. These \n",
        "        capabilities find applications in healthcare diagnosis, financial analysis, \n",
        "        autonomous vehicles, and countless other domains. However, concerns about \n",
        "        algorithmic bias, job displacement, privacy erosion, and existential risk \n",
        "        demand careful consideration. Researchers and policymakers work to develop \n",
        "        frameworks for responsible AI development and deployment. What principles \n",
        "        should guide the advancement of artificial intelligence?\"\"\",\n",
        "    ],\n",
        "    \n",
        "    \"high\": [\n",
        "        # Technical, specialized vocabulary, rare words\n",
        "        \"\"\"The phenomenological implications of quantum chromodynamics for understanding \n",
        "        hadronic interactions require sophisticated mathematical formalisms including \n",
        "        perturbative expansions and non-perturbative lattice calculations. Asymptotic \n",
        "        freedom in the ultraviolet regime permits reliable perturbative computations \n",
        "        of high-energy scattering amplitudes, while confinement in the infrared sector \n",
        "        necessitates alternative approaches such as effective field theories and \n",
        "        holographic dualities. The chiral symmetry breaking mechanism generates \n",
        "        constituent quark masses through dynamical processes fundamentally different \n",
        "        from the Higgs mechanism responsible for electroweak symmetry breaking. \n",
        "        Instantons and other topological configurations contribute to the anomalous \n",
        "        violation of axial symmetry and the resolution of the strong CP problem \n",
        "        through axion dynamics. Contemporary lattice QCD simulations incorporating \n",
        "        dynamical fermions achieve unprecedented precision in predicting hadronic \n",
        "        spectroscopy and matrix elements. What experimental signatures might \n",
        "        distinguish between competing theoretical frameworks?\"\"\",\n",
        "        \n",
        "        \"\"\"Neuroplasticity mechanisms underlying long-term potentiation involve intricate \n",
        "        cascades of molecular signaling initiated by glutamatergic neurotransmission \n",
        "        at postsynaptic densities. NMDA receptor activation permits calcium influx \n",
        "        triggering calmodulin-dependent protein kinase phosphorylation cascades that \n",
        "        modulate AMPA receptor trafficking and conductance properties. Retrograde \n",
        "        messengers including endocannabinoids and nitric oxide mediate presynaptic \n",
        "        modifications complementing postsynaptic changes. Structural plasticity \n",
        "        encompasses dendritic spine morphogenesis regulated by actin cytoskeleton \n",
        "        dynamics and extracellular matrix remodeling. Transcriptional programs \n",
        "        activated by CREB phosphorylation consolidate transient modifications into \n",
        "        persistent synaptic strengthening through protein synthesis-dependent \n",
        "        mechanisms. Homeostatic plasticity mechanisms including synaptic scaling \n",
        "        maintain network stability amid Hebbian modifications. Astrocytic and \n",
        "        microglial contributions to synaptic plasticity remain incompletely \n",
        "        characterized. How do these mechanisms interact during memory consolidation?\"\"\",\n",
        "        \n",
        "        \"\"\"Cryptographic protocols employing elliptic curve arithmetic over finite fields \n",
        "        provide computational security guarantees predicated on the intractability of \n",
        "        the discrete logarithm problem in appropriately parameterized algebraic groups. \n",
        "        Pairing-based constructions enable sophisticated functionalities including \n",
        "        identity-based encryption and attribute-based access control through bilinear \n",
        "        mappings between elliptic curve subgroups. Post-quantum cryptographic schemes \n",
        "        incorporating lattice problems, isogenies, and multivariate polynomials \n",
        "        address vulnerabilities to quantum algorithmic attacks threatening conventional \n",
        "        public-key infrastructure. Homomorphic encryption permitting computation on \n",
        "        ciphertexts without decryption enables privacy-preserving data analysis though \n",
        "        substantial computational overhead limitations persist. Zero-knowledge proof \n",
        "        systems facilitate verification of computational claims without revealing \n",
        "        underlying inputs through interactive or non-interactive protocols. Formal \n",
        "        verification methodologies ensure implementation correctness against \n",
        "        specification through automated theorem proving. What vulnerabilities might \n",
        "        emerge from quantum computing advances?\"\"\",\n",
        "    ],\n",
        "    \n",
        "    \"mixed_ascending\": [\n",
        "        # Start simple, get progressively more complex\n",
        "        \"\"\"I want to learn about how the brain works. It starts simple - the brain is \n",
        "        in your head and it helps you think. But it gets more interesting when you \n",
        "        look closer. The brain has billions of cells called neurons. These neurons \n",
        "        talk to each other through connections called synapses. When you learn \n",
        "        something new, synaptic connections strengthen through a process called \n",
        "        long-term potentiation. This involves calcium signaling, protein kinase \n",
        "        activation, and eventually gene transcription leading to structural changes \n",
        "        in dendritic spines. The molecular cascades underlying memory consolidation \n",
        "        implicate NMDA receptor-mediated glutamatergic transmission, retrograde \n",
        "        endocannabinoid signaling, and CREB-dependent transcriptional programs. \n",
        "        How do these hierarchical levels of neural organization produce conscious \n",
        "        experience and adaptive behavior?\"\"\",\n",
        "    ],\n",
        "    \n",
        "    \"mixed_descending\": [\n",
        "        # Start complex, get progressively simpler\n",
        "        \"\"\"Quantum decoherence mechanisms underlying the transition from superposition \n",
        "        to classical probability distributions involve entanglement with environmental \n",
        "        degrees of freedom through unitary evolution of composite system-reservoir \n",
        "        states. The reduced density matrix obtained by partial trace exhibits \n",
        "        exponentially decaying off-diagonal elements characterizing quantum coherence. \n",
        "        This mathematical description captures what happens when quantum things \n",
        "        interact with their surroundings. In simpler terms, the quantum effects \n",
        "        disappear when things touch the world around them. It's like how a wave \n",
        "        in water spreads out and fades. The small quantum world becomes the normal \n",
        "        big world we see every day. Hot things have more of this effect than cold \n",
        "        things. Big things lose their quantum nature faster than small things. \n",
        "        What do you think about this idea?\"\"\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Verify complexity levels\n",
        "print(\"=== Zipf Complexity by Prompt Category ===\")\n",
        "for category, prompts in COMPLEXITY_PROMPTS.items():\n",
        "    complexities = [ZipfMetrics.from_text(p).complexity for p in prompts]\n",
        "    rare_ratios = [ZipfMetrics.from_text(p).rare_word_ratio for p in prompts]\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(f\"  Mean complexity: {np.mean(complexities):.2f}\")\n",
        "    print(f\"  Mean rare word ratio: {np.mean(rare_ratios):.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Configuration for Zipf complexity matching experiment.\"\"\"\n",
        "    \n",
        "    models: Dict[str, str] = field(default_factory=lambda: {\n",
        "        \"gpt2-medium\": \"gpt2-medium\",\n",
        "        \"gpt2-large\": \"gpt2-large\",\n",
        "    })\n",
        "    \n",
        "    max_new_tokens: int = 150  # Longer responses to get stable Zipf measurements\n",
        "    n_generations_per_prompt: int = 3  # Multiple generations per prompt\n",
        "    temperature: float = 0.7  # Some randomness for diversity\n",
        "    random_seed: int = 42\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        np.random.seed(self.random_seed)\n",
        "        torch.manual_seed(self.random_seed)\n",
        "\n",
        "\n",
        "config = ExperimentConfig()\n",
        "print(f\"Models: {list(config.models.keys())}\")\n",
        "print(f\"Max new tokens: {config.max_new_tokens}\")\n",
        "print(f\"Generations per prompt: {config.n_generations_per_prompt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(model_name: str) -> Tuple:\n",
        "    \"\"\"Load model and tokenizer.\"\"\"\n",
        "    print(f\"Loading {model_name}...\")\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    \n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
        "        device_map=\"auto\" if DEVICE == \"cuda\" else None\n",
        "    )\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"  Hidden size: {model.config.hidden_size}\")\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class GenerationResult:\n",
        "    \"\"\"Result from a single generation.\"\"\"\n",
        "    prompt: str\n",
        "    response: str\n",
        "    prompt_metrics: ZipfMetrics\n",
        "    response_metrics: ZipfMetrics\n",
        "    category: str\n",
        "\n",
        "\n",
        "def generate_and_analyze(model, tokenizer, prompt: str, category: str) -> List[GenerationResult]:\n",
        "    \"\"\"Generate responses and analyze Zipf complexity.\"\"\"\n",
        "    \n",
        "    prompt_metrics = ZipfMetrics.from_text(prompt)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _ in range(config.n_generations_per_prompt):\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=config.max_new_tokens,\n",
        "                do_sample=True,\n",
        "                temperature=config.temperature,\n",
        "                top_p=0.9,\n",
        "                pad_token_id=tokenizer.pad_token_id\n",
        "            )\n",
        "            \n",
        "            # Decode only the new tokens\n",
        "            new_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
        "            response = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "            \n",
        "            response_metrics = ZipfMetrics.from_text(response)\n",
        "            \n",
        "            results.append(GenerationResult(\n",
        "                prompt=prompt,\n",
        "                response=response,\n",
        "                prompt_metrics=prompt_metrics,\n",
        "                response_metrics=response_metrics,\n",
        "                category=category\n",
        "            ))\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def run_zipf_experiment(model_name: str, model_path: str) -> List[GenerationResult]:\n",
        "    \"\"\"Run Zipf complexity matching experiment.\"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    model, tokenizer = load_model(model_path)\n",
        "    \n",
        "    all_results = []\n",
        "    \n",
        "    for category, prompts in COMPLEXITY_PROMPTS.items():\n",
        "        print(f\"\\nCategory: {category}\")\n",
        "        \n",
        "        for i, prompt in enumerate(tqdm(prompts, desc=category)):\n",
        "            results = generate_and_analyze(model, tokenizer, prompt, category)\n",
        "            all_results.extend(results)\n",
        "            \n",
        "            # Quick feedback\n",
        "            avg_prompt_complexity = results[0].prompt_metrics.complexity\n",
        "            avg_response_complexity = np.mean([r.response_metrics.complexity for r in results])\n",
        "            # print(f\"  Prompt {i+1}: P_complexity={avg_prompt_complexity:.2f}, R_complexity={avg_response_complexity:.2f}\")\n",
        "    \n",
        "    # Cleanup\n",
        "    del model\n",
        "    gc.collect()\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Run experiment\n",
        "all_experiment_results = {}\n",
        "for model_name, model_path in config.models.items():\n",
        "    try:\n",
        "        all_experiment_results[model_name] = run_zipf_experiment(model_name, model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {model_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analysis and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_complexity_matching(results: Dict[str, List[GenerationResult]]) -> None:\n",
        "    \"\"\"Analyze whether response complexity matches prompt complexity.\"\"\"\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ANALYSIS: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Collect data\n",
        "        prompt_complexities = [r.prompt_metrics.complexity for r in model_results]\n",
        "        response_complexities = [r.response_metrics.complexity for r in model_results]\n",
        "        categories = [r.category for r in model_results]\n",
        "        \n",
        "        # Overall correlation\n",
        "        r, p = stats.pearsonr(prompt_complexities, response_complexities)\n",
        "        print(f\"\\nOverall Complexity Correlation:\")\n",
        "        print(f\"  r = {r:.3f}, p = {p:.6f}\")\n",
        "        \n",
        "        if r > 0.3 and p < 0.05:\n",
        "            print(f\"  -> STRONG evidence: Model MATCHES prompt complexity\")\n",
        "        elif r > 0.1 and p < 0.05:\n",
        "            print(f\"  -> MODERATE evidence: Model somewhat matches complexity\")\n",
        "        elif r < -0.1 and p < 0.05:\n",
        "            print(f\"  -> INVERSE relationship: Model produces OPPOSITE complexity\")\n",
        "        else:\n",
        "            print(f\"  -> No significant relationship\")\n",
        "        \n",
        "        # By category\n",
        "        print(f\"\\nBy Category:\")\n",
        "        print(f\"{'Category':<20} {'Prompt Complexity':>18} {'Response Complexity':>20} {'Difference':>12}\")\n",
        "        print(\"-\" * 70)\n",
        "        \n",
        "        for cat in ['low', 'medium', 'high', 'mixed_ascending', 'mixed_descending']:\n",
        "            cat_results = [r for r in model_results if r.category == cat]\n",
        "            if not cat_results:\n",
        "                continue\n",
        "            \n",
        "            p_comp = np.mean([r.prompt_metrics.complexity for r in cat_results])\n",
        "            r_comp = np.mean([r.response_metrics.complexity for r in cat_results])\n",
        "            diff = r_comp - p_comp\n",
        "            \n",
        "            print(f\"{cat:<20} {p_comp:>18.3f} {r_comp:>20.3f} {diff:>+12.3f}\")\n",
        "        \n",
        "        # Rare word ratio analysis\n",
        "        prompt_rare = [r.prompt_metrics.rare_word_ratio for r in model_results]\n",
        "        response_rare = [r.response_metrics.rare_word_ratio for r in model_results]\n",
        "        \n",
        "        r_rare, p_rare = stats.pearsonr(prompt_rare, response_rare)\n",
        "        print(f\"\\nRare Word Ratio Correlation:\")\n",
        "        print(f\"  r = {r_rare:.3f}, p = {p_rare:.6f}\")\n",
        "\n",
        "\n",
        "if all_experiment_results:\n",
        "    analyze_complexity_matching(all_experiment_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_complexity_matching(results: Dict[str, List[GenerationResult]]) -> None:\n",
        "    \"\"\"Visualize complexity matching.\"\"\"\n",
        "    \n",
        "    n_models = len(results)\n",
        "    fig, axes = plt.subplots(2, n_models, figsize=(7 * n_models, 10))\n",
        "    if n_models == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "    \n",
        "    for col, (model_name, model_results) in enumerate(results.items()):\n",
        "        # Scatter plot: prompt vs response complexity\n",
        "        ax = axes[0, col]\n",
        "        \n",
        "        prompt_comp = [r.prompt_metrics.complexity for r in model_results]\n",
        "        response_comp = [r.response_metrics.complexity for r in model_results]\n",
        "        categories = [r.category for r in model_results]\n",
        "        \n",
        "        # Color by category\n",
        "        cat_colors = {'low': 'blue', 'medium': 'green', 'high': 'red', \n",
        "                     'mixed_ascending': 'purple', 'mixed_descending': 'orange'}\n",
        "        colors = [cat_colors.get(c, 'gray') for c in categories]\n",
        "        \n",
        "        ax.scatter(prompt_comp, response_comp, c=colors, alpha=0.6, s=50)\n",
        "        \n",
        "        # Add regression line\n",
        "        z = np.polyfit(prompt_comp, response_comp, 1)\n",
        "        p = np.poly1d(z)\n",
        "        x_line = np.linspace(min(prompt_comp), max(prompt_comp), 100)\n",
        "        ax.plot(x_line, p(x_line), 'k--', alpha=0.5, label=f'Fit (slope={z[0]:.2f})')\n",
        "        \n",
        "        # Add y=x line (perfect matching)\n",
        "        ax.plot([2, 5], [2, 5], 'r:', alpha=0.5, label='Perfect matching')\n",
        "        \n",
        "        ax.set_xlabel('Prompt Complexity (7 - mean Zipf)', fontsize=12)\n",
        "        ax.set_ylabel('Response Complexity (7 - mean Zipf)', fontsize=12)\n",
        "        ax.set_title(f'{model_name}\\nPrompt vs Response Complexity', fontsize=14)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Correlation annotation\n",
        "        r, p = stats.pearsonr(prompt_comp, response_comp)\n",
        "        ax.annotate(f'r = {r:.3f}\\np = {p:.4f}', xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "                   fontsize=11, verticalalignment='top',\n",
        "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        \n",
        "        # Bar plot by category\n",
        "        ax = axes[1, col]\n",
        "        \n",
        "        cat_order = ['low', 'medium', 'high']\n",
        "        prompt_means = []\n",
        "        response_means = []\n",
        "        response_stds = []\n",
        "        \n",
        "        for cat in cat_order:\n",
        "            cat_results = [r for r in model_results if r.category == cat]\n",
        "            if cat_results:\n",
        "                prompt_means.append(np.mean([r.prompt_metrics.complexity for r in cat_results]))\n",
        "                response_means.append(np.mean([r.response_metrics.complexity for r in cat_results]))\n",
        "                response_stds.append(np.std([r.response_metrics.complexity for r in cat_results]))\n",
        "        \n",
        "        x = np.arange(len(cat_order))\n",
        "        width = 0.35\n",
        "        \n",
        "        bars1 = ax.bar(x - width/2, prompt_means, width, label='Prompt', color='steelblue')\n",
        "        bars2 = ax.bar(x + width/2, response_means, width, yerr=response_stds, \n",
        "                      label='Response', color='coral', capsize=5)\n",
        "        \n",
        "        ax.set_ylabel('Complexity Score', fontsize=12)\n",
        "        ax.set_xlabel('Prompt Category', fontsize=12)\n",
        "        ax.set_title(f'{model_name}\\nComplexity by Category', fontsize=14)\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(['Low', 'Medium', 'High'])\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('035G_zipf_complexity_matching.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if all_experiment_results:\n",
        "    plot_complexity_matching(all_experiment_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_zipf_distributions(results: Dict[str, List[GenerationResult]]) -> None:\n",
        "    \"\"\"Visualize Zipf score distributions for prompts and responses.\"\"\"\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        \n",
        "        for idx, category in enumerate(['low', 'medium', 'high']):\n",
        "            ax = axes[idx]\n",
        "            cat_results = [r for r in model_results if r.category == category]\n",
        "            \n",
        "            if not cat_results:\n",
        "                continue\n",
        "            \n",
        "            # Collect all Zipf scores\n",
        "            prompt_words = []\n",
        "            response_words = []\n",
        "            \n",
        "            for r in cat_results:\n",
        "                prompt_words.extend(tokenize_text(r.prompt))\n",
        "                response_words.extend(tokenize_text(r.response))\n",
        "            \n",
        "            prompt_zipf = get_zipf_scores(prompt_words)\n",
        "            response_zipf = get_zipf_scores(response_words)\n",
        "            \n",
        "            # Filter zeros\n",
        "            prompt_zipf = [z for z in prompt_zipf if z > 0]\n",
        "            response_zipf = [z for z in response_zipf if z > 0]\n",
        "            \n",
        "            # Plot histograms\n",
        "            bins = np.linspace(0, 7, 30)\n",
        "            ax.hist(prompt_zipf, bins=bins, alpha=0.5, label='Prompt', color='steelblue', density=True)\n",
        "            ax.hist(response_zipf, bins=bins, alpha=0.5, label='Response', color='coral', density=True)\n",
        "            \n",
        "            ax.set_xlabel('Zipf Frequency Score', fontsize=11)\n",
        "            ax.set_ylabel('Density', fontsize=11)\n",
        "            ax.set_title(f'{category.capitalize()} Complexity\\nZipf Distribution', fontsize=12)\n",
        "            ax.legend()\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add mean lines\n",
        "            ax.axvline(np.mean(prompt_zipf), color='steelblue', linestyle='--', linewidth=2)\n",
        "            ax.axvline(np.mean(response_zipf), color='coral', linestyle='--', linewidth=2)\n",
        "        \n",
        "        plt.suptitle(f'{model_name}: Zipf Distribution Comparison', fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'035G_zipf_distribution_{model_name}.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "if all_experiment_results:\n",
        "    plot_zipf_distributions(all_experiment_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Statistical Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def statistical_summary(results: Dict[str, List[GenerationResult]]) -> None:\n",
        "    \"\"\"Print comprehensive statistical summary.\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STATISTICAL SUMMARY: ZIPF COMPLEXITY MATCHING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        print(f\"\\n### {model_name} ###\")\n",
        "        print(f\"Total generations: {len(model_results)}\")\n",
        "        \n",
        "        # Collect metrics\n",
        "        prompt_comp = [r.prompt_metrics.complexity for r in model_results]\n",
        "        response_comp = [r.response_metrics.complexity for r in model_results]\n",
        "        prompt_rare = [r.prompt_metrics.rare_word_ratio for r in model_results]\n",
        "        response_rare = [r.response_metrics.rare_word_ratio for r in model_results]\n",
        "        prompt_info = [r.prompt_metrics.information_density for r in model_results]\n",
        "        response_info = [r.response_metrics.information_density for r in model_results]\n",
        "        \n",
        "        print(\"\\nCorrelations (prompt -> response):\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        metrics = [\n",
        "            (\"Complexity\", prompt_comp, response_comp),\n",
        "            (\"Rare word ratio\", prompt_rare, response_rare),\n",
        "            (\"Information density\", prompt_info, response_info)\n",
        "        ]\n",
        "        \n",
        "        for name, p_vals, r_vals in metrics:\n",
        "            r, p = stats.pearsonr(p_vals, r_vals)\n",
        "            sig = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"\"\n",
        "            print(f\"  {name:<25} r = {r:>6.3f}, p = {p:.6f} {sig}\")\n",
        "        \n",
        "        # Effect size: how much does response complexity change per unit prompt complexity?\n",
        "        slope, intercept, r_value, p_value, std_err = stats.linregress(prompt_comp, response_comp)\n",
        "        print(f\"\\nRegression (Response = slope * Prompt + intercept):\")\n",
        "        print(f\"  slope = {slope:.3f}, intercept = {intercept:.3f}\")\n",
        "        print(f\"  R-squared = {r_value**2:.3f}\")\n",
        "        \n",
        "        # Interpretation\n",
        "        print(\"\\nInterpretation:\")\n",
        "        if slope > 0.5:\n",
        "            print(f\"  Model STRONGLY matches prompt complexity (slope = {slope:.2f})\")\n",
        "            print(f\"  -> Supports hypothesis that LLMs try to match the Zipf complexity space\")\n",
        "        elif slope > 0.2:\n",
        "            print(f\"  Model MODERATELY matches prompt complexity (slope = {slope:.2f})\")\n",
        "        elif slope > 0:\n",
        "            print(f\"  Model WEAKLY matches prompt complexity (slope = {slope:.2f})\")\n",
        "        else:\n",
        "            print(f\"  Model does NOT match prompt complexity (slope = {slope:.2f})\")\n",
        "        \n",
        "        # Compare high vs low\n",
        "        low_results = [r for r in model_results if r.category == 'low']\n",
        "        high_results = [r for r in model_results if r.category == 'high']\n",
        "        \n",
        "        if low_results and high_results:\n",
        "            low_resp_comp = [r.response_metrics.complexity for r in low_results]\n",
        "            high_resp_comp = [r.response_metrics.complexity for r in high_results]\n",
        "            \n",
        "            t_stat, p_val = stats.ttest_ind(low_resp_comp, high_resp_comp)\n",
        "            \n",
        "            # Cohen's d\n",
        "            pooled_std = np.sqrt((np.std(low_resp_comp)**2 + np.std(high_resp_comp)**2) / 2)\n",
        "            cohens_d = (np.mean(high_resp_comp) - np.mean(low_resp_comp)) / pooled_std if pooled_std > 0 else 0\n",
        "            \n",
        "            print(f\"\\nLow vs High Prompt Category (Response Complexity):\")\n",
        "            print(f\"  Low prompts -> response complexity: {np.mean(low_resp_comp):.3f}\")\n",
        "            print(f\"  High prompts -> response complexity: {np.mean(high_resp_comp):.3f}\")\n",
        "            print(f\"  t = {t_stat:.3f}, p = {p_val:.6f}\")\n",
        "            print(f\"  Cohen's d = {cohens_d:.3f}\")\n",
        "\n",
        "\n",
        "if all_experiment_results:\n",
        "    statistical_summary(all_experiment_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Example Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_example_responses(results: Dict[str, List[GenerationResult]], n_examples: int = 2) -> None:\n",
        "    \"\"\"Show example responses from different complexity levels.\"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXAMPLE RESPONSES BY COMPLEXITY LEVEL\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        print(f\"\\n### {model_name} ###\")\n",
        "        \n",
        "        for category in ['low', 'high']:\n",
        "            print(f\"\\n--- {category.upper()} complexity prompts ---\")\n",
        "            cat_results = [r for r in model_results if r.category == category]\n",
        "            \n",
        "            for i, r in enumerate(cat_results[:n_examples]):\n",
        "                print(f\"\\nExample {i+1}:\")\n",
        "                print(f\"  Prompt complexity: {r.prompt_metrics.complexity:.2f}\")\n",
        "                print(f\"  Response complexity: {r.response_metrics.complexity:.2f}\")\n",
        "                print(f\"  Prompt rare word ratio: {r.prompt_metrics.rare_word_ratio:.2%}\")\n",
        "                print(f\"  Response rare word ratio: {r.response_metrics.rare_word_ratio:.2%}\")\n",
        "                print(f\"  Response: {r.response[:200]}...\" if len(r.response) > 200 else f\"  Response: {r.response}\")\n",
        "\n",
        "\n",
        "if all_experiment_results:\n",
        "    show_example_responses(all_experiment_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusions\n",
        "\n",
        "This experiment tests whether LLMs **match the Zipf complexity** of their prompts.\n",
        "\n",
        "**Hypothesis**: The model's \"belief state\" is influenced by the Zipf distribution\n",
        "of the prompt. Complex prompts (rare words, high information density) should\n",
        "elicit complex responses.\n",
        "\n",
        "**Key findings:**\n",
        "\n",
        "1. **Correlation between prompt and response complexity**:\n",
        "   - Positive correlation supports complexity matching\n",
        "   - Slope near 1.0 would indicate perfect matching\n",
        "\n",
        "2. **Category differences**:\n",
        "   - Do high-complexity prompts produce higher-complexity responses?\n",
        "   - Is the effect size meaningful?\n",
        "\n",
        "3. **Zipf distribution shape**:\n",
        "   - Do response distributions mirror prompt distributions?\n",
        "\n",
        "**Connection to AKIRA theory:**\n",
        "\n",
        "If AQ crystallize from accumulated patterns in the weight field, then:\n",
        "- Prompts with complex Zipf profiles activate more specific AQ\n",
        "- The response should reflect this specificity\n",
        "- Common-word prompts activate diffuse, general AQ\n",
        "- Rare-word prompts activate focused, specialized AQ\n",
        "\n",
        "The Zipf complexity of the prompt defines the **belief space** the model\n",
        "operates in. The model then generates responses that stay within\n",
        "that complexity regime."
      ]
    }
  ]
}
