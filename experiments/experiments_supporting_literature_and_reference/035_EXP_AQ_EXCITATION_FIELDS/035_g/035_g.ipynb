{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 035G: Phase Relationship Detection\n",
    "\n",
    "**AKIRA Project - Oscar Goldman - Shogu Research Group @ Datamutant.ai**\n",
    "\n",
    "---\n",
    "\n",
    "## Goal\n",
    "\n",
    "Test whether AQ have detectable phase structure, not just magnitude clustering.\n",
    "\n",
    "From `ACTION_QUANTA.md`:\n",
    "```\n",
    "AQ have four properties: magnitude, phase, frequency, coherence\n",
    "Phase enables bonding via alignment\n",
    "```\n",
    "\n",
    "This experiment addresses:\n",
    "1. **Phase extraction**: Can we detect phase structure in activation patterns?\n",
    "2. **Phase alignment**: Do components of bonded states show aligned phases?\n",
    "3. **Phase interference**: Do incompatible AQ show phase opposition?\n",
    "\n",
    "---\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "If AQ phase is real:\n",
    "1. Components of bonded states should have ALIGNED phases (low circular variance)\n",
    "2. Random AQ combinations should have HIGH phase variance\n",
    "3. Incompatible AQ (e.g., FLEE + APPROACH) should show phase opposition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment for Colab)\n",
    "# !pip install transformers torch numpy scikit-learn matplotlib seaborn scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "import warnings\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configuration for phase relationship experiment.\"\"\"\n",
    "    \n",
    "    model_name: str = \"gpt2-medium\"\n",
    "    model_path: str = \"gpt2-medium\"\n",
    "    \n",
    "    # Samples per category\n",
    "    samples_per_category: int = 50\n",
    "    \n",
    "    # Layers to analyze\n",
    "    layers_to_probe: List[int] = field(default_factory=lambda: [0, 4, 8, 12, 16, 20, 23])\n",
    "    \n",
    "    # Statistical parameters\n",
    "    random_seed: int = 42\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        np.random.seed(self.random_seed)\n",
    "        torch.manual_seed(self.random_seed)\n",
    "\n",
    "\n",
    "config = ExperimentConfig()\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"Layers to probe: {config.layers_to_probe}\")\n",
    "print(f\"Samples per category: {config.samples_per_category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Circular Statistics Functions\n",
    "\n",
    "Phase is circular (wraps around at 2*pi), so we need circular statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mean(phases: np.ndarray) -> float:\n",
    "    \"\"\"Compute circular mean of phases.\n",
    "    \n",
    "    Args:\n",
    "        phases: Array of phase values in radians\n",
    "        \n",
    "    Returns:\n",
    "        Circular mean in radians\n",
    "    \"\"\"\n",
    "    sin_sum = np.sum(np.sin(phases))\n",
    "    cos_sum = np.sum(np.cos(phases))\n",
    "    return np.arctan2(sin_sum, cos_sum)\n",
    "\n",
    "\n",
    "def circular_variance(phases: np.ndarray) -> float:\n",
    "    \"\"\"Compute circular variance of phases.\n",
    "    \n",
    "    Args:\n",
    "        phases: Array of phase values in radians\n",
    "        \n",
    "    Returns:\n",
    "        Circular variance (0 = perfectly aligned, 1 = uniform)\n",
    "    \"\"\"\n",
    "    n = len(phases)\n",
    "    sin_sum = np.sum(np.sin(phases))\n",
    "    cos_sum = np.sum(np.cos(phases))\n",
    "    R = np.sqrt(sin_sum**2 + cos_sum**2) / n\n",
    "    return 1 - R\n",
    "\n",
    "\n",
    "def circular_std(phases: np.ndarray) -> float:\n",
    "    \"\"\"Compute circular standard deviation.\n",
    "    \n",
    "    Args:\n",
    "        phases: Array of phase values in radians\n",
    "        \n",
    "    Returns:\n",
    "        Circular standard deviation\n",
    "    \"\"\"\n",
    "    var = circular_variance(phases)\n",
    "    return np.sqrt(-2 * np.log(1 - var)) if var < 1 else np.inf\n",
    "\n",
    "\n",
    "def rayleigh_test(phases: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"Rayleigh test for non-uniformity of circular distribution.\n",
    "    \n",
    "    Args:\n",
    "        phases: Array of phase values in radians\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (R statistic, p-value)\n",
    "    \"\"\"\n",
    "    n = len(phases)\n",
    "    sin_sum = np.sum(np.sin(phases))\n",
    "    cos_sum = np.sum(np.cos(phases))\n",
    "    R = np.sqrt(sin_sum**2 + cos_sum**2) / n\n",
    "    \n",
    "    # Rayleigh test statistic\n",
    "    Z = n * R**2\n",
    "    \n",
    "    # P-value approximation\n",
    "    p_value = np.exp(-Z) * (1 + (2*Z - Z**2) / (4*n) - \n",
    "                           (24*Z - 132*Z**2 + 76*Z**3 - 9*Z**4) / (288*n**2))\n",
    "    \n",
    "    return R, p_value\n",
    "\n",
    "\n",
    "def watson_u2_test(phases1: np.ndarray, phases2: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"Watson's U2 test for comparing two circular distributions.\n",
    "    \n",
    "    Args:\n",
    "        phases1: First set of phases\n",
    "        phases2: Second set of phases\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (U2 statistic, approximate p-value)\n",
    "    \"\"\"\n",
    "    # Combine and sort\n",
    "    n1, n2 = len(phases1), len(phases2)\n",
    "    N = n1 + n2\n",
    "    \n",
    "    all_phases = np.concatenate([phases1, phases2])\n",
    "    labels = np.concatenate([np.ones(n1), np.zeros(n2)])\n",
    "    \n",
    "    # Sort by phase\n",
    "    sorted_idx = np.argsort(all_phases)\n",
    "    sorted_labels = labels[sorted_idx]\n",
    "    \n",
    "    # Compute cumulative differences\n",
    "    d = np.zeros(N)\n",
    "    cum1 = 0\n",
    "    cum2 = 0\n",
    "    for i in range(N):\n",
    "        if sorted_labels[i] == 1:\n",
    "            cum1 += 1\n",
    "        else:\n",
    "            cum2 += 1\n",
    "        d[i] = cum1/n1 - cum2/n2\n",
    "    \n",
    "    # U2 statistic\n",
    "    d_bar = np.mean(d)\n",
    "    U2 = (n1 * n2 / N**2) * np.sum((d - d_bar)**2)\n",
    "    \n",
    "    # Approximate p-value (critical values from tables)\n",
    "    # U2 > 0.187 is significant at p < 0.05\n",
    "    if U2 > 0.268:\n",
    "        p_value = 0.01\n",
    "    elif U2 > 0.187:\n",
    "        p_value = 0.05\n",
    "    elif U2 > 0.152:\n",
    "        p_value = 0.10\n",
    "    else:\n",
    "        p_value = 0.50\n",
    "    \n",
    "    return U2, p_value\n",
    "\n",
    "\n",
    "def circular_correlation(phases1: np.ndarray, phases2: np.ndarray) -> float:\n",
    "    \"\"\"Compute circular-circular correlation.\n",
    "    \n",
    "    Args:\n",
    "        phases1: First set of phases\n",
    "        phases2: Second set of phases\n",
    "        \n",
    "    Returns:\n",
    "        Circular correlation coefficient\n",
    "    \"\"\"\n",
    "    sin1 = np.sin(phases1 - circular_mean(phases1))\n",
    "    sin2 = np.sin(phases2 - circular_mean(phases2))\n",
    "    \n",
    "    numerator = np.sum(sin1 * sin2)\n",
    "    denominator = np.sqrt(np.sum(sin1**2) * np.sum(sin2**2))\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "print(\"Circular statistics functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase Extraction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phase_hilbert(activation: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract phase using Hilbert transform.\n",
    "    \n",
    "    The Hilbert transform creates an analytic signal from which\n",
    "    we can extract instantaneous phase.\n",
    "    \n",
    "    Args:\n",
    "        activation: Activation vector\n",
    "        \n",
    "    Returns:\n",
    "        Phase vector (same shape as input)\n",
    "    \"\"\"\n",
    "    # Apply Hilbert transform\n",
    "    analytic_signal = hilbert(activation)\n",
    "    \n",
    "    # Extract phase\n",
    "    phase = np.angle(analytic_signal)\n",
    "    \n",
    "    return phase\n",
    "\n",
    "\n",
    "def extract_phase_pca(activation: np.ndarray, n_components: int = 2) -> np.ndarray:\n",
    "    \"\"\"Extract phase using PCA projection to 2D and computing angle.\n",
    "    \n",
    "    Args:\n",
    "        activation: Activation vector\n",
    "        n_components: Number of PCA components (2 for phase extraction)\n",
    "        \n",
    "    Returns:\n",
    "        Single phase value\n",
    "    \"\"\"\n",
    "    # This method works on multiple activations\n",
    "    # For single activation, just return angle of first two components\n",
    "    if len(activation.shape) == 1:\n",
    "        return np.arctan2(activation[1], activation[0])\n",
    "    else:\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        projected = pca.fit_transform(activation)\n",
    "        return np.arctan2(projected[:, 1], projected[:, 0])\n",
    "\n",
    "\n",
    "def extract_phase_fourier(activation: np.ndarray, n_components: int = 10) -> np.ndarray:\n",
    "    \"\"\"Extract phase from dominant Fourier components.\n",
    "    \n",
    "    Args:\n",
    "        activation: Activation vector\n",
    "        n_components: Number of Fourier components to use\n",
    "        \n",
    "    Returns:\n",
    "        Array of phases for dominant frequency components\n",
    "    \"\"\"\n",
    "    fft = np.fft.fft(activation)\n",
    "    \n",
    "    # Get phases of n_components largest magnitude components\n",
    "    magnitudes = np.abs(fft)\n",
    "    top_indices = np.argsort(magnitudes)[-n_components:]\n",
    "    \n",
    "    phases = np.angle(fft[top_indices])\n",
    "    \n",
    "    return phases\n",
    "\n",
    "\n",
    "print(\"Phase extraction functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Sets for Phase Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatible AQ pairs (should show phase alignment)\n",
    "COMPATIBLE_PAIRS = {\n",
    "    \"threat_flee\": {\n",
    "        \"prompts\": [\n",
    "            \"A dangerous fire threatens you and you must escape. You should\",\n",
    "            \"A predator is hunting you and you need to flee. You should\",\n",
    "            \"The building is collapsing and you must run away. You should\",\n",
    "            \"A venomous snake approaches and you should retreat. You should\",\n",
    "            \"The flood is rising and you need to evacuate. You should\",\n",
    "        ] * 10,  # Repeat to get enough samples\n",
    "        \"components\": [\"threat\", \"flee\"]\n",
    "    },\n",
    "    \"urgency_act\": {\n",
    "        \"prompts\": [\n",
    "            \"The deadline is now and you must act immediately. You should\",\n",
    "            \"Time is running out and you need to move now. You should\",\n",
    "            \"This is your last chance and you must take action. You should\",\n",
    "            \"The moment is here and you need to respond instantly. You should\",\n",
    "            \"There's no time left and you must do something now. You should\",\n",
    "        ] * 10,\n",
    "        \"components\": [\"urgency\", \"action\"]\n",
    "    },\n",
    "    \"proximity_reach\": {\n",
    "        \"prompts\": [\n",
    "            \"The goal is within arm's reach and you can grab it. You should\",\n",
    "            \"Safety is just steps away and you can get there. You should\",\n",
    "            \"The prize is right beside you and you can take it. You should\",\n",
    "            \"Help is nearby and you can access it easily. You should\",\n",
    "            \"The exit is close and you can reach it quickly. You should\",\n",
    "        ] * 10,\n",
    "        \"components\": [\"proximity\", \"reach\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Incompatible AQ pairs (should show phase opposition)\n",
    "INCOMPATIBLE_PAIRS = {\n",
    "    \"flee_approach\": {\n",
    "        \"prompts\": [\n",
    "            \"You must run away but also move closer. You should\",\n",
    "            \"Escape is necessary but you need to approach. You should\",\n",
    "            \"Flee immediately but also advance forward. You should\",\n",
    "            \"Retreat quickly but also move toward it. You should\",\n",
    "            \"Get away fast but also get closer. You should\",\n",
    "        ] * 10,\n",
    "        \"components\": [\"flee\", \"approach\"]\n",
    "    },\n",
    "    \"urgent_wait\": {\n",
    "        \"prompts\": [\n",
    "            \"Act immediately but also wait patiently. You should\",\n",
    "            \"This is urgent but you must be patient. You should\",\n",
    "            \"Move now but also stay still. You should\",\n",
    "            \"Time is critical but delay is needed. You should\",\n",
    "            \"Rush immediately but also hold back. You should\",\n",
    "        ] * 10,\n",
    "        \"components\": [\"urgent\", \"wait\"]\n",
    "    },\n",
    "    \"threat_safe\": {\n",
    "        \"prompts\": [\n",
    "            \"Danger is present but everything is safe. You should\",\n",
    "            \"The threat is real but there's no risk. You should\",\n",
    "            \"It's hazardous but completely secure. You should\",\n",
    "            \"A menace approaches but all is well. You should\",\n",
    "            \"Peril exists but safety is assured. You should\",\n",
    "        ] * 10,\n",
    "        \"components\": [\"threat\", \"safe\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Random/control pairs (should show random phase distribution)\n",
    "RANDOM_PAIRS = {\n",
    "    \"random_1\": {\n",
    "        \"prompts\": [\n",
    "            \"The weather is nice and books are interesting. You should\",\n",
    "            \"Mathematics is useful and music is pleasant. You should\",\n",
    "            \"Trees are tall and water is wet. You should\",\n",
    "            \"Science explains things and art expresses them. You should\",\n",
    "            \"History teaches us and geography shows us. You should\",\n",
    "        ] * 10,\n",
    "        \"components\": [\"random\", \"random\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Compatible pairs: {list(COMPATIBLE_PAIRS.keys())}\")\n",
    "print(f\"Incompatible pairs: {list(INCOMPATIBLE_PAIRS.keys())}\")\n",
    "print(f\"Random pairs: {list(RANDOM_PAIRS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Loading and Activation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading {config.model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.model_path,\n",
    "    output_hidden_states=True,\n",
    "    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Model loaded: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(prompt: str, model: nn.Module, tokenizer: AutoTokenizer, \n",
    "                   layers: List[int]) -> Dict[int, np.ndarray]:\n",
    "    \"\"\"Get last token activation at specified layers.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input text\n",
    "        model: The model\n",
    "        tokenizer: The tokenizer\n",
    "        layers: List of layer indices\n",
    "        \n",
    "    Returns:\n",
    "        Dict mapping layer index to activation vector\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    activations = {}\n",
    "    for layer_idx in layers:\n",
    "        h = outputs.hidden_states[layer_idx][0, -1, :].cpu().float().numpy()\n",
    "        activations[layer_idx] = h\n",
    "    \n",
    "    return activations\n",
    "\n",
    "\n",
    "print(\"Activation extraction ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Phase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_phase_alignment(prompts: List[str], model, tokenizer, \n",
    "                            layers: List[int]) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze phase alignment across prompts.\n",
    "    \n",
    "    Args:\n",
    "        prompts: List of prompts\n",
    "        model: The model\n",
    "        tokenizer: The tokenizer\n",
    "        layers: Layers to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dict with phase analysis results\n",
    "    \"\"\"\n",
    "    results = {\"layers\": {}}\n",
    "    \n",
    "    # Get activations for all prompts\n",
    "    all_activations = {layer: [] for layer in layers}\n",
    "    \n",
    "    for prompt in tqdm(prompts[:config.samples_per_category], desc=\"Getting activations\"):\n",
    "        acts = get_activation(prompt, model, tokenizer, layers)\n",
    "        for layer in layers:\n",
    "            all_activations[layer].append(acts[layer])\n",
    "    \n",
    "    # Analyze phase at each layer\n",
    "    for layer in layers:\n",
    "        activations = np.array(all_activations[layer])\n",
    "        \n",
    "        # Extract phases using multiple methods\n",
    "        # Method 1: Hilbert transform (per dimension, then aggregate)\n",
    "        hilbert_phases = []\n",
    "        for act in activations:\n",
    "            phase = extract_phase_hilbert(act)\n",
    "            # Use mean phase across dimensions\n",
    "            hilbert_phases.append(circular_mean(phase))\n",
    "        hilbert_phases = np.array(hilbert_phases)\n",
    "        \n",
    "        # Method 2: Fourier dominant component\n",
    "        fourier_phases = []\n",
    "        for act in activations:\n",
    "            phase = extract_phase_fourier(act, n_components=1)\n",
    "            fourier_phases.append(phase[0])\n",
    "        fourier_phases = np.array(fourier_phases)\n",
    "        \n",
    "        # Compute statistics\n",
    "        hilbert_var = circular_variance(hilbert_phases)\n",
    "        hilbert_R, hilbert_p = rayleigh_test(hilbert_phases)\n",
    "        \n",
    "        fourier_var = circular_variance(fourier_phases)\n",
    "        fourier_R, fourier_p = rayleigh_test(fourier_phases)\n",
    "        \n",
    "        results[\"layers\"][layer] = {\n",
    "            \"hilbert\": {\n",
    "                \"circular_variance\": float(hilbert_var),\n",
    "                \"rayleigh_R\": float(hilbert_R),\n",
    "                \"rayleigh_p\": float(hilbert_p),\n",
    "                \"mean_phase\": float(circular_mean(hilbert_phases)),\n",
    "                \"circular_std\": float(circular_std(hilbert_phases))\n",
    "            },\n",
    "            \"fourier\": {\n",
    "                \"circular_variance\": float(fourier_var),\n",
    "                \"rayleigh_R\": float(fourier_R),\n",
    "                \"rayleigh_p\": float(fourier_p),\n",
    "                \"mean_phase\": float(circular_mean(fourier_phases)),\n",
    "                \"circular_std\": float(circular_std(fourier_phases))\n",
    "            },\n",
    "            \"phases_hilbert\": hilbert_phases.tolist(),\n",
    "            \"phases_fourier\": fourier_phases.tolist()\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Phase analysis function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis for all prompt categories\n",
    "print(\"Analyzing phase relationships...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "RESULTS = {\n",
    "    \"compatible\": {},\n",
    "    \"incompatible\": {},\n",
    "    \"random\": {}\n",
    "}\n",
    "\n",
    "# Compatible pairs\n",
    "print(\"\\nCompatible pairs (expecting LOW phase variance, significant Rayleigh):\")\n",
    "for name, data in COMPATIBLE_PAIRS.items():\n",
    "    print(f\"  Analyzing {name}...\")\n",
    "    RESULTS[\"compatible\"][name] = analyze_phase_alignment(\n",
    "        data[\"prompts\"], model, tokenizer, config.layers_to_probe\n",
    "    )\n",
    "\n",
    "# Incompatible pairs\n",
    "print(\"\\nIncompatible pairs (expecting phase opposition):\")\n",
    "for name, data in INCOMPATIBLE_PAIRS.items():\n",
    "    print(f\"  Analyzing {name}...\")\n",
    "    RESULTS[\"incompatible\"][name] = analyze_phase_alignment(\n",
    "        data[\"prompts\"], model, tokenizer, config.layers_to_probe\n",
    "    )\n",
    "\n",
    "# Random pairs\n",
    "print(\"\\nRandom pairs (expecting HIGH phase variance, non-significant Rayleigh):\")\n",
    "for name, data in RANDOM_PAIRS.items():\n",
    "    print(f\"  Analyzing {name}...\")\n",
    "    RESULTS[\"random\"][name] = analyze_phase_alignment(\n",
    "        data[\"prompts\"], model, tokenizer, config.layers_to_probe\n",
    "    )\n",
    "\n",
    "print(\"\\nAnalysis complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE RELATIONSHIP ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find best layer (lowest variance for compatible pairs)\n",
    "best_layer = None\n",
    "best_variance = float('inf')\n",
    "\n",
    "for layer in config.layers_to_probe:\n",
    "    variances = []\n",
    "    for name, results in RESULTS[\"compatible\"].items():\n",
    "        variances.append(results[\"layers\"][layer][\"hilbert\"][\"circular_variance\"])\n",
    "    mean_var = np.mean(variances)\n",
    "    if mean_var < best_variance:\n",
    "        best_variance = mean_var\n",
    "        best_layer = layer\n",
    "\n",
    "print(f\"\\nBest layer for phase alignment: {best_layer}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\nResults at Layer {best_layer}:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Category':<20} {'Type':<15} {'Circ.Var':<12} {'Rayleigh R':<12} {'p-value':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compatible\n",
    "compatible_sig_count = 0\n",
    "for name, results in RESULTS[\"compatible\"].items():\n",
    "    layer_data = results[\"layers\"][best_layer][\"hilbert\"]\n",
    "    sig = \"***\" if layer_data[\"rayleigh_p\"] < 0.001 else \"**\" if layer_data[\"rayleigh_p\"] < 0.01 else \"*\" if layer_data[\"rayleigh_p\"] < 0.05 else \"\"\n",
    "    if layer_data[\"rayleigh_p\"] < 0.05:\n",
    "        compatible_sig_count += 1\n",
    "    print(f\"{name:<20} {'Compatible':<15} {layer_data['circular_variance']:<12.4f} {layer_data['rayleigh_R']:<12.4f} {layer_data['rayleigh_p']:<10.4f} {sig}\")\n",
    "\n",
    "# Incompatible\n",
    "print()\n",
    "for name, results in RESULTS[\"incompatible\"].items():\n",
    "    layer_data = results[\"layers\"][best_layer][\"hilbert\"]\n",
    "    sig = \"***\" if layer_data[\"rayleigh_p\"] < 0.001 else \"**\" if layer_data[\"rayleigh_p\"] < 0.01 else \"*\" if layer_data[\"rayleigh_p\"] < 0.05 else \"\"\n",
    "    print(f\"{name:<20} {'Incompatible':<15} {layer_data['circular_variance']:<12.4f} {layer_data['rayleigh_R']:<12.4f} {layer_data['rayleigh_p']:<10.4f} {sig}\")\n",
    "\n",
    "# Random\n",
    "print()\n",
    "for name, results in RESULTS[\"random\"].items():\n",
    "    layer_data = results[\"layers\"][best_layer][\"hilbert\"]\n",
    "    sig = \"***\" if layer_data[\"rayleigh_p\"] < 0.001 else \"**\" if layer_data[\"rayleigh_p\"] < 0.01 else \"*\" if layer_data[\"rayleigh_p\"] < 0.05 else \"\"\n",
    "    print(f\"{name:<20} {'Random':<15} {layer_data['circular_variance']:<12.4f} {layer_data['rayleigh_R']:<12.4f} {layer_data['rayleigh_p']:<10.4f} {sig}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"\\n*** p < 0.001, ** p < 0.01, * p < 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polar plots of phase distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Plot compatible pairs\n",
    "for idx, (name, results) in enumerate(RESULTS[\"compatible\"].items()):\n",
    "    if idx >= 3:\n",
    "        break\n",
    "    ax = axes[0, idx]\n",
    "    phases = np.array(results[\"layers\"][best_layer][\"phases_hilbert\"])\n",
    "    ax.hist(phases, bins=36, density=True, alpha=0.7, color='green')\n",
    "    ax.set_title(f\"Compatible: {name}\\nVar={results['layers'][best_layer]['hilbert']['circular_variance']:.3f}\")\n",
    "\n",
    "# Plot incompatible pairs\n",
    "for idx, (name, results) in enumerate(RESULTS[\"incompatible\"].items()):\n",
    "    if idx >= 3:\n",
    "        break\n",
    "    ax = axes[1, idx]\n",
    "    phases = np.array(results[\"layers\"][best_layer][\"phases_hilbert\"])\n",
    "    ax.hist(phases, bins=36, density=True, alpha=0.7, color='red')\n",
    "    ax.set_title(f\"Incompatible: {name}\\nVar={results['layers'][best_layer]['hilbert']['circular_variance']:.3f}\")\n",
    "\n",
    "plt.suptitle(f\"035G: Phase Distributions at Layer {best_layer}\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"035G_phase_distributions.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: 035G_phase_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase variance across layers\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Compatible\n",
    "for name, results in RESULTS[\"compatible\"].items():\n",
    "    variances = [results[\"layers\"][l][\"hilbert\"][\"circular_variance\"] for l in config.layers_to_probe]\n",
    "    ax.plot(config.layers_to_probe, variances, 'o-', label=f\"Compatible: {name}\", color='green', alpha=0.7)\n",
    "\n",
    "# Incompatible\n",
    "for name, results in RESULTS[\"incompatible\"].items():\n",
    "    variances = [results[\"layers\"][l][\"hilbert\"][\"circular_variance\"] for l in config.layers_to_probe]\n",
    "    ax.plot(config.layers_to_probe, variances, 's--', label=f\"Incompatible: {name}\", color='red', alpha=0.7)\n",
    "\n",
    "# Random\n",
    "for name, results in RESULTS[\"random\"].items():\n",
    "    variances = [results[\"layers\"][l][\"hilbert\"][\"circular_variance\"] for l in config.layers_to_probe]\n",
    "    ax.plot(config.layers_to_probe, variances, '^:', label=f\"Random: {name}\", color='gray', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel(\"Layer\")\n",
    "ax.set_ylabel(\"Circular Variance (lower = more aligned)\")\n",
    "ax.set_title(\"Phase Alignment by Layer and Category Type\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"035G_phase_variance_by_layer.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: 035G_phase_variance_by_layer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT 035G: PHASE RELATIONSHIPS CONCLUSIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nExperiment Configuration:\")\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  Samples per category: {config.samples_per_category}\")\n",
    "print(f\"  Layers analyzed: {config.layers_to_probe}\")\n",
    "\n",
    "# Compute success criteria\n",
    "n_compatible = len(RESULTS[\"compatible\"])\n",
    "n_compatible_sig = compatible_sig_count\n",
    "\n",
    "# Compare variances\n",
    "compatible_vars = []\n",
    "incompatible_vars = []\n",
    "random_vars = []\n",
    "\n",
    "for results in RESULTS[\"compatible\"].values():\n",
    "    compatible_vars.append(results[\"layers\"][best_layer][\"hilbert\"][\"circular_variance\"])\n",
    "for results in RESULTS[\"incompatible\"].values():\n",
    "    incompatible_vars.append(results[\"layers\"][best_layer][\"hilbert\"][\"circular_variance\"])\n",
    "for results in RESULTS[\"random\"].values():\n",
    "    random_vars.append(results[\"layers\"][best_layer][\"hilbert\"][\"circular_variance\"])\n",
    "\n",
    "mean_compatible_var = np.mean(compatible_vars)\n",
    "mean_incompatible_var = np.mean(incompatible_vars)\n",
    "mean_random_var = np.mean(random_vars)\n",
    "\n",
    "print(f\"\\nPhase Variance Summary (Layer {best_layer}):\")\n",
    "print(f\"  Compatible pairs:   {mean_compatible_var:.4f}\")\n",
    "print(f\"  Incompatible pairs: {mean_incompatible_var:.4f}\")\n",
    "print(f\"  Random pairs:       {mean_random_var:.4f}\")\n",
    "\n",
    "print(f\"\\nHypothesis Testing:\")\n",
    "print(f\"  1. Compatible < Random variance: {mean_compatible_var < mean_random_var}\")\n",
    "print(f\"  2. Rayleigh significant for compatible: {n_compatible_sig}/{n_compatible}\")\n",
    "\n",
    "# Overall conclusion\n",
    "success = (mean_compatible_var < mean_random_var) and (n_compatible_sig >= n_compatible // 2)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "if success:\n",
    "    print(\"CONCLUSION: Evidence SUPPORTS AQ phase alignment hypothesis.\")\n",
    "    print(\"Compatible AQ pairs show lower phase variance than random pairs.\")\n",
    "else:\n",
    "    print(\"CONCLUSION: Evidence does NOT clearly support AQ phase hypothesis.\")\n",
    "    print(\"Phase structure may require different extraction methods or more data.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "def make_serializable(obj):\n",
    "    \"\"\"Convert numpy types for JSON.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): make_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "results_output = {\n",
    "    \"config\": {\n",
    "        \"model\": config.model_name,\n",
    "        \"samples_per_category\": config.samples_per_category,\n",
    "        \"layers\": config.layers_to_probe\n",
    "    },\n",
    "    \"results\": make_serializable(RESULTS),\n",
    "    \"summary\": {\n",
    "        \"best_layer\": best_layer,\n",
    "        \"mean_compatible_variance\": float(mean_compatible_var),\n",
    "        \"mean_incompatible_variance\": float(mean_incompatible_var),\n",
    "        \"mean_random_variance\": float(mean_random_var),\n",
    "        \"compatible_rayleigh_significant\": n_compatible_sig,\n",
    "        \"conclusion\": \"SUPPORTS\" if success else \"DOES NOT SUPPORT\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"035G_results.json\", \"w\") as f:\n",
    "    json.dump(results_output, f, indent=2)\n",
    "\n",
    "print(\"Results saved to 035G_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
