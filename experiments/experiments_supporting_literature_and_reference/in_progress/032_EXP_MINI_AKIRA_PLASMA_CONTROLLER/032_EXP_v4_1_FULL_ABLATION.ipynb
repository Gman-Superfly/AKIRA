{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 032 v4.1: Full Architecture Ablation\n",
    "\n",
    "**Purpose**: Comprehensive ablation testing ALL architectural variants.\n",
    "\n",
    "**Key Change from v2.3**: NO control signal passed to models.\n",
    "We replicate the winning 032 setup (pure prediction) and test architecture variations.\n",
    "\n",
    "**v4.1 Fix**: Proper batch size handling - drop incomplete batches to maintain\n",
    "consistent tensor shapes for history management. This is important for wormhole\n",
    "attention which needs persistent history across batches.\n",
    "\n",
    "## Ablation Dimensions\n",
    "\n",
    "### 1. Number of Spectral Bands\n",
    "- **2-band**: Low/High frequency split\n",
    "- **3-band**: Low/Mid/High (like 033 experiment)\n",
    "- **7-band**: Original SBM design (log-spaced radial masks)\n",
    "\n",
    "### 2. Attention Types (from 033 experiment)\n",
    "- **None**: No attention (pure spectral processing)\n",
    "- **Temporal**: Per-position Top-K temporal attention (object permanence)\n",
    "- **Neighbor**: 3x3 local spatial attention (local physics)\n",
    "- **Wormhole**: Sparse similarity-gated non-local attention (teleportation)\n",
    "- **Full**: All three attention types\n",
    "\n",
    "### 3. Baselines\n",
    "- **Flat ConvNet**: Direct spatial convolutions\n",
    "\n",
    "## Models Tested (12 total)\n",
    "\n",
    "| Model | Bands | Temporal | Neighbor | Wormhole |\n",
    "|-------|-------|----------|----------|----------|\n",
    "| SBM_2B_None | 2 | - | - | - |\n",
    "| SBM_3B_None | 3 | - | - | - |\n",
    "| SBM_7B_None | 7 | - | - | - |\n",
    "| SBM_3B_Temporal | 3 | Y | - | - |\n",
    "| SBM_3B_Neighbor | 3 | - | Y | - |\n",
    "| SBM_3B_Wormhole | 3 | - | - | Y |\n",
    "| SBM_3B_TempNeigh | 3 | Y | Y | - |\n",
    "| SBM_3B_Full | 3 | Y | Y | Y |\n",
    "| SBM_7B_Temporal | 7 | Y | - | - |\n",
    "| SBM_7B_Full | 7 | Y | Y | Y |\n",
    "| Flat_Baseline | - | - | - | - |\n",
    "| Flat_WithAttn | - | Y | Y | - |\n",
    "\n",
    "**Run on Colab with GPU**: Runtime -> Change runtime type -> A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "GRID_SIZE = 64\n",
    "EPOCHS = 50\n",
    "DIFFICULTY = \"turbulent\"\n",
    "PREDICT_DELTA = True\n",
    "PREDICTION_HORIZON = 3  # Like original winning experiment\n",
    "NUM_TRAJECTORIES = 100\n",
    "TRAJECTORY_LENGTH = 100\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "\n",
    "# Attention config (from 033)\n",
    "HISTORY_LEN = 8\n",
    "TOP_K_TEMPORAL = 4\n",
    "TEMPORAL_DECAY = 0.95\n",
    "NEIGHBOR_RANGE = 3\n",
    "WORMHOLE_THRESHOLD = 0.9995\n",
    "WORMHOLE_MAX_CONN = 4\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Grid: {GRID_SIZE}x{GRID_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Difficulty: {DIFFICULTY}\")\n",
    "print(f\"Prediction: delta t+{PREDICTION_HORIZON}\")\n",
    "print(f\"\\nNO CONTROL SIGNAL - Pure prediction task (like winning 032)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment (Same as original 032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import math\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class PlasmaConfig:\n",
    "    height: int = 64\n",
    "    width: int = 64\n",
    "    diffusion: float = 0.25\n",
    "    advection: float = 0.08\n",
    "    noise_std: float = 0.02\n",
    "    disturbance_prob: float = 0.1\n",
    "    disturbance_strength: float = 0.15\n",
    "    num_vortices: int = 3\n",
    "    vortex_strength: float = 0.1\n",
    "    shear_strength: float = 0.05\n",
    "    multiscale_noise: bool = True\n",
    "    num_actuators: int = 9\n",
    "    _base_actuator_sigma: float = 5.0\n",
    "    device: str = \"cpu\"\n",
    "    dtype: torch.dtype = torch.float32\n",
    "    \n",
    "    @property\n",
    "    def actuator_sigma(self) -> float:\n",
    "        return self._base_actuator_sigma * min(self.height, self.width) / 64.0\n",
    "    \n",
    "    @classmethod\n",
    "    def turbulent(cls, device: str = \"cpu\", size: int = 64):\n",
    "        return cls(height=size, width=size, diffusion=0.3, advection=0.12, noise_std=0.03,\n",
    "                   disturbance_prob=0.25, disturbance_strength=0.3,\n",
    "                   num_vortices=3, vortex_strength=0.15, shear_strength=0.08,\n",
    "                   multiscale_noise=True, num_actuators=9, device=device)\n",
    "    \n",
    "    @classmethod\n",
    "    def medium(cls, device: str = \"cpu\", size: int = 64):\n",
    "        return cls(height=size, width=size, device=device)\n",
    "\n",
    "\n",
    "class TurbulentPlasmaEnv:\n",
    "    def __init__(self, cfg: PlasmaConfig):\n",
    "        self.cfg = cfg\n",
    "        self.device = torch.device(cfg.device)\n",
    "        self.dtype = cfg.dtype\n",
    "        self._actuator_maps = self._build_actuator_maps()\n",
    "        self._vortex_flow = self._build_vortex_flow()\n",
    "        self._shear_flow = self._build_shear_flow()\n",
    "    \n",
    "    def _build_actuator_maps(self) -> torch.Tensor:\n",
    "        h, w = self.cfg.height, self.cfg.width\n",
    "        grid_n = int(math.ceil(math.sqrt(self.cfg.num_actuators)))\n",
    "        centers_y = torch.linspace(h * 0.2, h * 0.8, grid_n, device=self.device, dtype=self.dtype)\n",
    "        centers_x = torch.linspace(w * 0.2, w * 0.8, grid_n, device=self.device, dtype=self.dtype)\n",
    "        centers = torch.cartesian_prod(centers_y, centers_x)[:self.cfg.num_actuators]\n",
    "        sig2 = self.cfg.actuator_sigma ** 2\n",
    "        yy, xx = torch.meshgrid(\n",
    "            torch.arange(h, device=self.device, dtype=self.dtype),\n",
    "            torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
    "        bumps = [torch.exp(-((yy - cy) ** 2 + (xx - cx) ** 2) / (2 * sig2)) for cy, cx in centers]\n",
    "        return torch.stack(bumps, dim=0)\n",
    "    \n",
    "    def _build_vortex_flow(self):\n",
    "        if self.cfg.num_vortices == 0: return None, None\n",
    "        h, w = self.cfg.height, self.cfg.width\n",
    "        torch.manual_seed(42)  # Reproducible vortex positions\n",
    "        centers_y = torch.rand(self.cfg.num_vortices, device=self.device) * (h * 0.6) + (h * 0.2)\n",
    "        centers_x = torch.rand(self.cfg.num_vortices, device=self.device) * (w * 0.6) + (w * 0.2)\n",
    "        yy, xx = torch.meshgrid(torch.arange(h, device=self.device, dtype=self.dtype),\n",
    "                                torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
    "        vy, vx = torch.zeros_like(yy), torch.zeros_like(xx)\n",
    "        scale = min(h, w) / 64.0\n",
    "        for i in range(self.cfg.num_vortices):\n",
    "            dy, dx = yy - centers_y[i], xx - centers_x[i]\n",
    "            r2 = dy**2 + dx**2 + 1e-6\n",
    "            decay = torch.exp(-r2 / (2 * (10 * scale)**2))\n",
    "            sign = 1 if i % 2 == 0 else -1\n",
    "            vy += sign * self.cfg.vortex_strength * (-dx) / torch.sqrt(r2) * decay\n",
    "            vx += sign * self.cfg.vortex_strength * dy / torch.sqrt(r2) * decay\n",
    "        return vy, vx\n",
    "    \n",
    "    def _build_shear_flow(self):\n",
    "        if self.cfg.shear_strength == 0: return None, None\n",
    "        h, w = self.cfg.height, self.cfg.width\n",
    "        yy, _ = torch.meshgrid(torch.arange(h, device=self.device, dtype=self.dtype),\n",
    "                               torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
    "        return torch.zeros_like(yy), self.cfg.shear_strength * torch.sin(2 * math.pi * yy / h)\n",
    "    \n",
    "    def _apply_flow(self, field, vy, vx):\n",
    "        B, C, H, W = field.shape\n",
    "        yy, xx = torch.meshgrid(torch.linspace(-1, 1, H, device=self.device),\n",
    "                                torch.linspace(-1, 1, W, device=self.device), indexing=\"ij\")\n",
    "        grid = torch.stack([xx - vx/(W/2), yy - vy/(H/2)], dim=-1).unsqueeze(0).expand(B, -1, -1, -1)\n",
    "        return F.grid_sample(field, grid, mode='bilinear', padding_mode='border', align_corners=True)\n",
    "    \n",
    "    def _multiscale_noise(self, shape):\n",
    "        B, C, H, W = shape\n",
    "        noise = torch.zeros(shape, device=self.device, dtype=self.dtype)\n",
    "        for scale in [1, 2, 4, 8]:\n",
    "            hs, ws = H // scale, W // scale\n",
    "            if hs < 4: continue\n",
    "            coarse = torch.randn(B, C, hs, ws, device=self.device, dtype=self.dtype)\n",
    "            noise += F.interpolate(coarse, size=(H, W), mode='bilinear', align_corners=False) * (self.cfg.noise_std / scale)\n",
    "        return noise\n",
    "    \n",
    "    def reset(self, batch_size=1):\n",
    "        h, w = self.cfg.height, self.cfg.width\n",
    "        cx = torch.randint(int(w*0.3), int(w*0.7), (batch_size,), device=self.device)\n",
    "        cy = torch.randint(int(h*0.3), int(h*0.7), (batch_size,), device=self.device)\n",
    "        yy, xx = torch.meshgrid(torch.arange(h, device=self.device, dtype=self.dtype),\n",
    "                                torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
    "        sig2 = (self.cfg.actuator_sigma * 1.5) ** 2\n",
    "        field = torch.zeros(batch_size, 1, h, w, device=self.device, dtype=self.dtype)\n",
    "        for b in range(batch_size):\n",
    "            field[b, 0] = torch.exp(-((yy - cy[b].float())**2 + (xx - cx[b].float())**2) / (2*sig2))\n",
    "        return field\n",
    "    \n",
    "    def step(self, field, control, noise=True):\n",
    "        B = field.shape[0]\n",
    "        # Diffusion\n",
    "        lap = (F.pad(field, (0,0,1,0))[:,:,:-1,:] + F.pad(field, (0,0,0,1))[:,:,1:,:] +\n",
    "               F.pad(field, (1,0,0,0))[:,:,:,:-1] + F.pad(field, (0,1,0,0))[:,:,:,1:]) - 4*field\n",
    "        diffused = field + self.cfg.diffusion * lap\n",
    "        # Advection\n",
    "        advected = torch.roll(diffused, shifts=(1,-1), dims=(2,3)) * self.cfg.advection + diffused * (1 - self.cfg.advection)\n",
    "        if self._vortex_flow[0] is not None:\n",
    "            advected = self._apply_flow(advected, self._vortex_flow[0], self._vortex_flow[1])\n",
    "        if self._shear_flow[0] is not None:\n",
    "            advected = self._apply_flow(advected, self._shear_flow[0], self._shear_flow[1])\n",
    "        # Actuators\n",
    "        force = torch.einsum('ba,ahw->bhw', control, self._actuator_maps).unsqueeze(1)\n",
    "        next_field = advected + force\n",
    "        # Noise\n",
    "        if noise:\n",
    "            next_field = next_field + (self._multiscale_noise(next_field.shape) if self.cfg.multiscale_noise \n",
    "                                       else torch.randn_like(next_field) * self.cfg.noise_std)\n",
    "        return torch.clamp(next_field, -1, 1)\n",
    "\n",
    "\n",
    "def generate_trajectories_no_control(env, num_traj, traj_len, control_scale=0.1, horizon=1):\n",
    "    \"\"\"Generate data WITHOUT returning control - pure prediction task.\"\"\"\n",
    "    all_fields, all_next = [], []\n",
    "    for _ in range(num_traj):\n",
    "        field = env.reset(1)\n",
    "        traj = [field.clone()]\n",
    "        for _ in range(traj_len + horizon):\n",
    "            # Control still affects physics, but NOT passed to model\n",
    "            ctrl = torch.clamp(torch.randn(1, env.cfg.num_actuators, device=env.device) * control_scale, -1, 1)\n",
    "            traj.append(env.step(field, ctrl).clone())\n",
    "            field = traj[-1].detach()\n",
    "        for t in range(traj_len):\n",
    "            all_fields.append(traj[t])\n",
    "            all_next.append(traj[t + horizon])\n",
    "    return torch.cat(all_fields), torch.cat(all_next)\n",
    "\n",
    "print(\"Environment defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attention Modules (from 033)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TEMPORAL ATTENTION: Per-position Top-K (object permanence)\n",
    "# Each (i,j) attends to its OWN history at (i,j,t'<t)\n",
    "# ============================================================================\n",
    "\n",
    "class PerPositionTemporalAttention(nn.Module):\n",
    "    \"\"\"Per-position temporal attention with Top-K selection.\n",
    "    \n",
    "    Key insight: Each spatial position tracks its own history,\n",
    "    NOT a pooled summary. This enables proper object tracking.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_dim: int, attn_dim: int, top_k: int = 4, \n",
    "                 decay_rate: float = 0.95, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.top_k = top_k\n",
    "        self.decay_rate = decay_rate\n",
    "        self.device = device\n",
    "        \n",
    "        self.W_q = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_k = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_v = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_o = nn.Linear(attn_dim, feature_dim, bias=False)\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, query: torch.Tensor, history: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: Current features [B, H, W, D]\n",
    "            history: Past features [B, T, H, W, D]\n",
    "        Returns:\n",
    "            output: Attended features [B, H, W, D]\n",
    "        \"\"\"\n",
    "        B, H, W, D = query.shape\n",
    "        T = history.shape[1]\n",
    "        \n",
    "        if T == 0:\n",
    "            return torch.zeros_like(query)\n",
    "        \n",
    "        # Project\n",
    "        Q = self.W_q(query)  # [B, H, W, attn_dim]\n",
    "        K = self.W_k(history)  # [B, T, H, W, attn_dim]\n",
    "        V = self.W_v(history)  # [B, T, H, W, attn_dim]\n",
    "        \n",
    "        # Reshape for per-position attention\n",
    "        Q_flat = Q.reshape(B * H * W, self.attn_dim)  # [BHW, attn_dim]\n",
    "        K_flat = K.permute(0, 2, 3, 1, 4).reshape(B * H * W, T, self.attn_dim)  # [BHW, T, attn_dim]\n",
    "        V_flat = V.permute(0, 2, 3, 1, 4).reshape(B * H * W, T, self.attn_dim)  # [BHW, T, attn_dim]\n",
    "        \n",
    "        # Attention scores\n",
    "        scores = torch.bmm(Q_flat.unsqueeze(1), K_flat.transpose(1, 2)).squeeze(1)  # [BHW, T]\n",
    "        scores = scores / math.sqrt(self.attn_dim)\n",
    "        \n",
    "        # Top-K selection\n",
    "        if self.top_k < T:\n",
    "            _, topk_idx = torch.topk(scores, self.top_k, dim=-1)\n",
    "            mask = torch.ones_like(scores, dtype=torch.bool)\n",
    "            mask.scatter_(-1, topk_idx, False)\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        # Temporal decay\n",
    "        time_offsets = torch.arange(T, device=query.device, dtype=torch.float32)\n",
    "        decay_weights = self.decay_rate ** (T - time_offsets)\n",
    "        scores = scores + torch.log(decay_weights.unsqueeze(0) + 1e-10)\n",
    "        \n",
    "        # Softmax and attend\n",
    "        attn = F.softmax(scores, dim=-1)  # [BHW, T]\n",
    "        output = torch.bmm(attn.unsqueeze(1), V_flat).squeeze(1)  # [BHW, attn_dim]\n",
    "        output = self.W_o(output)\n",
    "        \n",
    "        return output.reshape(B, H, W, D)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# NEIGHBOR ATTENTION: 3x3 local spatial (local physics)\n",
    "# ============================================================================\n",
    "\n",
    "class NeighborAttention(nn.Module):\n",
    "    \"\"\"8-connected neighbor attention for local physics.\n",
    "    \n",
    "    Models diffusion, collision, wavefront propagation.\n",
    "    Like a learned convolution but with attention weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_dim: int, attn_dim: int, layer_range: int = 3,\n",
    "                 device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.layer_range = layer_range\n",
    "        self.device = device\n",
    "        \n",
    "        self.W_q = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_k = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_v = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_o = nn.Linear(attn_dim, feature_dim, bias=False)\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, query: torch.Tensor, history: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: Current features [B, H, W, D]\n",
    "            history: Past features [B, T, H, W, D]\n",
    "        Returns:\n",
    "            output: Attended features [B, H, W, D]\n",
    "        \"\"\"\n",
    "        B, H, W, D = query.shape\n",
    "        T = history.shape[1]\n",
    "        \n",
    "        if T == 0:\n",
    "            return torch.zeros_like(query)\n",
    "        \n",
    "        # Use most recent frame for neighbor attention\n",
    "        key_frame = history[:, -1]  # [B, H, W, D]\n",
    "        \n",
    "        Q = self.W_q(query)  # [B, H, W, attn_dim]\n",
    "        K = self.W_k(key_frame)  # [B, H, W, attn_dim]\n",
    "        V = self.W_v(key_frame)  # [B, H, W, attn_dim]\n",
    "        \n",
    "        # Pad for boundary handling\n",
    "        K_padded = F.pad(K.permute(0, 3, 1, 2), (1, 1, 1, 1), mode='replicate').permute(0, 2, 3, 1)\n",
    "        V_padded = F.pad(V.permute(0, 3, 1, 2), (1, 1, 1, 1), mode='replicate').permute(0, 2, 3, 1)\n",
    "        \n",
    "        # 9 neighbors (self + 8-connected)\n",
    "        neighbor_offsets = [\n",
    "            (-1, -1), (-1, 0), (-1, 1),\n",
    "            (0, -1),  (0, 0),  (0, 1),\n",
    "            (1, -1),  (1, 0),  (1, 1)\n",
    "        ]\n",
    "        \n",
    "        K_neighbors = torch.zeros(B, H, W, 9, self.attn_dim, device=query.device)\n",
    "        V_neighbors = torch.zeros(B, H, W, 9, self.attn_dim, device=query.device)\n",
    "        \n",
    "        for n_idx, (di, dj) in enumerate(neighbor_offsets):\n",
    "            K_neighbors[:, :, :, n_idx, :] = K_padded[:, 1+di:H+1+di, 1+dj:W+1+dj, :]\n",
    "            V_neighbors[:, :, :, n_idx, :] = V_padded[:, 1+di:H+1+di, 1+dj:W+1+dj, :]\n",
    "        \n",
    "        # Compute attention\n",
    "        scores = torch.einsum('bhwd,bhwnd->bhwn', Q, K_neighbors) / math.sqrt(self.attn_dim)\n",
    "        attn = F.softmax(scores, dim=-1)  # [B, H, W, 9]\n",
    "        output = torch.einsum('bhwn,bhwnd->bhwd', attn, V_neighbors)\n",
    "        \n",
    "        return self.W_o(output)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# WORMHOLE ATTENTION: Sparse similarity-gated non-local (teleportation)\n",
    "# ============================================================================\n",
    "\n",
    "class WormholeAttention(nn.Module):\n",
    "    \"\"\"Sparse non-local attention via cosine similarity gating.\n",
    "    \n",
    "    Connects distant tokens based on content similarity.\n",
    "    Enables instant global synchronization and resonance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_dim: int, attn_dim: int, threshold: float = 0.9995,\n",
    "                 max_connections: int = 4, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.threshold = threshold\n",
    "        self.max_connections = max_connections\n",
    "        self.device = device\n",
    "        \n",
    "        self.W_q = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_k = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_v = nn.Linear(feature_dim, attn_dim, bias=False)\n",
    "        self.W_o = nn.Linear(attn_dim, feature_dim, bias=False)\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, query: torch.Tensor, history: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: Current features [B, H, W, D]\n",
    "            history: Past features [B, T, H, W, D]\n",
    "        Returns:\n",
    "            output: Attended features [B, H, W, D]\n",
    "        \"\"\"\n",
    "        B, H, W, D = query.shape\n",
    "        T = history.shape[1]\n",
    "        \n",
    "        if T == 0:\n",
    "            return torch.zeros_like(query)\n",
    "        \n",
    "        # Flatten spatial dimensions\n",
    "        Q = self.W_q(query).reshape(B, H * W, self.attn_dim)  # [B, HW, attn_dim]\n",
    "        K = self.W_k(history).reshape(B, T * H * W, self.attn_dim)  # [B, THW, attn_dim]\n",
    "        V = self.W_v(history).reshape(B, T * H * W, self.attn_dim)  # [B, THW, attn_dim]\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        Q_norm = F.normalize(Q, p=2, dim=-1)\n",
    "        K_norm = F.normalize(K, p=2, dim=-1)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        sim = torch.bmm(Q_norm, K_norm.transpose(1, 2))  # [B, HW, THW]\n",
    "        \n",
    "        # Top-K selection\n",
    "        K_conn = min(self.max_connections, T * H * W)\n",
    "        topk_sim, topk_idx = torch.topk(sim, K_conn, dim=-1)  # [B, HW, K]\n",
    "        \n",
    "        # Threshold mask\n",
    "        mask = topk_sim > self.threshold\n",
    "        \n",
    "        # Gather values\n",
    "        V_gathered = torch.gather(\n",
    "            V.unsqueeze(1).expand(-1, H * W, -1, -1),\n",
    "            2,\n",
    "            topk_idx.unsqueeze(-1).expand(-1, -1, -1, self.attn_dim)\n",
    "        )  # [B, HW, K, attn_dim]\n",
    "        \n",
    "        # Attention scores with threshold mask\n",
    "        scores = topk_sim / math.sqrt(self.attn_dim)\n",
    "        scores = scores.masked_fill(~mask, float('-inf'))\n",
    "        attn = F.softmax(scores, dim=-1)  # [B, HW, K]\n",
    "        \n",
    "        # Handle positions with no valid connections\n",
    "        valid_rows = mask.any(dim=-1)  # [B, HW]\n",
    "        attn = torch.where(\n",
    "            valid_rows.unsqueeze(-1),\n",
    "            attn,\n",
    "            torch.zeros_like(attn)\n",
    "        )\n",
    "        \n",
    "        output = torch.einsum('bhk,bhkd->bhd', attn, V_gathered)  # [B, HW, attn_dim]\n",
    "        output = self.W_o(output)\n",
    "        \n",
    "        return output.reshape(B, H, W, D)\n",
    "\n",
    "print(\"Attention modules defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spectral Band Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_radial_masks(h: int, w: int, num_bands: int, device: str) -> torch.Tensor:\n",
    "    \"\"\"Create radial frequency masks for spectral decomposition.\n",
    "    \n",
    "    Args:\n",
    "        h, w: Grid dimensions\n",
    "        num_bands: Number of frequency bands (2, 3, or 7)\n",
    "        device: Torch device\n",
    "    Returns:\n",
    "        masks: [num_bands, H, W] normalized masks\n",
    "    \"\"\"\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.linspace(-1, 1, h, device=device),\n",
    "        torch.linspace(-1, 1, w, device=device), indexing=\"ij\")\n",
    "    rr = torch.sqrt(yy**2 + xx**2).clamp(min=1e-6)\n",
    "    \n",
    "    # Different edge spacing for different band counts\n",
    "    if num_bands == 2:\n",
    "        # Simple low/high split at 0.5\n",
    "        edges = torch.tensor([0.0, 0.5, math.sqrt(2)], device=device)\n",
    "    elif num_bands == 3:\n",
    "        # Low/mid/high (like 033 experiment)\n",
    "        edges = torch.tensor([0.0, 0.3, 0.7, math.sqrt(2)], device=device)\n",
    "    else:\n",
    "        # Log-spaced for 7 bands (original SBM)\n",
    "        edges = torch.logspace(-3, math.log10(math.sqrt(2)), num_bands + 1, device=device)\n",
    "        edges[0] = 0.0\n",
    "    \n",
    "    masks = []\n",
    "    for i in range(num_bands):\n",
    "        lo, hi = edges[i], edges[i + 1]\n",
    "        mask = torch.sigmoid((rr - lo) * 20) * torch.sigmoid((hi - rr) * 20)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    masks = torch.stack(masks)\n",
    "    return masks / (masks.sum(0, keepdim=True) + 1e-8)\n",
    "\n",
    "\n",
    "# Visualize masks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 7, figsize=(14, 6))\n",
    "\n",
    "for row, (num_bands, name) in enumerate([(2, '2-band'), (3, '3-band'), (7, '7-band')]):\n",
    "    masks = make_radial_masks(64, 64, num_bands, 'cpu')\n",
    "    for i in range(7):\n",
    "        if i < num_bands:\n",
    "            axes[row, i].imshow(masks[i].numpy(), cmap='viridis')\n",
    "            axes[row, i].set_title(f'{name} band {i}')\n",
    "        else:\n",
    "            axes[row, i].axis('off')\n",
    "        axes[row, i].set_xticks([])\n",
    "        axes[row, i].set_yticks([])\n",
    "\n",
    "plt.suptitle('Spectral Band Masks Comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mask generation defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SBM Models with Configurable Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SBMConfig:\n",
    "    height: int = 64\n",
    "    width: int = 64\n",
    "    num_bands: int = 3\n",
    "    channels: int = 16\n",
    "    attn_dim: int = 32\n",
    "    history_len: int = 8\n",
    "    # Attention flags\n",
    "    use_temporal: bool = False\n",
    "    use_neighbor: bool = False\n",
    "    use_wormhole: bool = False\n",
    "    # Temporal config\n",
    "    top_k: int = 4\n",
    "    decay: float = 0.95\n",
    "    # Neighbor config\n",
    "    neighbor_range: int = 3\n",
    "    # Wormhole config\n",
    "    wormhole_threshold: float = 0.9995\n",
    "    wormhole_max_conn: int = 4\n",
    "    device: str = \"cpu\"\n",
    "\n",
    "\n",
    "class SBMWithAttention(nn.Module):\n",
    "    \"\"\"Spectral Belief Machine with configurable attention types.\n",
    "    \n",
    "    NO CONTROL SIGNAL - pure prediction like winning 032 experiment.\n",
    "    \n",
    "    Supports:\n",
    "    - Variable band count (2, 3, or 7)\n",
    "    - Per-position temporal attention (from 033)\n",
    "    - Neighbor attention (from 033)\n",
    "    - Wormhole attention (from 033)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: SBMConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Spectral masks\n",
    "        self.register_buffer(\"masks\", make_radial_masks(\n",
    "            cfg.height, cfg.width, cfg.num_bands, cfg.device))\n",
    "        self.register_buffer(\"window\", torch.ones(cfg.height, cfg.width, device=cfg.device))\n",
    "        \n",
    "        # Band processing blocks: input = 2 (real/imag)\n",
    "        self.bands = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(2, cfg.channels, 3, padding=1), nn.GELU(),\n",
    "                nn.Conv2d(cfg.channels, cfg.channels, 3, padding=1), nn.GELU(),\n",
    "                nn.Conv2d(cfg.channels, 2, 1),\n",
    "            ) for _ in range(cfg.num_bands)\n",
    "        ])\n",
    "        \n",
    "        # Feature dimension for attention (2 channels per band -> flatten)\n",
    "        self.feat_dim = cfg.num_bands * 2 * 4 * 4  # 2x2 pool per band, 2 channels\n",
    "        \n",
    "        # Optional attention modules\n",
    "        if cfg.use_temporal:\n",
    "            self.temporal_attn = PerPositionTemporalAttention(\n",
    "                feature_dim=2,  # Per band: real/imag\n",
    "                attn_dim=cfg.attn_dim,\n",
    "                top_k=cfg.top_k,\n",
    "                decay_rate=cfg.decay,\n",
    "                device=cfg.device\n",
    "            )\n",
    "        \n",
    "        if cfg.use_neighbor:\n",
    "            self.neighbor_attn = NeighborAttention(\n",
    "                feature_dim=2,\n",
    "                attn_dim=cfg.attn_dim,\n",
    "                layer_range=cfg.neighbor_range,\n",
    "                device=cfg.device\n",
    "            )\n",
    "        \n",
    "        if cfg.use_wormhole:\n",
    "            self.wormhole_attn = WormholeAttention(\n",
    "                feature_dim=2,\n",
    "                attn_dim=cfg.attn_dim,\n",
    "                threshold=cfg.wormhole_threshold,\n",
    "                max_connections=cfg.wormhole_max_conn,\n",
    "                device=cfg.device\n",
    "            )\n",
    "        \n",
    "        # Fusion layer if using attention\n",
    "        num_attn = sum([cfg.use_temporal, cfg.use_neighbor, cfg.use_wormhole])\n",
    "        if num_attn > 0:\n",
    "            self.fusion = nn.Sequential(\n",
    "                nn.Linear(2 * (1 + num_attn), cfg.attn_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(cfg.attn_dim, 2)\n",
    "            )\n",
    "        \n",
    "        self.to(cfg.device)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, history: Optional[Dict] = None) -> Tuple[torch.Tensor, Dict]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input field [B, 1, H, W]\n",
    "            history: Dict with 'bands': [B, T, num_bands, H, W, 2]\n",
    "        Returns:\n",
    "            pred: Predicted field [B, 1, H, W]\n",
    "            info: Dict with features for history\n",
    "        \"\"\"\n",
    "        B, _, H, W = x.shape\n",
    "        \n",
    "        # FFT decompose\n",
    "        fft = torch.fft.fftshift(torch.fft.fft2(x.squeeze(1) * self.window))\n",
    "        \n",
    "        proc_bands = []\n",
    "        current_band_feats = []  # For history\n",
    "        \n",
    "        for i in range(self.cfg.num_bands):\n",
    "            band = fft * self.masks[i].unsqueeze(0)\n",
    "            band_feat = torch.stack([band.real, band.imag], dim=1)  # [B, 2, H, W]\n",
    "            \n",
    "            # Apply band processing\n",
    "            proc = self.bands[i](band_feat)\n",
    "            processed = band_feat + proc  # Residual\n",
    "            \n",
    "            # Apply attention if enabled and history available\n",
    "            if history is not None and 'bands' in history and history['bands'].shape[1] > 0:\n",
    "                band_history = history['bands'][:, :, i]  # [B, T, H, W, 2]\n",
    "                current_as_feat = processed.permute(0, 2, 3, 1)  # [B, H, W, 2]\n",
    "                \n",
    "                attn_outputs = [current_as_feat]\n",
    "                \n",
    "                if self.cfg.use_temporal:\n",
    "                    t_out = self.temporal_attn(current_as_feat, band_history)\n",
    "                    attn_outputs.append(t_out)\n",
    "                \n",
    "                if self.cfg.use_neighbor:\n",
    "                    n_out = self.neighbor_attn(current_as_feat, band_history)\n",
    "                    attn_outputs.append(n_out)\n",
    "                \n",
    "                if self.cfg.use_wormhole:\n",
    "                    w_out = self.wormhole_attn(current_as_feat, band_history)\n",
    "                    attn_outputs.append(w_out)\n",
    "                \n",
    "                if len(attn_outputs) > 1:\n",
    "                    # Fuse attention outputs\n",
    "                    combined = torch.cat(attn_outputs, dim=-1)  # [B, H, W, 2*(1+num_attn)]\n",
    "                    fused = self.fusion(combined)  # [B, H, W, 2]\n",
    "                    processed = processed + 0.1 * fused.permute(0, 3, 1, 2)  # Add attention contribution\n",
    "            \n",
    "            proc_bands.append(processed)\n",
    "            current_band_feats.append(processed.permute(0, 2, 3, 1))  # [B, H, W, 2]\n",
    "        \n",
    "        # Stack band features for history\n",
    "        band_feats = torch.stack(current_band_feats, dim=1)  # [B, num_bands, H, W, 2]\n",
    "        \n",
    "        # Reconstruct\n",
    "        recon = sum(\n",
    "            torch.complex(b[:, 0], b[:, 1]) * self.masks[i].unsqueeze(0)\n",
    "            for i, b in enumerate(proc_bands)\n",
    "        )\n",
    "        pred = torch.fft.ifft2(torch.fft.ifftshift(recon)).real.unsqueeze(1)\n",
    "        \n",
    "        return pred, {'bands': band_feats.detach()}\n",
    "\n",
    "\n",
    "class FlatBaseline(nn.Module):\n",
    "    \"\"\"Flat ConvNet baseline - no spectral decomposition.\"\"\"\n",
    "    \n",
    "    def __init__(self, height: int, width: int, channels: int = 32, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, channels, 3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(channels, channels*2, 3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(channels*2, channels*2, 3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(channels*2, channels, 3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(channels, 1, 3, padding=1),\n",
    "        )\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, x, history=None):\n",
    "        return self.net(x), {}\n",
    "\n",
    "\n",
    "class FlatWithAttention(nn.Module):\n",
    "    \"\"\"Flat ConvNet with temporal and neighbor attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, height: int, width: int, channels: int = 32, \n",
    "                 attn_dim: int = 32, history_len: int = 8, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.channels = channels\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, channels, 3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1), nn.GELU(),\n",
    "        )\n",
    "        \n",
    "        # Attention\n",
    "        self.temporal_attn = PerPositionTemporalAttention(\n",
    "            feature_dim=channels, attn_dim=attn_dim, device=device)\n",
    "        self.neighbor_attn = NeighborAttention(\n",
    "            feature_dim=channels, attn_dim=attn_dim, device=device)\n",
    "        \n",
    "        # Fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(channels * 3, channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(channels, 1, 3, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, x, history=None):\n",
    "        B, _, H, W = x.shape\n",
    "        \n",
    "        # Encode\n",
    "        feat = self.encoder(x)  # [B, C, H, W]\n",
    "        feat_hwc = feat.permute(0, 2, 3, 1)  # [B, H, W, C]\n",
    "        \n",
    "        # Apply attention if history available\n",
    "        if history is not None and 'feat' in history and history['feat'].shape[1] > 0:\n",
    "            hist_feat = history['feat']  # [B, T, H, W, C]\n",
    "            \n",
    "            t_out = self.temporal_attn(feat_hwc, hist_feat)\n",
    "            n_out = self.neighbor_attn(feat_hwc, hist_feat)\n",
    "            \n",
    "            combined = torch.cat([feat_hwc, t_out, n_out], dim=-1)\n",
    "            fused = self.fusion(combined)  # [B, H, W, C]\n",
    "            feat = feat + 0.1 * fused.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Decode\n",
    "        pred = self.decoder(feat)\n",
    "        \n",
    "        return pred, {'feat': feat.permute(0, 2, 3, 1).detach()}\n",
    "\n",
    "print(\"Models defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "**Key v4.1 Fix**: Drop last incomplete batch to maintain consistent tensor shapes.\n",
    "This is critical for wormhole attention which needs persistent history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, fields, targets, epochs, lr, device, delta=True, batch=32, history_len=8):\n",
    "    \"\"\"Train model with proper history management.\n",
    "    \n",
    "    v4.1: Drop incomplete batches to maintain consistent tensor shapes.\n",
    "    This is important for wormhole attention which builds history across batches.\n",
    "    \"\"\"\n",
    "    fields = fields.to(device)\n",
    "    targets = targets.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "    # Calculate number of complete batches (drop incomplete last batch)\n",
    "    num_samples = len(fields)\n",
    "    num_complete_batches = num_samples // batch\n",
    "    usable_samples = num_complete_batches * batch\n",
    "    \n",
    "    print(f\"    Total samples: {num_samples}, Using: {usable_samples} ({num_complete_batches} batches of {batch})\")\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        t0 = time.time()\n",
    "        ep_loss = []\n",
    "        \n",
    "        # Shuffle only the usable samples\n",
    "        perm = torch.randperm(usable_samples)\n",
    "        \n",
    "        # Reset history at start of each epoch (fresh start)\n",
    "        history = None\n",
    "        \n",
    "        for batch_idx in range(num_complete_batches):\n",
    "            i = batch_idx * batch\n",
    "            idx = perm[i:i+batch]\n",
    "            x, y = fields[idx], targets[idx]\n",
    "            \n",
    "            pred, info = model(x, history)\n",
    "            \n",
    "            loss = F.mse_loss(pred - x, y - x) if delta else F.mse_loss(pred, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            ep_loss.append(loss.item())\n",
    "            \n",
    "            # Update history (rolling buffer)\n",
    "            if 'bands' in info and info['bands'] is not None:\n",
    "                new_feat = info['bands'].unsqueeze(1)  # [B, 1, num_bands, H, W, 2]\n",
    "                if history is None or 'bands' not in history:\n",
    "                    history = {'bands': new_feat}\n",
    "                else:\n",
    "                    # Append and keep last history_len entries\n",
    "                    history['bands'] = torch.cat([history['bands'], new_feat], dim=1)[:, -history_len:]\n",
    "            elif 'feat' in info and info['feat'] is not None:\n",
    "                new_feat = info['feat'].unsqueeze(1)  # [B, 1, H, W, C]\n",
    "                if history is None or 'feat' not in history:\n",
    "                    history = {'feat': new_feat}\n",
    "                else:\n",
    "                    # Append and keep last history_len entries\n",
    "                    history['feat'] = torch.cat([history['feat'], new_feat], dim=1)[:, -history_len:]\n",
    "        \n",
    "        avg = sum(ep_loss) / len(ep_loss)\n",
    "        losses.append(avg)\n",
    "        print(f\"  Ep {ep+1}/{epochs}: loss={avg:.6f}, time={time.time()-t0:.1f}s\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "print(\"Training function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "print(\"[1] Creating environment...\")\n",
    "plasma_cfg = PlasmaConfig.turbulent(device=DEVICE, size=GRID_SIZE)\n",
    "env = TurbulentPlasmaEnv(plasma_cfg)\n",
    "\n",
    "print(\"\\n[2] Generating data (NO CONTROL SIGNAL)...\")\n",
    "fields, targets = generate_trajectories_no_control(\n",
    "    env, NUM_TRAJECTORIES, TRAJECTORY_LENGTH, 0.1, PREDICTION_HORIZON)\n",
    "print(f\"    Fields: {fields.shape}, Targets: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all models for ablation\n",
    "print(\"\\n[3] Creating models...\")\n",
    "\n",
    "models = {}\n",
    "\n",
    "# ============================================================================\n",
    "# BAND COUNT ABLATION (no attention)\n",
    "# ============================================================================\n",
    "for num_bands in [2, 3, 7]:\n",
    "    cfg = SBMConfig(\n",
    "        height=GRID_SIZE, width=GRID_SIZE, num_bands=num_bands,\n",
    "        use_temporal=False, use_neighbor=False, use_wormhole=False,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    models[f'SBM_{num_bands}B_None'] = SBMWithAttention(cfg)\n",
    "\n",
    "# ============================================================================\n",
    "# ATTENTION TYPE ABLATION (3-band base)\n",
    "# ============================================================================\n",
    "attention_configs = [\n",
    "    ('Temporal', True, False, False),\n",
    "    ('Neighbor', False, True, False),\n",
    "    ('Wormhole', False, False, True),\n",
    "    ('TempNeigh', True, True, False),\n",
    "    ('Full', True, True, True),\n",
    "]\n",
    "\n",
    "for name, use_t, use_n, use_w in attention_configs:\n",
    "    cfg = SBMConfig(\n",
    "        height=GRID_SIZE, width=GRID_SIZE, num_bands=3,\n",
    "        use_temporal=use_t, use_neighbor=use_n, use_wormhole=use_w,\n",
    "        history_len=HISTORY_LEN, top_k=TOP_K_TEMPORAL, decay=TEMPORAL_DECAY,\n",
    "        neighbor_range=NEIGHBOR_RANGE, wormhole_threshold=WORMHOLE_THRESHOLD,\n",
    "        wormhole_max_conn=WORMHOLE_MAX_CONN, device=DEVICE\n",
    "    )\n",
    "    models[f'SBM_3B_{name}'] = SBMWithAttention(cfg)\n",
    "\n",
    "# ============================================================================\n",
    "# 7-BAND WITH ATTENTION\n",
    "# ============================================================================\n",
    "cfg = SBMConfig(\n",
    "    height=GRID_SIZE, width=GRID_SIZE, num_bands=7,\n",
    "    use_temporal=True, use_neighbor=False, use_wormhole=False,\n",
    "    history_len=HISTORY_LEN, device=DEVICE\n",
    ")\n",
    "models['SBM_7B_Temporal'] = SBMWithAttention(cfg)\n",
    "\n",
    "cfg = SBMConfig(\n",
    "    height=GRID_SIZE, width=GRID_SIZE, num_bands=7,\n",
    "    use_temporal=True, use_neighbor=True, use_wormhole=True,\n",
    "    history_len=HISTORY_LEN, device=DEVICE\n",
    ")\n",
    "models['SBM_7B_Full'] = SBMWithAttention(cfg)\n",
    "\n",
    "# ============================================================================\n",
    "# BASELINES\n",
    "# ============================================================================\n",
    "models['Flat_Baseline'] = FlatBaseline(GRID_SIZE, GRID_SIZE, 32, DEVICE)\n",
    "models['Flat_WithAttn'] = FlatWithAttention(GRID_SIZE, GRID_SIZE, 32, 32, HISTORY_LEN, DEVICE)\n",
    "\n",
    "# Print model info\n",
    "print(\"\\nModels created:\")\n",
    "for name, model in models.items():\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"    {name:20s}: {params:>8,} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    results[name] = train(model, fields, targets, EPOCHS, LR, DEVICE, \n",
    "                          PREDICT_DELTA, BATCH_SIZE, HISTORY_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group models by category\n",
    "band_models = ['SBM_2B_None', 'SBM_3B_None', 'SBM_7B_None']\n",
    "attn_models = ['SBM_3B_None', 'SBM_3B_Temporal', 'SBM_3B_Neighbor', 'SBM_3B_Wormhole', 'SBM_3B_TempNeigh', 'SBM_3B_Full']\n",
    "seven_band_models = ['SBM_7B_None', 'SBM_7B_Temporal', 'SBM_7B_Full']\n",
    "flat_models = ['Flat_Baseline', 'Flat_WithAttn']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Band count comparison\n",
    "ax = axes[0, 0]\n",
    "for name in band_models:\n",
    "    ax.semilogy(results[name], label=f\"{name}: {results[name][-1]:.6f}\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_title('Band Count Ablation (No Attention)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Attention type comparison (3-band)\n",
    "ax = axes[0, 1]\n",
    "for name in attn_models:\n",
    "    ax.semilogy(results[name], label=f\"{name.replace('SBM_3B_', '')}: {results[name][-1]:.6f}\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_title('Attention Type Ablation (3-Band)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 7-band comparison\n",
    "ax = axes[1, 0]\n",
    "for name in seven_band_models:\n",
    "    ax.semilogy(results[name], label=f\"{name.replace('SBM_7B_', '7B_')}: {results[name][-1]:.6f}\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_title('7-Band with Attention')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Best SBM vs Flat\n",
    "ax = axes[1, 1]\n",
    "# Find best SBM\n",
    "sbm_final = {k: v[-1] for k, v in results.items() if k.startswith('SBM')}\n",
    "best_sbm = min(sbm_final, key=sbm_final.get)\n",
    "compare = [best_sbm] + flat_models\n",
    "for name in compare:\n",
    "    ax.semilogy(results[name], label=f\"{name}: {results[name][-1]:.6f}\", linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_title(f'Best SBM ({best_sbm}) vs Flat Baselines')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FULL ABLATION RESULTS (No Control Signal - Pure Prediction)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sort by final loss\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1][-1])\n",
    "\n",
    "print(\"\\n{:25s} {:>12s} {:>12s} {:>10s}\".format('Model', 'Final Loss', 'Improvement', 'Rank'))\n",
    "print(\"-\"*60)\n",
    "for rank, (name, losses) in enumerate(sorted_results, 1):\n",
    "    improvement = losses[0] / losses[-1]\n",
    "    print(f\"{name:25s} {losses[-1]:12.6f} {improvement:10.1f}x {rank:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY COMPARISONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Band count effect\n",
    "print(\"\\n1. BAND COUNT EFFECT (No Attention):\")\n",
    "for name in band_models:\n",
    "    print(f\"   {name}: {results[name][-1]:.6f}\")\n",
    "best_bands = min(band_models, key=lambda x: results[x][-1])\n",
    "print(f\"   Winner: {best_bands}\")\n",
    "\n",
    "# 2. Attention type effect\n",
    "print(\"\\n2. ATTENTION TYPE EFFECT (3-Band Base):\")\n",
    "base = results['SBM_3B_None'][-1]\n",
    "for name in attn_models:\n",
    "    loss = results[name][-1]\n",
    "    diff = (base - loss) / base * 100\n",
    "    print(f\"   {name.replace('SBM_3B_', ''):12s}: {loss:.6f} ({diff:+.1f}% vs None)\")\n",
    "\n",
    "# 3. SBM vs Flat\n",
    "print(\"\\n3. ARCHITECTURE COMPARISON:\")\n",
    "sbm_final = {k: v[-1] for k, v in results.items() if k.startswith('SBM')}\n",
    "flat_final = {k: v[-1] for k, v in results.items() if k.startswith('Flat')}\n",
    "best_sbm = min(sbm_final, key=sbm_final.get)\n",
    "best_flat = min(flat_final, key=flat_final.get)\n",
    "print(f\"   Best SBM:  {best_sbm} = {sbm_final[best_sbm]:.6f}\")\n",
    "print(f\"   Best Flat: {best_flat} = {flat_final[best_flat]:.6f}\")\n",
    "diff = (sbm_final[best_sbm] - flat_final[best_flat]) / flat_final[best_flat] * 100\n",
    "winner = \"SBM\" if diff < 0 else \"Flat\"\n",
    "print(f\"   Difference: {abs(diff):.1f}% ({winner} wins)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of all results\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "names = [x[0] for x in sorted_results]\n",
    "finals = [x[1][-1] for x in sorted_results]\n",
    "\n",
    "# Color by category\n",
    "colors = []\n",
    "for n in names:\n",
    "    if 'Flat' in n:\n",
    "        colors.append('green')\n",
    "    elif '7B' in n:\n",
    "        colors.append('darkblue')\n",
    "    elif '3B' in n:\n",
    "        colors.append('blue')\n",
    "    else:\n",
    "        colors.append('lightblue')\n",
    "\n",
    "bars = ax.bar(range(len(names)), finals, color=colors)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels([n.replace('SBM_', '').replace('_', '\\n') for n in names], fontsize=8, rotation=45, ha='right')\n",
    "ax.set_ylabel('Final Loss (MSE)')\n",
    "ax.set_title('Full Ablation Results - Sorted by Performance')\n",
    "\n",
    "for bar, val in zip(bars, finals):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{val:.4f}', \n",
    "            ha='center', va='bottom', fontsize=7, rotation=90)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightblue', label='2-Band SBM'),\n",
    "    Patch(facecolor='blue', label='3-Band SBM'),\n",
    "    Patch(facecolor='darkblue', label='7-Band SBM'),\n",
    "    Patch(facecolor='green', label='Flat Baseline'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions from best models\n",
    "print(\"\\nVisualizing predictions from top models...\")\n",
    "\n",
    "# Get sample\n",
    "idx = 500\n",
    "x_sample = fields[idx:idx+1].to(DEVICE)\n",
    "y_sample = targets[idx:idx+1].to(DEVICE)\n",
    "\n",
    "# Get predictions from top 3 models\n",
    "top_models = [x[0] for x in sorted_results[:3]]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(top_models) + 2, figsize=(16, 6))\n",
    "\n",
    "# Input and target\n",
    "axes[0, 0].imshow(x_sample[0, 0].cpu().numpy(), cmap='viridis')\n",
    "axes[0, 0].set_title('Input')\n",
    "axes[0, 1].imshow(y_sample[0, 0].cpu().numpy(), cmap='viridis')\n",
    "axes[0, 1].set_title(f'Target (t+{PREDICTION_HORIZON})')\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Predictions\n",
    "with torch.no_grad():\n",
    "    for i, name in enumerate(top_models):\n",
    "        pred, _ = models[name](x_sample, None)\n",
    "        err = torch.abs(pred - y_sample)\n",
    "        \n",
    "        axes[0, i+2].imshow(pred[0, 0].cpu().numpy(), cmap='viridis')\n",
    "        axes[0, i+2].set_title(f'{name}\\nPrediction')\n",
    "        \n",
    "        axes[1, i+2].imshow(err[0, 0].cpu().numpy(), cmap='hot')\n",
    "        axes[1, i+2].set_title(f'Error\\n(MSE: {err.mean():.4f})')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.suptitle('Top 3 Model Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Ablation Dimensions Tested:\n",
    "\n",
    "1. **Band Count**: 2, 3, 7 bands\n",
    "2. **Attention Types**: None, Temporal, Neighbor, Wormhole, TempNeigh, Full\n",
    "3. **Architecture**: SBM vs Flat ConvNet\n",
    "\n",
    "### Key Questions Answered:\n",
    "\n",
    "1. Does band count matter for prediction quality?\n",
    "2. Does per-position temporal attention help (vs pooled)?\n",
    "3. Does neighbor attention capture local physics better than convolutions?\n",
    "4. Does wormhole attention provide useful non-local information?\n",
    "5. Does spectral decomposition (SBM) outperform flat spatial processing?\n",
    "\n",
    "### Task: Pure Prediction\n",
    "\n",
    "This experiment uses NO control signal - models must predict future state from\n",
    "current state alone, exactly like the original winning 032 experiment.\n",
    "\n",
    "The actuators still affect the physics (control is applied in simulation),\n",
    "but models don't have access to control signals. They must learn to predict\n",
    "despite actuator-induced uncertainty.\n",
    "\n",
    "### v4.1 Fix\n",
    "\n",
    "Dropped incomplete last batch to maintain consistent tensor shapes for history\n",
    "management. This ensures wormhole attention can build proper temporal context\n",
    "across batches within an epoch."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "standard",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
