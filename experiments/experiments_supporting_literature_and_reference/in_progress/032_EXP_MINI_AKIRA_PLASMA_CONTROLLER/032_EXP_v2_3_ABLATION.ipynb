{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 032 v2.3: Pre-FFT vs Post-FFT Control Conditioning Ablation\n",
        "\n",
        "**Purpose**: Test whether control signal should be applied BEFORE or AFTER FFT transform.\n",
        "\n",
        "**Key Insight from v2.2**: Post-FFT control conditioning destroys spatial locality.\n",
        "When control features are concatenated AFTER the FFT transform, learned actuator maps\n",
        "become identical concentric ring patterns instead of localized Gaussian blobs at\n",
        "different spatial positions.\n",
        "\n",
        "**Ablation Tests (5 models)**:\n",
        "1. **SBM_PostFFT_Known**: Original flawed design with known maps (for comparison)\n",
        "2. **SBM_PreFFT_Known**: Correct design with known maps - control applied BEFORE FFT\n",
        "3. **SBM_PreFFT_Learned**: Correct design with learned maps - tests structure discovery\n",
        "4. **Flat_Known**: Baseline ConvNet with known actuator physics\n",
        "5. **Flat_Learned**: Baseline ConvNet learning actuator locations\n",
        "\n",
        "**Architecture Comparison**:\n",
        "- Post-FFT (Wrong): `x -> FFT -> bands -> [concat ctrl_feat] -> process -> iFFT -> output`\n",
        "- Pre-FFT (Correct): `x + ctrl_spatial -> FFT -> bands -> process -> iFFT -> output`\n",
        "\n",
        "**Key Hypothesis**: Pre-FFT control preserves spatial locality, enabling proper\n",
        "localized actuator pattern learning.\n",
        "\n",
        "**Run on Colab with GPU**: Runtime -> Change runtime type -> A100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "GRID_SIZE = 64\n",
        "EPOCHS = 50\n",
        "DIFFICULTY = \"turbulent\"\n",
        "PREDICT_DELTA = True\n",
        "PREDICTION_HORIZON = 5\n",
        "NUM_TRAJECTORIES = 100\n",
        "TRAJECTORY_LENGTH = 100\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.001\n",
        "\n",
        "# Attention\n",
        "TOP_K_TEMPORAL = 4\n",
        "TEMPORAL_DECAY = 0.9\n",
        "\n",
        "# Control\n",
        "NUM_ACTUATORS = 9\n",
        "CONTROL_EMBED_DIM = 32\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Grid: {GRID_SIZE}x{GRID_SIZE}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Difficulty: {DIFFICULTY}\")\n",
        "print(f\"Prediction: delta t+{PREDICTION_HORIZON}\")\n",
        "print(f\"Actuators: {NUM_ACTUATORS} (3x3 grid)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import math\n",
        "import time\n",
        "\n",
        "@dataclass\n",
        "class PlasmaConfig:\n",
        "    height: int = 64\n",
        "    width: int = 64\n",
        "    diffusion: float = 0.25\n",
        "    advection: float = 0.08\n",
        "    noise_std: float = 0.02\n",
        "    disturbance_prob: float = 0.1\n",
        "    disturbance_strength: float = 0.15\n",
        "    num_vortices: int = 3\n",
        "    vortex_strength: float = 0.1\n",
        "    shear_strength: float = 0.05\n",
        "    multiscale_noise: bool = True\n",
        "    num_actuators: int = 9\n",
        "    _base_actuator_sigma: float = 5.0\n",
        "    device: str = \"cpu\"\n",
        "    dtype: torch.dtype = torch.float32\n",
        "    \n",
        "    @property\n",
        "    def actuator_sigma(self) -> float:\n",
        "        return self._base_actuator_sigma * min(self.height, self.width) / 64.0\n",
        "    \n",
        "    @classmethod\n",
        "    def turbulent(cls, device: str = \"cpu\", size: int = 64):\n",
        "        return cls(height=size, width=size, diffusion=0.3, advection=0.12, noise_std=0.03,\n",
        "                   disturbance_prob=0.25, disturbance_strength=0.3,\n",
        "                   num_vortices=3, vortex_strength=0.15, shear_strength=0.08,\n",
        "                   multiscale_noise=True, num_actuators=9, device=device)\n",
        "\n",
        "\n",
        "class TurbulentPlasmaEnv:\n",
        "    def __init__(self, cfg: PlasmaConfig):\n",
        "        self.cfg = cfg\n",
        "        self.device = torch.device(cfg.device)\n",
        "        self.dtype = cfg.dtype\n",
        "        self._actuator_maps = self._build_actuator_maps()\n",
        "        self._vortex_flow = self._build_vortex_flow()\n",
        "        self._shear_flow = self._build_shear_flow()\n",
        "    \n",
        "    def _build_actuator_maps(self) -> torch.Tensor:\n",
        "        h, w = self.cfg.height, self.cfg.width\n",
        "        grid_n = int(math.ceil(math.sqrt(self.cfg.num_actuators)))\n",
        "        centers_y = torch.linspace(h * 0.2, h * 0.8, grid_n, device=self.device, dtype=self.dtype)\n",
        "        centers_x = torch.linspace(w * 0.2, w * 0.8, grid_n, device=self.device, dtype=self.dtype)\n",
        "        centers = torch.cartesian_prod(centers_y, centers_x)[:self.cfg.num_actuators]\n",
        "        sig2 = self.cfg.actuator_sigma ** 2\n",
        "        yy, xx = torch.meshgrid(\n",
        "            torch.arange(h, device=self.device, dtype=self.dtype),\n",
        "            torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
        "        bumps = [torch.exp(-((yy - cy) ** 2 + (xx - cx) ** 2) / (2 * sig2)) for cy, cx in centers]\n",
        "        return torch.stack(bumps, dim=0)\n",
        "    \n",
        "    def _build_vortex_flow(self):\n",
        "        if self.cfg.num_vortices == 0: return None, None\n",
        "        h, w = self.cfg.height, self.cfg.width\n",
        "        centers_y = torch.rand(self.cfg.num_vortices, device=self.device) * (h * 0.6) + (h * 0.2)\n",
        "        centers_x = torch.rand(self.cfg.num_vortices, device=self.device) * (w * 0.6) + (w * 0.2)\n",
        "        yy, xx = torch.meshgrid(torch.arange(h, device=self.device, dtype=self.dtype),\n",
        "                                torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
        "        vy, vx = torch.zeros_like(yy), torch.zeros_like(xx)\n",
        "        scale = min(h, w) / 64.0\n",
        "        for i in range(self.cfg.num_vortices):\n",
        "            dy, dx = yy - centers_y[i], xx - centers_x[i]\n",
        "            r2 = dy**2 + dx**2 + 1e-6\n",
        "            decay = torch.exp(-r2 / (2 * (10 * scale)**2))\n",
        "            sign = 1 if i % 2 == 0 else -1\n",
        "            vy += sign * self.cfg.vortex_strength * (-dx) / torch.sqrt(r2) * decay\n",
        "            vx += sign * self.cfg.vortex_strength * dy / torch.sqrt(r2) * decay\n",
        "        return vy, vx\n",
        "    \n",
        "    def _build_shear_flow(self):\n",
        "        if self.cfg.shear_strength == 0: return None, None\n",
        "        h, w = self.cfg.height, self.cfg.width\n",
        "        yy, _ = torch.meshgrid(torch.arange(h, device=self.device, dtype=self.dtype),\n",
        "                               torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
        "        return torch.zeros_like(yy), self.cfg.shear_strength * torch.sin(2 * math.pi * yy / h)\n",
        "    \n",
        "    def _apply_flow(self, field, vy, vx):\n",
        "        B, C, H, W = field.shape\n",
        "        yy, xx = torch.meshgrid(torch.linspace(-1, 1, H, device=self.device),\n",
        "                                torch.linspace(-1, 1, W, device=self.device), indexing=\"ij\")\n",
        "        grid = torch.stack([xx - vx/(W/2), yy - vy/(H/2)], dim=-1).unsqueeze(0).expand(B, -1, -1, -1)\n",
        "        return F.grid_sample(field, grid, mode='bilinear', padding_mode='border', align_corners=True)\n",
        "    \n",
        "    def _multiscale_noise(self, shape):\n",
        "        B, C, H, W = shape\n",
        "        noise = torch.zeros(shape, device=self.device, dtype=self.dtype)\n",
        "        for scale in [1, 2, 4, 8]:\n",
        "            hs, ws = H // scale, W // scale\n",
        "            if hs < 4: continue\n",
        "            coarse = torch.randn(B, C, hs, ws, device=self.device, dtype=self.dtype)\n",
        "            noise += F.interpolate(coarse, size=(H, W), mode='bilinear', align_corners=False) * (self.cfg.noise_std / scale)\n",
        "        return noise\n",
        "    \n",
        "    def reset(self, batch_size=1):\n",
        "        h, w = self.cfg.height, self.cfg.width\n",
        "        cx = torch.randint(int(w*0.3), int(w*0.7), (batch_size,), device=self.device)\n",
        "        cy = torch.randint(int(h*0.3), int(h*0.7), (batch_size,), device=self.device)\n",
        "        yy, xx = torch.meshgrid(torch.arange(h, device=self.device, dtype=self.dtype),\n",
        "                                torch.arange(w, device=self.device, dtype=self.dtype), indexing=\"ij\")\n",
        "        sig2 = (self.cfg.actuator_sigma * 1.5) ** 2\n",
        "        field = torch.zeros(batch_size, 1, h, w, device=self.device, dtype=self.dtype)\n",
        "        for b in range(batch_size):\n",
        "            field[b, 0] = torch.exp(-((yy - cy[b].float())**2 + (xx - cx[b].float())**2) / (2*sig2))\n",
        "        return field\n",
        "    \n",
        "    def step(self, field, control, noise=True):\n",
        "        B = field.shape[0]\n",
        "        # Diffusion\n",
        "        lap = (F.pad(field, (0,0,1,0))[:,:,:-1,:] + F.pad(field, (0,0,0,1))[:,:,1:,:] +\n",
        "               F.pad(field, (1,0,0,0))[:,:,:,:-1] + F.pad(field, (0,1,0,0))[:,:,:,1:]) - 4*field\n",
        "        diffused = field + self.cfg.diffusion * lap\n",
        "        # Advection\n",
        "        advected = torch.roll(diffused, shifts=(1,-1), dims=(2,3)) * self.cfg.advection + diffused * (1 - self.cfg.advection)\n",
        "        if self._vortex_flow[0] is not None:\n",
        "            advected = self._apply_flow(advected, self._vortex_flow[0], self._vortex_flow[1])\n",
        "        if self._shear_flow[0] is not None:\n",
        "            advected = self._apply_flow(advected, self._shear_flow[0], self._shear_flow[1])\n",
        "        # Actuators\n",
        "        force = torch.einsum('ba,ahw->bhw', control, self._actuator_maps).unsqueeze(1)\n",
        "        next_field = advected + force\n",
        "        # Noise\n",
        "        if noise:\n",
        "            next_field = next_field + (self._multiscale_noise(next_field.shape) if self.cfg.multiscale_noise \n",
        "                                       else torch.randn_like(next_field) * self.cfg.noise_std)\n",
        "        return torch.clamp(next_field, -1, 1)\n",
        "    \n",
        "    def get_actuator_maps(self):\n",
        "        \"\"\"Return actuator Gaussian maps for known control encoding.\"\"\"\n",
        "        return self._actuator_maps.clone()\n",
        "\n",
        "\n",
        "def generate_trajectories(env, num_traj, traj_len, control_scale=0.1, horizon=1):\n",
        "    \"\"\"Generate data with control sequences.\"\"\"\n",
        "    all_fields, all_next, all_ctrl = [], [], []\n",
        "    for _ in range(num_traj):\n",
        "        field = env.reset(1)\n",
        "        traj, ctrls = [field.clone()], []\n",
        "        for _ in range(traj_len + horizon):\n",
        "            ctrl = torch.clamp(torch.randn(1, env.cfg.num_actuators, device=env.device) * control_scale, -1, 1)\n",
        "            traj.append(env.step(field, ctrl).clone())\n",
        "            ctrls.append(ctrl)\n",
        "            field = traj[-1].detach()\n",
        "        for t in range(traj_len):\n",
        "            all_fields.append(traj[t])\n",
        "            all_next.append(traj[t + horizon])\n",
        "            all_ctrl.append(torch.stack([ctrls[t+k] for k in range(horizon)], dim=1).squeeze(0))\n",
        "    return torch.cat(all_fields), torch.cat(all_next), torch.stack(all_ctrl)\n",
        "\n",
        "print(\"Environment defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Control Encoders\n",
        "\n",
        "Two types of control encoders:\n",
        "- **Post-FFT encoders**: Output `embed_dim` channels for concatenation with FFT bands\n",
        "- **Pre-FFT (Spatial) encoders**: Output 1 channel for spatial addition before FFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# POST-FFT CONTROL ENCODERS (for SBMPostFFT - the flawed design)\n",
        "# Output: [B, embed_dim, H, W] for concatenation with FFT bands\n",
        "# ============================================================================\n",
        "\n",
        "class ControlEncoderKnownPostFFT(nn.Module):\n",
        "    \"\"\"Known actuator maps, outputs embed_dim channels for Post-FFT concat.\"\"\"\n",
        "    def __init__(self, actuator_maps: torch.Tensor, horizon: int, embed_dim: int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('actuator_maps', actuator_maps)\n",
        "        self.temporal_enc = nn.Sequential(\n",
        "            nn.Linear(horizon, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "        )\n",
        "    \n",
        "    def forward(self, ctrl_seq):\n",
        "        # ctrl_seq: [B, horizon, A] -> [B, embed_dim, H, W]\n",
        "        ctrl_per_act = ctrl_seq.transpose(1, 2)\n",
        "        ctrl_enc = self.temporal_enc(ctrl_per_act)\n",
        "        return torch.einsum('bae,ahw->behw', ctrl_enc, self.actuator_maps)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PRE-FFT CONTROL ENCODERS (for SBMPreFFT - the correct design)\n",
        "# Output: [B, 1, H, W] for spatial addition before FFT\n",
        "# ============================================================================\n",
        "\n",
        "class ControlEncoderKnownPreFFT(nn.Module):\n",
        "    \"\"\"Known actuator maps, outputs 1 channel for Pre-FFT spatial addition.\n",
        "    \n",
        "    Preserves spatial locality by applying control in spatial domain.\n",
        "    \"\"\"\n",
        "    def __init__(self, actuator_maps: torch.Tensor, horizon: int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('actuator_maps', actuator_maps)\n",
        "        self.temporal_enc = nn.Sequential(\n",
        "            nn.Linear(horizon, 16),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(16, 1),\n",
        "        )\n",
        "    \n",
        "    def forward(self, ctrl_seq):\n",
        "        # ctrl_seq: [B, horizon, A] -> [B, 1, H, W]\n",
        "        ctrl_per_act = ctrl_seq.transpose(1, 2)  # [B, A, horizon]\n",
        "        weights = self.temporal_enc(ctrl_per_act).squeeze(-1)  # [B, A]\n",
        "        spatial = torch.einsum('ba,ahw->bhw', weights, self.actuator_maps)\n",
        "        return spatial.unsqueeze(1)\n",
        "\n",
        "\n",
        "class ControlEncoderLearnedPreFFT(nn.Module):\n",
        "    \"\"\"Learned actuator maps, outputs 1 channel for Pre-FFT spatial addition.\n",
        "    \n",
        "    Model discovers actuator locations while preserving spatial locality.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_actuators: int, horizon: int, height: int, width: int):\n",
        "        super().__init__()\n",
        "        self.actuator_patterns = nn.Parameter(torch.randn(num_actuators, height, width) * 0.01)\n",
        "        self.temporal_enc = nn.Sequential(\n",
        "            nn.Linear(horizon, 16),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(16, 1),\n",
        "        )\n",
        "    \n",
        "    def forward(self, ctrl_seq):\n",
        "        ctrl_per_act = ctrl_seq.transpose(1, 2)\n",
        "        weights = self.temporal_enc(ctrl_per_act).squeeze(-1)\n",
        "        spatial = torch.einsum('ba,ahw->bhw', weights, self.actuator_patterns)\n",
        "        return spatial.unsqueeze(1)\n",
        "    \n",
        "    def get_learned_maps(self):\n",
        "        return self.actuator_patterns.detach()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FLAT MODEL CONTROL ENCODERS (multi-channel for ConvNet input)\n",
        "# ============================================================================\n",
        "\n",
        "class ControlEncoderKnownFlat(nn.Module):\n",
        "    \"\"\"Known actuator maps for Flat ConvNet baseline.\"\"\"\n",
        "    def __init__(self, actuator_maps: torch.Tensor, horizon: int, embed_dim: int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('actuator_maps', actuator_maps)\n",
        "        self.temporal_enc = nn.Sequential(\n",
        "            nn.Linear(horizon, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "        )\n",
        "    \n",
        "    def forward(self, ctrl_seq):\n",
        "        ctrl_per_act = ctrl_seq.transpose(1, 2)\n",
        "        ctrl_enc = self.temporal_enc(ctrl_per_act)\n",
        "        return torch.einsum('bae,ahw->behw', ctrl_enc, self.actuator_maps)\n",
        "\n",
        "\n",
        "class ControlEncoderLearnedFlat(nn.Module):\n",
        "    \"\"\"Learned actuator maps for Flat ConvNet baseline.\"\"\"\n",
        "    def __init__(self, num_actuators: int, horizon: int, embed_dim: int, height: int, width: int):\n",
        "        super().__init__()\n",
        "        self.actuator_patterns = nn.Parameter(torch.randn(num_actuators, height, width) * 0.01)\n",
        "        self.temporal_enc = nn.Sequential(\n",
        "            nn.Linear(horizon, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "        )\n",
        "    \n",
        "    def forward(self, ctrl_seq):\n",
        "        ctrl_per_act = ctrl_seq.transpose(1, 2)\n",
        "        ctrl_enc = self.temporal_enc(ctrl_per_act)\n",
        "        return torch.einsum('bae,ahw->behw', ctrl_enc, self.actuator_patterns)\n",
        "    \n",
        "    def get_learned_maps(self):\n",
        "        return self.actuator_patterns.detach()\n",
        "\n",
        "print(\"Control encoders defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class SpectralConfig:\n",
        "    height: int = 64\n",
        "    width: int = 64\n",
        "    num_bands: int = 7\n",
        "    channels: int = 16\n",
        "    history_len: int = 8\n",
        "    num_heads: int = 4\n",
        "    top_k: int = 4\n",
        "    decay: float = 0.9\n",
        "    num_actuators: int = 9\n",
        "    horizon: int = 5\n",
        "    ctrl_embed: int = 32\n",
        "    device: str = \"cpu\"\n",
        "\n",
        "\n",
        "def make_radial_masks(h, w, num_bands, device):\n",
        "    yy, xx = torch.meshgrid(torch.linspace(-1, 1, h, device=device),\n",
        "                            torch.linspace(-1, 1, w, device=device), indexing=\"ij\")\n",
        "    rr = torch.sqrt(yy**2 + xx**2).clamp(min=1e-6)\n",
        "    edges = torch.logspace(-3, math.log10(math.sqrt(2)), num_bands+1, device=device)\n",
        "    edges[0] = 0\n",
        "    masks = [torch.sigmoid((rr - edges[i])*20) * torch.sigmoid((edges[i+1] - rr)*20) for i in range(num_bands)]\n",
        "    masks = torch.stack(masks)\n",
        "    return masks / (masks.sum(0, keepdim=True) + 1e-8)\n",
        "\n",
        "\n",
        "class TopKTemporal(nn.Module):\n",
        "    def __init__(self, dim, heads, max_len, top_k=4, decay=0.9):\n",
        "        super().__init__()\n",
        "        self.heads, self.head_dim, self.top_k, self.decay = heads, dim//heads, top_k, decay\n",
        "        self.qkv = nn.Linear(dim, 3*dim)\n",
        "        self.out = nn.Linear(dim, dim)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(max_len, max_len), 1).bool())\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        qkv = self.qkv(x).view(B, T, 3, self.heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        Q, K, V = qkv[0], qkv[1], qkv[2]\n",
        "        scores = (Q @ K.transpose(-2,-1)) / math.sqrt(self.head_dim)\n",
        "        scores = scores.masked_fill(self.mask[:T,:T].unsqueeze(0).unsqueeze(0), float('-inf'))\n",
        "        if T > self.top_k:\n",
        "            _, topk_idx = torch.topk(scores, self.top_k, dim=-1)\n",
        "            mask = torch.ones_like(scores, dtype=torch.bool).scatter_(-1, topk_idx, False)\n",
        "            scores = scores.masked_fill(mask, float('-inf'))\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        out = (attn @ V).transpose(1, 2).reshape(B, T, D)\n",
        "        return self.out(out), attn.mean(1).sum(-1).mean(-1)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SBMPostFFT: FLAWED DESIGN - Control applied AFTER FFT (kept for comparison)\n",
        "# ============================================================================\n",
        "\n",
        "class SBMPostFFT(nn.Module):\n",
        "    \"\"\"Spectral Belief Machine with POST-FFT control conditioning.\n",
        "    \n",
        "    FLAWED DESIGN - kept for ablation comparison.\n",
        "    \n",
        "    Problem: Control features concatenated AFTER FFT destroys spatial locality.\n",
        "    Learned actuator maps become identical concentric rings instead of\n",
        "    localized Gaussian blobs at different positions.\n",
        "    \n",
        "    Architecture: x -> FFT -> bands -> [concat ctrl_feat] -> process -> iFFT -> output\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, cfg: SpectralConfig, actuator_maps: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        \n",
        "        # Post-FFT control encoder (multi-channel output)\n",
        "        self.ctrl_enc = ControlEncoderKnownPostFFT(actuator_maps, cfg.horizon, cfg.ctrl_embed)\n",
        "        \n",
        "        # Spectral\n",
        "        self.register_buffer(\"masks\", make_radial_masks(cfg.height, cfg.width, cfg.num_bands, torch.device(cfg.device)))\n",
        "        self.register_buffer(\"window\", torch.ones(cfg.height, cfg.width, device=cfg.device))\n",
        "        \n",
        "        # Band blocks: input = 2 (real/imag) + ctrl_embed\n",
        "        self.bands = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(2 + cfg.ctrl_embed, cfg.channels, 3, padding=1), nn.GELU(),\n",
        "                nn.Conv2d(cfg.channels, cfg.channels, 3, padding=1), nn.GELU(),\n",
        "                nn.Conv2d(cfg.channels, 2, 1),\n",
        "            ) for _ in range(cfg.num_bands)\n",
        "        ])\n",
        "        \n",
        "        # Temporal\n",
        "        tdim = cfg.num_bands * 2 * 4\n",
        "        self.t_in = nn.Linear(tdim, cfg.channels * 8)\n",
        "        self.temporal = TopKTemporal(cfg.channels * 8, cfg.num_heads, cfg.history_len + 1, cfg.top_k, cfg.decay)\n",
        "        self.t_out = nn.Linear(cfg.channels * 8, tdim)\n",
        "        self.to(cfg.device)\n",
        "    \n",
        "    def forward(self, x, ctrl, history=None):\n",
        "        B = x.shape[0]\n",
        "        ctrl_feat = self.ctrl_enc(ctrl)  # [B, embed, H, W]\n",
        "        \n",
        "        # FFT decompose\n",
        "        fft = torch.fft.fftshift(torch.fft.fft2(x.squeeze(1) * self.window))\n",
        "        proc_bands = []\n",
        "        for i in range(self.cfg.num_bands):\n",
        "            band = fft * self.masks[i].unsqueeze(0)\n",
        "            band_feat = torch.stack([band.real, band.imag], dim=1)\n",
        "            # POST-FFT: concat control features with band features\n",
        "            band_with_ctrl = torch.cat([band_feat, ctrl_feat], dim=1)\n",
        "            proc = self.bands[i](band_with_ctrl)\n",
        "            proc_bands.append(band_feat + proc)\n",
        "        \n",
        "        # Pool for temporal\n",
        "        pooled = torch.cat([F.adaptive_avg_pool2d(b, (2,2)).flatten(1) for b in proc_bands], dim=1)\n",
        "        \n",
        "        # Temporal attention\n",
        "        if history and len(history) > 0:\n",
        "            history = [h for h in history if h.shape[0] == B and h.shape[1] == pooled.shape[1]]\n",
        "            if history:\n",
        "                seq = torch.stack(history + [pooled], dim=1)\n",
        "                t_out, _ = self.temporal(self.t_in(seq))\n",
        "                t_feat = self.t_out(t_out[:, -1, :])\n",
        "                chunk = pooled.shape[1] // self.cfg.num_bands\n",
        "                for i in range(self.cfg.num_bands):\n",
        "                    delta = t_feat[:, i*chunk:(i+1)*chunk].view(B, 2, 2, 2)\n",
        "                    delta_up = delta.repeat_interleave(self.cfg.height//2, 2).repeat_interleave(self.cfg.width//2, 3)\n",
        "                    proc_bands[i] = proc_bands[i] + 0.1 * delta_up\n",
        "        \n",
        "        # Reconstruct\n",
        "        recon = sum(torch.complex(b[:,0], b[:,1]) * self.masks[i].unsqueeze(0) for i, b in enumerate(proc_bands))\n",
        "        pred = torch.fft.ifft2(torch.fft.ifftshift(recon)).real.unsqueeze(1)\n",
        "        \n",
        "        return pred, {\"feat\": pooled.detach()}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SBMPreFFT: CORRECT DESIGN - Control applied BEFORE FFT\n",
        "# ============================================================================\n",
        "\n",
        "class SBMPreFFT(nn.Module):\n",
        "    \"\"\"Spectral Belief Machine with PRE-FFT control conditioning.\n",
        "    \n",
        "    CORRECT DESIGN - preserves spatial locality.\n",
        "    \n",
        "    Control is applied spatially BEFORE the FFT transform.\n",
        "    This allows proper localized actuator pattern learning because\n",
        "    spatial locality is preserved before the frequency transform.\n",
        "    \n",
        "    Architecture: x + ctrl_spatial -> FFT -> bands -> process -> iFFT -> output\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, cfg: SpectralConfig, actuator_maps=None, mode='known'):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.mode = mode\n",
        "        \n",
        "        # Pre-FFT control encoder (1-channel spatial output)\n",
        "        if mode == 'known':\n",
        "            assert actuator_maps is not None, \"actuator_maps required for known mode\"\n",
        "            self.ctrl_enc = ControlEncoderKnownPreFFT(actuator_maps, cfg.horizon)\n",
        "        else:\n",
        "            self.ctrl_enc = ControlEncoderLearnedPreFFT(cfg.num_actuators, cfg.horizon, cfg.height, cfg.width)\n",
        "        \n",
        "        # Spectral\n",
        "        self.register_buffer(\"masks\", make_radial_masks(cfg.height, cfg.width, cfg.num_bands, torch.device(cfg.device)))\n",
        "        self.register_buffer(\"window\", torch.ones(cfg.height, cfg.width, device=cfg.device))\n",
        "        \n",
        "        # Band blocks: input = 2 (real/imag) only - NO ctrl_embed\n",
        "        self.bands = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(2, cfg.channels, 3, padding=1), nn.GELU(),\n",
        "                nn.Conv2d(cfg.channels, cfg.channels, 3, padding=1), nn.GELU(),\n",
        "                nn.Conv2d(cfg.channels, 2, 1),\n",
        "            ) for _ in range(cfg.num_bands)\n",
        "        ])\n",
        "        \n",
        "        # Temporal\n",
        "        tdim = cfg.num_bands * 2 * 4\n",
        "        self.t_in = nn.Linear(tdim, cfg.channels * 8)\n",
        "        self.temporal = TopKTemporal(cfg.channels * 8, cfg.num_heads, cfg.history_len + 1, cfg.top_k, cfg.decay)\n",
        "        self.t_out = nn.Linear(cfg.channels * 8, tdim)\n",
        "        self.to(cfg.device)\n",
        "    \n",
        "    def forward(self, x, ctrl, history=None):\n",
        "        B = x.shape[0]\n",
        "        \n",
        "        # PRE-FFT: Apply control spatially BEFORE FFT\n",
        "        ctrl_spatial = self.ctrl_enc(ctrl)  # [B, 1, H, W]\n",
        "        x_conditioned = x + ctrl_spatial\n",
        "        \n",
        "        # FFT decompose on conditioned input\n",
        "        fft = torch.fft.fftshift(torch.fft.fft2(x_conditioned.squeeze(1) * self.window))\n",
        "        proc_bands = []\n",
        "        for i in range(self.cfg.num_bands):\n",
        "            band = fft * self.masks[i].unsqueeze(0)\n",
        "            band_feat = torch.stack([band.real, band.imag], dim=1)\n",
        "            # No control concat here - just process the band\n",
        "            proc = self.bands[i](band_feat)\n",
        "            proc_bands.append(band_feat + proc)\n",
        "        \n",
        "        # Pool for temporal\n",
        "        pooled = torch.cat([F.adaptive_avg_pool2d(b, (2,2)).flatten(1) for b in proc_bands], dim=1)\n",
        "        \n",
        "        # Temporal attention\n",
        "        if history and len(history) > 0:\n",
        "            history = [h for h in history if h.shape[0] == B and h.shape[1] == pooled.shape[1]]\n",
        "            if history:\n",
        "                seq = torch.stack(history + [pooled], dim=1)\n",
        "                t_out, _ = self.temporal(self.t_in(seq))\n",
        "                t_feat = self.t_out(t_out[:, -1, :])\n",
        "                chunk = pooled.shape[1] // self.cfg.num_bands\n",
        "                for i in range(self.cfg.num_bands):\n",
        "                    delta = t_feat[:, i*chunk:(i+1)*chunk].view(B, 2, 2, 2)\n",
        "                    delta_up = delta.repeat_interleave(self.cfg.height//2, 2).repeat_interleave(self.cfg.width//2, 3)\n",
        "                    proc_bands[i] = proc_bands[i] + 0.1 * delta_up\n",
        "        \n",
        "        # Reconstruct\n",
        "        recon = sum(torch.complex(b[:,0], b[:,1]) * self.masks[i].unsqueeze(0) for i, b in enumerate(proc_bands))\n",
        "        pred = torch.fft.ifft2(torch.fft.ifftshift(recon)).real.unsqueeze(1)\n",
        "        \n",
        "        return pred, {\"feat\": pooled.detach()}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FlatWithControl: Baseline ConvNet\n",
        "# ============================================================================\n",
        "\n",
        "class FlatWithControl(nn.Module):\n",
        "    \"\"\"Flat ConvNet baseline with control conditioning.\"\"\"\n",
        "    \n",
        "    def __init__(self, height, width, channels, num_actuators, horizon, ctrl_embed, actuator_maps=None, mode='known', device='cpu'):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        \n",
        "        if mode == 'known':\n",
        "            self.ctrl_enc = ControlEncoderKnownFlat(actuator_maps, horizon, ctrl_embed)\n",
        "        else:\n",
        "            self.ctrl_enc = ControlEncoderLearnedFlat(num_actuators, horizon, ctrl_embed, height, width)\n",
        "        \n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1 + ctrl_embed, channels, 3, padding=1), nn.GELU(),\n",
        "            nn.Conv2d(channels, channels*2, 3, padding=1), nn.GELU(),\n",
        "            nn.Conv2d(channels*2, channels*2, 3, padding=1), nn.GELU(),\n",
        "            nn.Conv2d(channels*2, channels, 3, padding=1), nn.GELU(),\n",
        "            nn.Conv2d(channels, 1, 3, padding=1),\n",
        "        )\n",
        "        self.to(device)\n",
        "    \n",
        "    def forward(self, x, ctrl, history=None):\n",
        "        ctrl_feat = self.ctrl_enc(ctrl)\n",
        "        return self.net(torch.cat([x, ctrl_feat], dim=1)), {}\n",
        "\n",
        "print(\"Models defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, data, epochs, lr, device, delta=True, batch=32):\n",
        "    fields, targets, ctrls = [d.to(device) for d in data]\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    \n",
        "    for ep in range(epochs):\n",
        "        t0 = time.time()\n",
        "        ep_loss, history = [], []\n",
        "        perm = torch.randperm(len(fields))\n",
        "        \n",
        "        for i in range(0, len(fields), batch):\n",
        "            idx = perm[i:i+batch]\n",
        "            x, y, c = fields[idx], targets[idx], ctrls[idx]\n",
        "            \n",
        "            pred, info = model(x, c, history if history else None)\n",
        "            \n",
        "            loss = F.mse_loss(pred - x, y - x) if delta else F.mse_loss(pred, y)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            ep_loss.append(loss.item())\n",
        "            \n",
        "            if \"feat\" in info:\n",
        "                history.append(info[\"feat\"])\n",
        "                history = history[-8:]\n",
        "        \n",
        "        avg = sum(ep_loss) / len(ep_loss)\n",
        "        losses.append(avg)\n",
        "        print(f\"  Ep {ep+1}/{epochs}: loss={avg:.6f}, time={time.time()-t0:.1f}s\")\n",
        "    \n",
        "    return losses\n",
        "\n",
        "print(\"Training function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Ablation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "print(\"[1] Creating environment...\")\n",
        "plasma_cfg = PlasmaConfig.turbulent(device=DEVICE, size=GRID_SIZE)\n",
        "env = TurbulentPlasmaEnv(plasma_cfg)\n",
        "actuator_maps = env.get_actuator_maps()\n",
        "print(f\"    Actuator maps shape: {actuator_maps.shape}\")\n",
        "\n",
        "print(\"\\n[2] Generating data...\")\n",
        "data = generate_trajectories(env, NUM_TRAJECTORIES, TRAJECTORY_LENGTH, 0.1, PREDICTION_HORIZON)\n",
        "print(f\"    Fields: {data[0].shape}, Controls: {data[2].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create all 5 models for ablation\n",
        "print(\"\\n[3] Creating models...\")\n",
        "\n",
        "cfg = SpectralConfig(height=GRID_SIZE, width=GRID_SIZE, horizon=PREDICTION_HORIZON, \n",
        "                     ctrl_embed=CONTROL_EMBED_DIM, device=DEVICE)\n",
        "\n",
        "models = {\n",
        "    # Post-FFT (flawed design) - for comparison\n",
        "    'SBM_PostFFT_Known': SBMPostFFT(cfg, actuator_maps),\n",
        "    \n",
        "    # Pre-FFT (correct design) - known maps\n",
        "    'SBM_PreFFT_Known': SBMPreFFT(cfg, actuator_maps, mode='known'),\n",
        "    \n",
        "    # Pre-FFT (correct design) - learned maps\n",
        "    'SBM_PreFFT_Learned': SBMPreFFT(cfg, None, mode='learned'),\n",
        "    \n",
        "    # Flat baselines\n",
        "    'Flat_Known': FlatWithControl(GRID_SIZE, GRID_SIZE, 32, NUM_ACTUATORS, PREDICTION_HORIZON, \n",
        "                                   CONTROL_EMBED_DIM, actuator_maps, 'known', DEVICE),\n",
        "    'Flat_Learned': FlatWithControl(GRID_SIZE, GRID_SIZE, 32, NUM_ACTUATORS, PREDICTION_HORIZON,\n",
        "                                     CONTROL_EMBED_DIM, None, 'learned', DEVICE),\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"    {name}: {params:,} params\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {name}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "    results[name] = train(model, data, EPOCHS, LR, DEVICE, PREDICT_DELTA, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss curves\n",
        "ax = axes[0]\n",
        "colors = {'SBM_PostFFT_Known': 'red', 'SBM_PreFFT_Known': 'blue', \n",
        "          'SBM_PreFFT_Learned': 'lightblue', 'Flat_Known': 'green', 'Flat_Learned': 'lightgreen'}\n",
        "for name, losses in results.items():\n",
        "    ax.semilogy(losses, label=f\"{name}: {losses[-1]:.6f}\", color=colors.get(name, 'gray'))\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss (MSE)')\n",
        "ax.set_title('Pre-FFT vs Post-FFT Control Conditioning Ablation')\n",
        "ax.legend(fontsize=8)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Final comparison bar chart\n",
        "ax = axes[1]\n",
        "names = list(results.keys())\n",
        "finals = [results[n][-1] for n in names]\n",
        "bar_colors = [colors.get(n, 'gray') for n in names]\n",
        "bars = ax.bar(range(len(names)), finals, color=bar_colors)\n",
        "ax.set_xticks(range(len(names)))\n",
        "ax.set_xticklabels([n.replace('_', '\\n') for n in names], fontsize=8)\n",
        "ax.set_ylabel('Final Loss')\n",
        "ax.set_title('Final Loss Comparison')\n",
        "for bar, val in zip(bars, finals):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{val:.5f}', \n",
        "            ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ABLATION RESULTS: Pre-FFT vs Post-FFT Control Conditioning\")\n",
        "print(\"=\"*70)\n",
        "for name, losses in results.items():\n",
        "    improvement = losses[0] / losses[-1]\n",
        "    print(f\"{name:20s}: {losses[-1]:.6f} ({improvement:.1f}x improvement)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KEY COMPARISONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "post_known = results['SBM_PostFFT_Known'][-1]\n",
        "pre_known = results['SBM_PreFFT_Known'][-1]\n",
        "pre_learned = results['SBM_PreFFT_Learned'][-1]\n",
        "flat_known = results['Flat_Known'][-1]\n",
        "flat_learned = results['Flat_Learned'][-1]\n",
        "\n",
        "print(f\"\\n1. POST-FFT vs PRE-FFT (both with known maps):\")\n",
        "print(f\"   PostFFT: {post_known:.6f}\")\n",
        "print(f\"   PreFFT:  {pre_known:.6f}\")\n",
        "diff = (post_known - pre_known) / post_known * 100\n",
        "print(f\"   Difference: {diff:+.1f}% {'(PreFFT better)' if diff > 0 else '(PostFFT better)'}\")\n",
        "\n",
        "print(f\"\\n2. KNOWN vs LEARNED (Pre-FFT design):\")\n",
        "print(f\"   Known:   {pre_known:.6f}\")\n",
        "print(f\"   Learned: {pre_learned:.6f}\")\n",
        "diff = (pre_learned - pre_known) / pre_known * 100\n",
        "print(f\"   Difference: {diff:+.1f}%\")\n",
        "\n",
        "print(f\"\\n3. SBM vs FLAT (both known):\")\n",
        "print(f\"   SBM PreFFT: {pre_known:.6f}\")\n",
        "print(f\"   Flat:       {flat_known:.6f}\")\n",
        "diff = (pre_known - flat_known) / flat_known * 100\n",
        "print(f\"   Difference: {diff:+.1f}%\")\n",
        "\n",
        "print(f\"\\n4. SBM vs FLAT (both learned):\")\n",
        "print(f\"   SBM PreFFT: {pre_learned:.6f}\")\n",
        "print(f\"   Flat:       {flat_learned:.6f}\")\n",
        "diff = (pre_learned - flat_learned) / flat_learned * 100\n",
        "print(f\"   Difference: {diff:+.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize learned actuator maps\n",
        "print(\"\\nComparing Known vs Learned Actuator Maps (Pre-FFT SBM):\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 9, figsize=(18, 4))\n",
        "\n",
        "# Known maps (from environment)\n",
        "for i in range(9):\n",
        "    axes[0, i].imshow(actuator_maps[i].cpu(), cmap='viridis')\n",
        "    axes[0, i].set_title(f'Known {i}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "# Learned maps (from SBM_PreFFT_Learned)\n",
        "learned_maps = models['SBM_PreFFT_Learned'].ctrl_enc.get_learned_maps().cpu()\n",
        "for i in range(9):\n",
        "    axes[1, i].imshow(learned_maps[i], cmap='viridis')\n",
        "    axes[1, i].set_title(f'Learned {i}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "axes[0, 0].set_ylabel('Known\\n(Physics)', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Learned\\n(PreFFT SBM)', fontsize=12)\n",
        "\n",
        "plt.suptitle('Pre-FFT Control: Spatial Locality Preserved?', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey question: Are learned maps localized Gaussians at different positions?\")\n",
        "print(\"(vs identical concentric rings as seen with Post-FFT conditioning)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Also show Flat_Learned maps for comparison\n",
        "print(\"\\nFlat Baseline Learned Maps (for comparison):\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 9, figsize=(18, 2))\n",
        "\n",
        "flat_learned_maps = models['Flat_Learned'].ctrl_enc.get_learned_maps().cpu()\n",
        "for i in range(9):\n",
        "    axes[i].imshow(flat_learned_maps[i], cmap='viridis')\n",
        "    axes[i].set_title(f'Flat Learned {i}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Flat ConvNet Learned Actuator Maps', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "standard",
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
