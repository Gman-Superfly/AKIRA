{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 032: Mini AKIRA Plasma Controller\n",
    "\n",
    "**Purpose**: Test the 7+1 Spectral Belief Machine (SBM) architecture against baselines on a plasma field prediction task.\n",
    "\n",
    "**Key Features**:\n",
    "- 7 spectral bands (log-spaced FFT decomposition) + 1 temporal band\n",
    "- Delta prediction mode (predict change, not state)\n",
    "- Prediction horizon t+3 (harder task that penalizes identity copying)\n",
    "- Differential learning rates per band\n",
    "\n",
    "**Run on Colab with GPU**: Runtime -> Change runtime type -> A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "GRID_SIZE = 128  # 64, 128, or 256\n",
    "EPOCHS = 100\n",
    "DIFFICULTY = \"medium\"  # easy, medium, hard\n",
    "PREDICT_DELTA = True\n",
    "PREDICTION_HORIZON = 3\n",
    "NUM_TRAJECTORIES = 100\n",
    "TRAJECTORY_LENGTH = 100\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Grid size: {GRID_SIZE}x{GRID_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Difficulty: {DIFFICULTY}\")\n",
    "print(f\"Prediction mode: {'delta' if PREDICT_DELTA else 'absolute'}\")\n",
    "print(f\"Prediction horizon: t+{PREDICTION_HORIZON}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment: Mini Plasma Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class PlasmaConfig:\n",
    "    \"\"\"Configuration for the mini plasma environment.\n",
    "    \n",
    "    All spatial parameters (actuator_sigma, etc.) are automatically scaled\n",
    "    with grid size to maintain consistent dynamics across resolutions.\n",
    "    Base parameters are defined for 64x64 grid.\n",
    "    \"\"\"\n",
    "    height: int = 64\n",
    "    width: int = 64\n",
    "    # Physics (scale-independent)\n",
    "    diffusion: float = 0.25\n",
    "    advection: float = 0.08\n",
    "    noise_std: float = 0.02\n",
    "    disturbance_prob: float = 0.1\n",
    "    disturbance_strength: float = 0.15\n",
    "    # Spatial (base values for 64x64, will be scaled)\n",
    "    num_actuators: int = 9  # 3x3 grid of actuators\n",
    "    _base_actuator_sigma: float = 5.0  # Base sigma for 64x64\n",
    "    # Device\n",
    "    device: str = \"cpu\"\n",
    "    dtype: torch.dtype = torch.float32\n",
    "    \n",
    "    @property\n",
    "    def actuator_sigma(self) -> float:\n",
    "        \"\"\"Actuator sigma scaled to grid size (maintains ~8% of grid diameter).\"\"\"\n",
    "        scale = min(self.height, self.width) / 64.0\n",
    "        return self._base_actuator_sigma * scale\n",
    "    \n",
    "    @classmethod\n",
    "    def easy(cls, device: str = \"cpu\", size: int = 64) -> \"PlasmaConfig\":\n",
    "        return cls(height=size, width=size, diffusion=0.12, advection=0.02, noise_std=0.01,\n",
    "                   disturbance_prob=0.0, disturbance_strength=0.0, device=device)\n",
    "    \n",
    "    @classmethod\n",
    "    def medium(cls, device: str = \"cpu\", size: int = 64) -> \"PlasmaConfig\":\n",
    "        return cls(height=size, width=size, device=device)\n",
    "    \n",
    "    @classmethod\n",
    "    def hard(cls, device: str = \"cpu\", size: int = 64) -> \"PlasmaConfig\":\n",
    "        return cls(height=size, width=size, diffusion=0.4, advection=0.15, noise_std=0.05,\n",
    "                   disturbance_prob=0.2, disturbance_strength=0.25, device=device)\n",
    "\n",
    "\n",
    "class MiniPlasmaEnv:\n",
    "    \"\"\"A toy 2D plasma-like environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: PlasmaConfig):\n",
    "        self.cfg = cfg\n",
    "        self.device = torch.device(cfg.device)\n",
    "        self.dtype = cfg.dtype\n",
    "        self._actuator_maps = self._build_actuator_maps()\n",
    "        \n",
    "    def _build_actuator_maps(self) -> torch.Tensor:\n",
    "        h, w = self.cfg.height, self.cfg.width\n",
    "        yy, xx = torch.meshgrid(\n",
    "            torch.linspace(0, h - 1, h, device=self.device, dtype=self.dtype),\n",
    "            torch.linspace(0, w - 1, w, device=self.device, dtype=self.dtype),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        grid_n = int((self.cfg.num_actuators) ** 0.5)\n",
    "        if grid_n * grid_n < self.cfg.num_actuators:\n",
    "            grid_n += 1\n",
    "        centers_y = torch.linspace(h * 0.2, h * 0.8, grid_n, device=self.device, dtype=self.dtype)\n",
    "        centers_x = torch.linspace(w * 0.2, w * 0.8, grid_n, device=self.device, dtype=self.dtype)\n",
    "        centers = torch.cartesian_prod(centers_y, centers_x)[:self.cfg.num_actuators]\n",
    "        sig2 = self.cfg.actuator_sigma ** 2\n",
    "        bumps = []\n",
    "        for cy, cx in centers:\n",
    "            bump = torch.exp(-((yy - cy) ** 2 + (xx - cx) ** 2) / (2 * sig2))\n",
    "            bumps.append(bump)\n",
    "        return torch.stack(bumps, dim=0)\n",
    "    \n",
    "    def reset(self, batch_size: int = 1) -> torch.Tensor:\n",
    "        h, w = self.cfg.height, self.cfg.width\n",
    "        field = torch.zeros(batch_size, 1, h, w, device=self.device, dtype=self.dtype)\n",
    "        cy = torch.randint(int(h * 0.3), int(h * 0.7), (batch_size,), device=self.device)\n",
    "        cx = torch.randint(int(w * 0.3), int(w * 0.7), (batch_size,), device=self.device)\n",
    "        yy, xx = torch.meshgrid(\n",
    "            torch.arange(h, device=self.device, dtype=self.dtype),\n",
    "            torch.arange(w, device=self.device, dtype=self.dtype),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        sig2 = (self.cfg.actuator_sigma * 1.5) ** 2\n",
    "        for b in range(batch_size):\n",
    "            blob = torch.exp(-((yy - cy[b].float()) ** 2 + (xx - cx[b].float()) ** 2) / (2 * sig2))\n",
    "            field[b, 0] = blob\n",
    "        return field\n",
    "    \n",
    "    def step(self, field: torch.Tensor, control: torch.Tensor, noise: bool = True) -> torch.Tensor:\n",
    "        B = field.shape[0]\n",
    "        # Diffusion\n",
    "        lap = (-4 * field\n",
    "               + F.pad(field, (0, 0, 1, 0))[:, :, :-1, :]\n",
    "               + F.pad(field, (0, 0, 0, 1))[:, :, 1:, :]\n",
    "               + F.pad(field, (1, 0, 0, 0))[:, :, :, :-1]\n",
    "               + F.pad(field, (0, 1, 0, 0))[:, :, :, 1:])\n",
    "        diffused = field + self.cfg.diffusion * lap\n",
    "        # Advection\n",
    "        advected = (torch.roll(diffused, shifts=(1, -1), dims=(2, 3)) * self.cfg.advection\n",
    "                    + diffused * (1 - self.cfg.advection))\n",
    "        # Actuator forces\n",
    "        bumps = self._actuator_maps.unsqueeze(0).expand(B, -1, -1, -1)\n",
    "        control_expanded = control.unsqueeze(-1).unsqueeze(-1)\n",
    "        force = torch.sum(control_expanded * bumps, dim=1, keepdim=True)\n",
    "        next_field = advected + force\n",
    "        # Noise\n",
    "        if noise and self.cfg.noise_std > 0:\n",
    "            next_field = next_field + torch.randn_like(next_field) * self.cfg.noise_std\n",
    "        # Random disturbances\n",
    "        if self.cfg.disturbance_prob > 0 and torch.rand(1).item() < self.cfg.disturbance_prob:\n",
    "            h, w = self.cfg.height, self.cfg.width\n",
    "            cy = torch.randint(int(h * 0.2), int(h * 0.8), (1,)).item()\n",
    "            cx = torch.randint(int(w * 0.2), int(w * 0.8), (1,)).item()\n",
    "            yy, xx = torch.meshgrid(\n",
    "                torch.arange(h, device=self.device, dtype=self.dtype),\n",
    "                torch.arange(w, device=self.device, dtype=self.dtype),\n",
    "                indexing=\"ij\",\n",
    "            )\n",
    "            sig2 = (self.cfg.actuator_sigma * 1.5) ** 2\n",
    "            bump = torch.exp(-((yy - cy) ** 2 + (xx - cx) ** 2) / (2 * sig2))\n",
    "            sign = 2 * (torch.rand(1).item() > 0.5) - 1\n",
    "            disturbance = sign * self.cfg.disturbance_strength * bump.unsqueeze(0).unsqueeze(0)\n",
    "            next_field = next_field + disturbance.expand(B, -1, -1, -1)\n",
    "        return torch.clamp(next_field, min=-1.0, max=1.0)\n",
    "\n",
    "\n",
    "def generate_trajectories(\n",
    "    env: MiniPlasmaEnv,\n",
    "    num_trajectories: int,\n",
    "    trajectory_length: int,\n",
    "    control_scale: float = 0.1,\n",
    "    prediction_horizon: int = 1,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate training data with multi-step prediction (BATCHED - much faster).\n",
    "    \n",
    "    Generates all trajectories in parallel by using batch_size=num_trajectories.\n",
    "    This leverages GPU parallelism for massive speedup.\n",
    "    \"\"\"\n",
    "    # Generate all trajectories in parallel\n",
    "    field = env.reset(batch_size=num_trajectories)  # [N, 1, H, W]\n",
    "    trajectory = [field.clone()]\n",
    "    all_controls = []\n",
    "    \n",
    "    for _ in range(trajectory_length + prediction_horizon):\n",
    "        control = torch.randn(num_trajectories, env.cfg.num_actuators, \n",
    "                              device=env.device, dtype=env.dtype) * control_scale\n",
    "        control = torch.clamp(control, -1, 1)\n",
    "        next_field = env.step(field, control, noise=True)\n",
    "        trajectory.append(next_field.clone())\n",
    "        all_controls.append(control)\n",
    "        field = next_field.detach()\n",
    "    \n",
    "    # Extract (input, target) pairs for all trajectories\n",
    "    fields_list = []\n",
    "    targets_list = []\n",
    "    controls_list = []\n",
    "    \n",
    "    for t in range(trajectory_length):\n",
    "        fields_list.append(trajectory[t])  # [N, 1, H, W]\n",
    "        targets_list.append(trajectory[t + prediction_horizon])  # [N, 1, H, W]\n",
    "        controls_list.append(all_controls[t])  # [N, num_actuators]\n",
    "    \n",
    "    # Stack and reshape: [T, N, ...] -> [T*N, ...]\n",
    "    fields = torch.cat(fields_list, dim=0)  # [T*N, 1, H, W]\n",
    "    targets = torch.cat(targets_list, dim=0)  # [T*N, 1, H, W]\n",
    "    controls = torch.cat(controls_list, dim=0)  # [T*N, num_actuators]\n",
    "    \n",
    "    return fields, targets, controls\n",
    "\n",
    "print(\"Environment defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spectral Belief Machine (7+1 Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SpectralConfig:\n",
    "    \"\"\"Configuration for the Spectral Belief Machine.\"\"\"\n",
    "    height: int = 64\n",
    "    width: int = 64\n",
    "    num_spectral_bands: int = 7\n",
    "    channels_per_band: int = 16\n",
    "    history_len: int = 4\n",
    "    num_heads: int = 4\n",
    "    # Windowing OFF by default - causes edge artifacts in loss\n",
    "    use_windowing: bool = False\n",
    "    band_lr_multipliers: List[float] = field(default_factory=lambda: [\n",
    "        0.001, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 0.1\n",
    "    ])\n",
    "    device: str = \"cpu\"\n",
    "    dtype: torch.dtype = torch.float32\n",
    "\n",
    "\n",
    "def make_hamming_window(h: int, w: int, device: torch.device) -> torch.Tensor:\n",
    "    wy = torch.hamming_window(h, device=device)\n",
    "    wx = torch.hamming_window(w, device=device)\n",
    "    return wy.unsqueeze(1) * wx.unsqueeze(0)\n",
    "\n",
    "\n",
    "def make_radial_masks(h: int, w: int, num_bands: int, device: torch.device) -> torch.Tensor:\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.linspace(-1.0, 1.0, h, device=device),\n",
    "        torch.linspace(-1.0, 1.0, w, device=device),\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "    rr = torch.sqrt(yy ** 2 + xx ** 2).clamp(min=1e-6)\n",
    "    edges = torch.logspace(-3, math.log10(math.sqrt(2)), steps=num_bands + 1, device=device)\n",
    "    edges[0] = 0.0\n",
    "    masks = []\n",
    "    for i in range(num_bands):\n",
    "        lo, hi = edges[i], edges[i + 1]\n",
    "        mask = torch.sigmoid((rr - lo) * 20) * torch.sigmoid((hi - rr) * 20)\n",
    "        masks.append(mask)\n",
    "    masks = torch.stack(masks, dim=0)\n",
    "    return masks / (masks.sum(dim=0, keepdim=True) + 1e-8)\n",
    "\n",
    "\n",
    "class PerBandBlock(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(2, channels, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channels, 2, kernel_size=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TemporalBand(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int, max_len: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        self.register_buffer(\"causal_mask\", torch.triu(torch.ones(max_len, max_len), diagonal=1).bool())\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        B, T, D = x.shape\n",
    "        Q = self.q_proj(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_proj(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_proj(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        scores = scores.masked_fill(self.causal_mask[:T, :T].unsqueeze(0).unsqueeze(0), float('-inf'))\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn_avg = attn.mean(dim=1)\n",
    "        entropy = -(attn_avg * torch.log(attn_avg + 1e-9)).sum(dim=-1).mean(dim=1)\n",
    "        out = torch.matmul(attn, V).transpose(1, 2).contiguous().view(B, T, D)\n",
    "        return self.out_proj(out), entropy\n",
    "\n",
    "\n",
    "class SpectralBeliefMachine(nn.Module):\n",
    "    \"\"\"Complete 7+1 Spectral Belief Machine.\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: SpectralConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        # Windowing (optional - OFF by default)\n",
    "        if cfg.use_windowing:\n",
    "            self.register_buffer(\"window\", make_hamming_window(cfg.height, cfg.width, torch.device(cfg.device)))\n",
    "        else:\n",
    "            self.register_buffer(\"window\", torch.ones(cfg.height, cfg.width, device=torch.device(cfg.device)))\n",
    "        self.register_buffer(\"masks\", make_radial_masks(cfg.height, cfg.width, cfg.num_spectral_bands, torch.device(cfg.device)))\n",
    "        self.band_blocks = nn.ModuleList([PerBandBlock(cfg.channels_per_band) for _ in range(cfg.num_spectral_bands)])\n",
    "        temporal_dim = cfg.num_spectral_bands * 2 * 4\n",
    "        self.temporal_proj_in = nn.Linear(temporal_dim, cfg.channels_per_band * 8)\n",
    "        self.temporal_band = TemporalBand(cfg.channels_per_band * 8, cfg.num_heads, cfg.history_len)\n",
    "        self.temporal_proj_out = nn.Linear(cfg.channels_per_band * 8, temporal_dim)\n",
    "        self.to(cfg.device)\n",
    "    \n",
    "    def _fft_decompose(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        x_windowed = x.squeeze(1) * self.window\n",
    "        fft = torch.fft.fft2(x_windowed)\n",
    "        fft_shifted = torch.fft.fftshift(fft)\n",
    "        bands = []\n",
    "        for i in range(self.cfg.num_spectral_bands):\n",
    "            mask = self.masks[i].unsqueeze(0)\n",
    "            band_fft = fft_shifted * mask\n",
    "            band_feat = torch.stack([band_fft.real, band_fft.imag], dim=1)\n",
    "            bands.append(band_feat)\n",
    "        return bands\n",
    "    \n",
    "    def _fft_reconstruct(self, bands: List[torch.Tensor]) -> torch.Tensor:\n",
    "        fft_recon = torch.zeros(bands[0].shape[0], self.cfg.height, self.cfg.width,\n",
    "                                dtype=torch.complex64, device=bands[0].device)\n",
    "        for i, band in enumerate(bands):\n",
    "            mask = self.masks[i].unsqueeze(0)\n",
    "            band_complex = torch.complex(band[:, 0], band[:, 1])\n",
    "            fft_recon = fft_recon + band_complex * mask\n",
    "        fft_unshifted = torch.fft.ifftshift(fft_recon)\n",
    "        return torch.fft.ifft2(fft_unshifted).real.unsqueeze(1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, history: Optional[List[torch.Tensor]] = None\n",
    "                ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        B = x.shape[0]\n",
    "        bands = self._fft_decompose(x)\n",
    "        processed_bands = [self.band_blocks[i](bands[i]) for i in range(self.cfg.num_spectral_bands)]\n",
    "        \n",
    "        # Compute band entropies\n",
    "        band_entropies = []\n",
    "        for band in processed_bands:\n",
    "            mag = torch.sqrt(band[:, 0] ** 2 + band[:, 1] ** 2 + 1e-8)\n",
    "            mag_norm = mag / (mag.sum(dim=[1, 2], keepdim=True) + 1e-8)\n",
    "            entropy = -(mag_norm * torch.log(mag_norm + 1e-9)).sum(dim=[1, 2])\n",
    "            band_entropies.append(entropy)\n",
    "        \n",
    "        # Pool band features for temporal processing\n",
    "        pooled_bands = [F.adaptive_avg_pool2d(band, (2, 2)).flatten(1) for band in processed_bands]\n",
    "        band_feats = torch.cat(pooled_bands, dim=1)\n",
    "        \n",
    "        # Temporal processing\n",
    "        if history is None:\n",
    "            history = []\n",
    "        valid_history = [h for h in history if h.ndim == 2 and h.shape[0] == B and h.shape[1] == band_feats.shape[1]]\n",
    "        history_seq = valid_history + [band_feats]\n",
    "        while len(history_seq) < self.cfg.history_len:\n",
    "            history_seq.insert(0, torch.zeros_like(band_feats))\n",
    "        history_seq = history_seq[-self.cfg.history_len:]\n",
    "        \n",
    "        temporal_seq = torch.stack(history_seq, dim=1)\n",
    "        temporal_in = self.temporal_proj_in(temporal_seq)\n",
    "        temporal_out, temporal_entropy = self.temporal_band(temporal_in)\n",
    "        temporal_out = self.temporal_proj_out(temporal_out)\n",
    "        \n",
    "        # Reconstruct\n",
    "        pred = self._fft_reconstruct(processed_bands)\n",
    "        \n",
    "        # Belief state\n",
    "        entropy_tensor = torch.stack(band_entropies, dim=1)\n",
    "        padded_entropy = F.pad(entropy_tensor, (0, 1))\n",
    "        padded_entropy[:, -1] = temporal_entropy\n",
    "        \n",
    "        belief_state = {\n",
    "            \"band_entropy\": padded_entropy,\n",
    "            \"global_entropy\": padded_entropy.sum(dim=1),\n",
    "            \"band_features\": band_feats,\n",
    "        }\n",
    "        return pred, belief_state\n",
    "    \n",
    "    def get_lr_groups(self, base_lr: float) -> List[dict]:\n",
    "        groups = []\n",
    "        for i, block in enumerate(self.band_blocks):\n",
    "            groups.append({\"params\": block.parameters(), \"lr\": base_lr * self.cfg.band_lr_multipliers[i]})\n",
    "        groups.append({\"params\": list(self.temporal_proj_in.parameters()) +\n",
    "                                  list(self.temporal_band.parameters()) +\n",
    "                                  list(self.temporal_proj_out.parameters()),\n",
    "                       \"lr\": base_lr * self.cfg.band_lr_multipliers[-1]})\n",
    "        return groups\n",
    "\n",
    "print(\"SpectralBeliefMachine defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaselineConfig:\n",
    "    height: int = 64\n",
    "    width: int = 64\n",
    "    channels: int = 32\n",
    "    device: str = \"cpu\"\n",
    "    dtype: torch.dtype = torch.float32\n",
    "\n",
    "\n",
    "class FlatBaseline(nn.Module):\n",
    "    \"\"\"Flat ConvNet baseline - NO residual skip (fair comparison).\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: BaselineConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, cfg.channels, kernel_size=3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(cfg.channels, cfg.channels, kernel_size=3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(cfg.channels, cfg.channels * 2, kernel_size=3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(cfg.channels * 2, cfg.channels * 2, kernel_size=3, padding=1), nn.GELU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(cfg.channels * 2, cfg.channels * 2, kernel_size=3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(cfg.channels * 2, cfg.channels, kernel_size=3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(cfg.channels, cfg.channels, kernel_size=3, padding=1), nn.GELU(),\n",
    "            nn.Conv2d(cfg.channels, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "        self.to(cfg.device)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, history: Optional[List[torch.Tensor]] = None\n",
    "                ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        pred = self.decoder(self.encoder(x))\n",
    "        # NO residual skip - model must learn dynamics\n",
    "        B = x.shape[0]\n",
    "        belief_state = {\n",
    "            \"band_entropy\": torch.zeros(B, 8, device=x.device),\n",
    "            \"global_entropy\": torch.zeros(B, device=x.device),\n",
    "            \"band_features\": torch.zeros(B, 56, device=x.device),\n",
    "        }\n",
    "        return pred, belief_state\n",
    "\n",
    "\n",
    "class FourBandBaseline(nn.Module):\n",
    "    \"\"\"4-band spectral baseline (tests if 7 bands is better than fewer).\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: BaselineConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.num_bands = 4\n",
    "        self.register_buffer(\"masks\", self._make_masks(cfg.height, cfg.width))\n",
    "        self.band_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(2, cfg.channels, kernel_size=3, padding=1), nn.GELU(),\n",
    "                nn.Conv2d(cfg.channels, cfg.channels, kernel_size=3, padding=1), nn.GELU(),\n",
    "                nn.Conv2d(cfg.channels, 2, kernel_size=1),\n",
    "            ) for _ in range(self.num_bands)\n",
    "        ])\n",
    "        self.to(cfg.device)\n",
    "    \n",
    "    def _make_masks(self, h: int, w: int) -> torch.Tensor:\n",
    "        yy, xx = torch.meshgrid(torch.linspace(-1, 1, h), torch.linspace(-1, 1, w), indexing=\"ij\")\n",
    "        rr = torch.sqrt(yy ** 2 + xx ** 2).clamp(min=1e-6)\n",
    "        edges = torch.logspace(-2, math.log10(math.sqrt(2)), steps=5)\n",
    "        edges[0] = 0\n",
    "        masks = [torch.sigmoid((rr - edges[i]) * 20) * torch.sigmoid((edges[i+1] - rr) * 20) for i in range(4)]\n",
    "        masks = torch.stack(masks, dim=0)\n",
    "        return masks / (masks.sum(dim=0, keepdim=True) + 1e-8)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, history: Optional[List[torch.Tensor]] = None\n",
    "                ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        B = x.shape[0]\n",
    "        fft = torch.fft.fft2(x.squeeze(1))\n",
    "        fft_shifted = torch.fft.fftshift(fft)\n",
    "        processed_bands, band_entropies = [], []\n",
    "        for i in range(self.num_bands):\n",
    "            mask = self.masks[i].unsqueeze(0).to(x.device)\n",
    "            band_fft = fft_shifted * mask\n",
    "            band_feat = torch.stack([band_fft.real, band_fft.imag], dim=1)\n",
    "            processed = self.band_blocks[i](band_feat)\n",
    "            processed_bands.append(processed)\n",
    "            mag = torch.sqrt(processed[:, 0] ** 2 + processed[:, 1] ** 2 + 1e-8)\n",
    "            mag_norm = mag / (mag.sum(dim=[1, 2], keepdim=True) + 1e-8)\n",
    "            band_entropies.append(-(mag_norm * torch.log(mag_norm + 1e-9)).sum(dim=[1, 2]))\n",
    "        \n",
    "        fft_recon = torch.zeros_like(fft_shifted)\n",
    "        for i, band in enumerate(processed_bands):\n",
    "            mask = self.masks[i].unsqueeze(0).to(x.device)\n",
    "            fft_recon = fft_recon + torch.complex(band[:, 0], band[:, 1]) * mask\n",
    "        pred = torch.fft.ifft2(torch.fft.ifftshift(fft_recon)).real.unsqueeze(1)\n",
    "        \n",
    "        entropy_tensor = torch.stack(band_entropies, dim=1)\n",
    "        belief_state = {\n",
    "            \"band_entropy\": F.pad(entropy_tensor, (0, 4)),\n",
    "            \"global_entropy\": entropy_tensor.sum(dim=1),\n",
    "            \"band_features\": torch.zeros(B, 56, device=x.device),\n",
    "        }\n",
    "        return pred, belief_state\n",
    "\n",
    "print(\"Baselines defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predictor(\n",
    "    model: nn.Module,\n",
    "    train_data: Tuple[torch.Tensor, torch.Tensor],\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    device: str,\n",
    "    use_differential_lr: bool = False,\n",
    "    predict_delta: bool = True,\n",
    "    batch_size: int = 32,\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Train a predictor on next-frame prediction.\"\"\"\n",
    "    fields, next_fields = train_data\n",
    "    fields = fields.to(device)\n",
    "    next_fields = next_fields.to(device)\n",
    "    \n",
    "    if use_differential_lr and hasattr(model, 'get_lr_groups'):\n",
    "        optimizer = optim.Adam(model.get_lr_groups(lr))\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    metrics = {\"loss\": [], \"epoch_time\": []}\n",
    "    num_samples = fields.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        epoch_losses = []\n",
    "        history = []\n",
    "        perm = torch.randperm(num_samples)\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            idx = perm[i:i + batch_size]\n",
    "            x = fields[idx]\n",
    "            y = next_fields[idx]\n",
    "            \n",
    "            pred, belief = model(x, history if history else None)\n",
    "            \n",
    "            if predict_delta:\n",
    "                delta_target = y - x\n",
    "                delta_pred = pred - x\n",
    "                loss = F.mse_loss(delta_pred, delta_target)\n",
    "            else:\n",
    "                loss = F.mse_loss(pred, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            if \"band_features\" in belief:\n",
    "                history = (history + [belief[\"band_features\"].detach()])[-4:]\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        mean_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        metrics[\"loss\"].append(mean_loss)\n",
    "        metrics[\"epoch_time\"].append(epoch_time)\n",
    "        \n",
    "        print(f\"  Epoch {epoch + 1}/{epochs}: loss={mean_loss:.6f}, time={epoch_time:.2f}s\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Training function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "print(\"[1] Initializing environment...\")\n",
    "if DIFFICULTY == \"easy\":\n",
    "    plasma_cfg = PlasmaConfig.easy(device=DEVICE, size=GRID_SIZE)\n",
    "elif DIFFICULTY == \"hard\":\n",
    "    plasma_cfg = PlasmaConfig.hard(device=DEVICE, size=GRID_SIZE)\n",
    "else:\n",
    "    plasma_cfg = PlasmaConfig.medium(device=DEVICE, size=GRID_SIZE)\n",
    "\n",
    "print(f\"    Diffusion: {plasma_cfg.diffusion}, Advection: {plasma_cfg.advection}\")\n",
    "print(f\"    Noise: {plasma_cfg.noise_std}, Disturbance: {plasma_cfg.disturbance_prob}@{plasma_cfg.disturbance_strength}\")\n",
    "print(f\"    Actuator sigma: {plasma_cfg.actuator_sigma:.1f} (scaled from base {plasma_cfg._base_actuator_sigma} for {GRID_SIZE}x{GRID_SIZE})\")\n",
    "\n",
    "env = MiniPlasmaEnv(plasma_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "print(\"[2] Generating training data...\")\n",
    "fields, next_fields, controls = generate_trajectories(\n",
    "    env, NUM_TRAJECTORIES, TRAJECTORY_LENGTH,\n",
    "    control_scale=0.1,\n",
    "    prediction_horizon=PREDICTION_HORIZON\n",
    ")\n",
    "print(f\"    Generated {fields.shape[0]} samples (predicting t+{PREDICTION_HORIZON})\")\n",
    "\n",
    "train_data = (fields, next_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "print(\"[3] Initializing models...\")\n",
    "\n",
    "spectral_cfg = SpectralConfig(height=GRID_SIZE, width=GRID_SIZE, device=DEVICE)\n",
    "sbm = SpectralBeliefMachine(spectral_cfg)\n",
    "print(f\"    SpectralBeliefMachine: {sum(p.numel() for p in sbm.parameters()):,} params\")\n",
    "\n",
    "baseline_cfg = BaselineConfig(height=GRID_SIZE, width=GRID_SIZE, device=DEVICE)\n",
    "flat = FlatBaseline(baseline_cfg)\n",
    "four_band = FourBandBaseline(baseline_cfg)\n",
    "\n",
    "print(f\"    FlatBaseline: {sum(p.numel() for p in flat.parameters()):,} params\")\n",
    "print(f\"    FourBandBaseline: {sum(p.numel() for p in four_band.parameters()):,} params\")\n",
    "\n",
    "# Verify GPU usage\n",
    "print(f\"\\n[GPU CHECK]\")\n",
    "print(f\"    Target device: {DEVICE}\")\n",
    "print(f\"    SBM on: {next(sbm.parameters()).device}\")\n",
    "print(f\"    Flat on: {next(flat.parameters()).device}\")\n",
    "print(f\"    Training data on: {fields.device}\")\n",
    "if DEVICE == 'cuda' and torch.cuda.is_available():\n",
    "    print(f\"    GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SpectralBeliefMachine (7+1)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training SpectralBeliefMachine (7+1)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sbm_metrics = train_predictor(\n",
    "    sbm, train_data, EPOCHS, lr=LR,\n",
    "    device=DEVICE, use_differential_lr=True,\n",
    "    predict_delta=PREDICT_DELTA, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FlatBaseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training FlatBaseline...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "flat_metrics = train_predictor(\n",
    "    flat, train_data, EPOCHS, lr=LR,\n",
    "    device=DEVICE, use_differential_lr=False,\n",
    "    predict_delta=PREDICT_DELTA, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FourBandBaseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training FourBandBaseline...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "four_band_metrics = train_predictor(\n",
    "    four_band, train_data, EPOCHS, lr=LR,\n",
    "    device=DEVICE, use_differential_lr=False,\n",
    "    predict_delta=PREDICT_DELTA, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax = axes[0]\n",
    "ax.plot(sbm_metrics[\"loss\"], label=f\"SBM (7+1) - final: {sbm_metrics['loss'][-1]:.6f}\", linewidth=2)\n",
    "ax.plot(flat_metrics[\"loss\"], label=f\"FlatBaseline - final: {flat_metrics['loss'][-1]:.6f}\", linewidth=2)\n",
    "ax.plot(four_band_metrics[\"loss\"], label=f\"FourBandBaseline - final: {four_band_metrics['loss'][-1]:.6f}\", linewidth=2)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss (MSE)\")\n",
    "ax.set_title(\"Training Loss Curves\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Time per epoch\n",
    "ax = axes[1]\n",
    "models = [\"SBM (7+1)\", \"FlatBaseline\", \"FourBand\"]\n",
    "times = [sum(sbm_metrics[\"epoch_time\"])/EPOCHS, \n",
    "         sum(flat_metrics[\"epoch_time\"])/EPOCHS,\n",
    "         sum(four_band_metrics[\"epoch_time\"])/EPOCHS]\n",
    "ax.bar(models, times, color=['tab:blue', 'tab:orange', 'tab:green'])\n",
    "ax.set_ylabel(\"Seconds per Epoch\")\n",
    "ax.set_title(\"Training Speed\")\n",
    "for i, t in enumerate(times):\n",
    "    ax.text(i, t + 1, f\"{t:.1f}s\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"SpectralBeliefMachine (7+1): {sbm_metrics['loss'][-1]:.6f}\")\n",
    "print(f\"FlatBaseline:                {flat_metrics['loss'][-1]:.6f}\")\n",
    "print(f\"FourBandBaseline:            {four_band_metrics['loss'][-1]:.6f}\")\n",
    "print()\n",
    "print(f\"SBM improvement over epochs: {sbm_metrics['loss'][0]:.4f} -> {sbm_metrics['loss'][-1]:.4f} ({sbm_metrics['loss'][0]/sbm_metrics['loss'][-1]:.1f}x)\")\n",
    "print(f\"Flat improvement over epochs: {flat_metrics['loss'][0]:.4f} -> {flat_metrics['loss'][-1]:.4f} ({flat_metrics['loss'][0]/flat_metrics['loss'][-1]:.1f}x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "print(\"\\nVisualizing sample predictions...\")\n",
    "\n",
    "# Get a sample\n",
    "idx = 500\n",
    "x_sample = fields[idx:idx+1].to(DEVICE)\n",
    "y_sample = next_fields[idx:idx+1].to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sbm_pred, _ = sbm(x_sample, None)\n",
    "    flat_pred, _ = flat(x_sample, None)\n",
    "    four_pred, _ = four_band(x_sample, None)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Row 1: Fields\n",
    "axes[0, 0].imshow(x_sample[0, 0].cpu().numpy(), cmap='viridis')\n",
    "axes[0, 0].set_title('Input (t)')\n",
    "axes[0, 1].imshow(y_sample[0, 0].cpu().numpy(), cmap='viridis')\n",
    "axes[0, 1].set_title(f'Target (t+{PREDICTION_HORIZON})')\n",
    "axes[0, 2].imshow(sbm_pred[0, 0].cpu().numpy(), cmap='viridis')\n",
    "axes[0, 2].set_title('SBM Prediction')\n",
    "axes[0, 3].imshow(flat_pred[0, 0].cpu().numpy(), cmap='viridis')\n",
    "axes[0, 3].set_title('Flat Prediction')\n",
    "\n",
    "# Row 2: Errors\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 1].axis('off')\n",
    "sbm_err = torch.abs(sbm_pred - y_sample)[0, 0].cpu().numpy()\n",
    "flat_err = torch.abs(flat_pred - y_sample)[0, 0].cpu().numpy()\n",
    "vmax = max(sbm_err.max(), flat_err.max())\n",
    "im1 = axes[1, 2].imshow(sbm_err, cmap='hot', vmin=0, vmax=vmax)\n",
    "axes[1, 2].set_title(f'SBM Error (MSE: {sbm_err.mean():.4f})')\n",
    "im2 = axes[1, 3].imshow(flat_err, cmap='hot', vmin=0, vmax=vmax)\n",
    "axes[1, 3].set_title(f'Flat Error (MSE: {flat_err.mean():.4f})')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "Key observations:\n",
    "1. **SBM continues learning** - loss keeps dropping even after 30 epochs\n",
    "2. **FlatBaseline plateaus early** - learns quickly but stops improving\n",
    "3. **SBM has fewer parameters** (99K vs 130K) but competitive performance\n",
    "4. **Delta prediction mode** prevents identity copying shortcuts\n",
    "5. **Differential learning rates** allow progressive coarse-to-fine learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
