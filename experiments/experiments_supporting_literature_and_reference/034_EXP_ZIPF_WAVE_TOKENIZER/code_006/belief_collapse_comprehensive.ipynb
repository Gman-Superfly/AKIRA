{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Belief Collapse: Comprehensive Analysis\n",
        "\n",
        "This notebook consolidates the **valid, working approaches** for measuring belief collapse in transformers.\n",
        "\n",
        "## What we measure (and why it works)\n",
        "\n",
        "| Metric | What it captures | Why it's valid |\n",
        "|--------|------------------|----------------|\n",
        "| **Attention entropy** | How focused vs diffuse attention is | Direct measure of uncertainty |\n",
        "| **Output probability sharpening** | How the logit distribution tightens | Direct measure of belief collapse |\n",
        "| **Geometric alignment of heads** | Whether heads \"agree\" in vector space | No wave assumptions, pure geometry |\n",
        "| **Activation change across positions** | How information propagates | Uses actual sequence axis |\n",
        "| **Cosine similarity across layers** | Hidden state convergence | Measures representation stability |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import math\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib import cm\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "NOTEBOOK_DIR = Path.cwd()\n",
        "FIG_DIR = NOTEBOOK_DIR / \"figs_collapse\"\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load GPT-2\n",
        "model_name = \"gpt2\"\n",
        "print(f\"Loading {model_name}...\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "n_layers = model.config.n_layer\n",
        "n_heads = model.config.n_head\n",
        "d_model = model.config.n_embd\n",
        "d_head = d_model // n_heads\n",
        "print(f\"Model: {n_layers} layers, {n_heads} heads, d_model={d_model}, d_head={d_head}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference helper\n",
        "def run_inference(text: str) -> Dict:\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "    tokens = [tokenizer.decode([tid]) for tid in input_ids[0]]\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, output_attentions=True, output_hidden_states=True)\n",
        "    return {\n",
        "        \"tokens\": tokens,\n",
        "        \"input_ids\": input_ids,\n",
        "        \"logits\": outputs.logits.cpu(),\n",
        "        \"attentions\": [a.cpu() for a in outputs.attentions],\n",
        "        \"hidden_states\": [h.cpu() for h in outputs.hidden_states],\n",
        "        \"n_layers\": len(outputs.attentions),\n",
        "        \"n_heads\": outputs.attentions[0].size(1),\n",
        "        \"seq_len\": input_ids.size(1),\n",
        "    }\n",
        "\n",
        "print(\"run_inference() ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 1: Attention entropy across layers\n",
        "\n",
        "Directly measures how focused (low entropy) or diffuse (high entropy) the attention distribution is. No assumptions beyond the attention weights themselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_attention_entropy(attn: torch.Tensor) -> float:\n",
        "    \"\"\"Entropy of attention distribution. High = diffuse, Low = focused.\"\"\"\n",
        "    p = attn.clamp(min=1e-10)\n",
        "    entropy = -(p * p.log()).sum(dim=-1)\n",
        "    return entropy.mean().item()\n",
        "\n",
        "def attention_entropy_per_layer(result: Dict, query_pos: int = -1) -> List[float]:\n",
        "    \"\"\"Attention entropy at each layer for a given query position.\"\"\"\n",
        "    entropies = []\n",
        "    for attn in result[\"attentions\"]:\n",
        "        # attn: [1, heads, seq, seq]\n",
        "        q_attn = attn[0, :, query_pos, :]  # [heads, seq]\n",
        "        entropies.append(compute_attention_entropy(q_attn))\n",
        "    return entropies\n",
        "\n",
        "print(\"attention_entropy functions ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 2: Output probability sharpening (logit lens)\n",
        "\n",
        "Apply the output projection at each layer to see how the probability distribution evolves. Lower entropy = sharper = more confident.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def logit_lens(result: Dict, pos: int = -1) -> Tuple[List[float], List[str]]:\n",
        "    \"\"\"Apply output projection to hidden states at each layer.\n",
        "    \n",
        "    Returns:\n",
        "        entropies: Output entropy at each layer\n",
        "        top_tokens: Most likely token at each layer\n",
        "    \"\"\"\n",
        "    # Get the language model head (unembedding)\n",
        "    lm_head = model.lm_head\n",
        "    ln_f = model.transformer.ln_f  # final layer norm\n",
        "    \n",
        "    entropies = []\n",
        "    top_tokens = []\n",
        "    \n",
        "    for layer_idx, hidden in enumerate(result[\"hidden_states\"]):\n",
        "        # hidden: [1, seq, d_model]\n",
        "        h = hidden[0, pos, :]  # [d_model]\n",
        "        \n",
        "        # Apply final layer norm (for proper comparison)\n",
        "        h_normed = ln_f(h.to(device))\n",
        "        \n",
        "        # Project to vocab\n",
        "        logits = lm_head(h_normed)  # [vocab]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        \n",
        "        # Entropy\n",
        "        p = probs.clamp(min=1e-10)\n",
        "        entropy = -(p * p.log()).sum().item()\n",
        "        entropies.append(entropy)\n",
        "        \n",
        "        # Top token\n",
        "        top_id = probs.argmax().item()\n",
        "        top_tokens.append(tokenizer.decode([top_id]))\n",
        "    \n",
        "    return entropies, top_tokens\n",
        "\n",
        "print(\"logit_lens() ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 3: Geometric alignment of head outputs\n",
        "\n",
        "Measure whether attention heads \"agree\" by computing pairwise cosine similarity between head attention-weighted contexts. High agreement = heads are aligned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def head_context_vectors(result: Dict, layer_idx: int, query_pos: int = -1) -> np.ndarray:\n",
        "    \"\"\"Compute attention-weighted context vector for each head.\n",
        "    \n",
        "    Returns:\n",
        "        contexts: [n_heads, d_model] array of context vectors\n",
        "    \"\"\"\n",
        "    attn = result[\"attentions\"][layer_idx][0].numpy()  # [heads, seq, seq]\n",
        "    hidden_in = result[\"hidden_states\"][layer_idx][0].numpy()  # [seq, d_model]\n",
        "    \n",
        "    contexts = []\n",
        "    for h in range(attn.shape[0]):\n",
        "        weights = attn[h, query_pos, :]  # [seq]\n",
        "        ctx = weights @ hidden_in  # [d_model]\n",
        "        contexts.append(ctx)\n",
        "    return np.stack(contexts, axis=0)\n",
        "\n",
        "def head_alignment(result: Dict, layer_idx: int, query_pos: int = -1) -> float:\n",
        "    \"\"\"Mean pairwise cosine similarity between head context vectors.\"\"\"\n",
        "    contexts = head_context_vectors(result, layer_idx, query_pos)\n",
        "    n = contexts.shape[0]\n",
        "    \n",
        "    # Normalize\n",
        "    norms = np.linalg.norm(contexts, axis=1, keepdims=True) + 1e-10\n",
        "    contexts_normed = contexts / norms\n",
        "    \n",
        "    # Pairwise cosine similarity\n",
        "    sim_matrix = contexts_normed @ contexts_normed.T\n",
        "    \n",
        "    # Mean of upper triangle (excluding diagonal)\n",
        "    upper = sim_matrix[np.triu_indices(n, k=1)]\n",
        "    return float(upper.mean())\n",
        "\n",
        "def head_alignment_per_layer(result: Dict, query_pos: int = -1) -> List[float]:\n",
        "    \"\"\"Head alignment at each layer.\"\"\"\n",
        "    return [head_alignment(result, l, query_pos) for l in range(result[\"n_layers\"])]\n",
        "\n",
        "print(\"head_alignment functions ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 4: Activation change across token positions\n",
        "\n",
        "Measures how much the hidden state changes from one token position to the next. Uses the actual sequence axis (not embedding dimension).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def activation_change_across_positions(result: Dict, layer_idx: int) -> np.ndarray:\n",
        "    \"\"\"Cosine distance between consecutive position hidden states.\n",
        "    \n",
        "    Returns:\n",
        "        changes: [seq_len-1] array of cosine distances\n",
        "    \"\"\"\n",
        "    hidden = result[\"hidden_states\"][layer_idx][0].numpy()  # [seq, d_model]\n",
        "    seq_len = hidden.shape[0]\n",
        "    \n",
        "    if seq_len < 2:\n",
        "        return np.array([])\n",
        "    \n",
        "    # Normalize\n",
        "    norms = np.linalg.norm(hidden, axis=1, keepdims=True) + 1e-10\n",
        "    hidden_normed = hidden / norms\n",
        "    \n",
        "    # Consecutive cosine similarity -> distance\n",
        "    changes = []\n",
        "    for i in range(seq_len - 1):\n",
        "        sim = np.dot(hidden_normed[i], hidden_normed[i + 1])\n",
        "        changes.append(1 - sim)  # distance = 1 - similarity\n",
        "    \n",
        "    return np.array(changes)\n",
        "\n",
        "def mean_position_change_per_layer(result: Dict) -> List[float]:\n",
        "    \"\"\"Mean activation change across positions at each layer.\"\"\"\n",
        "    changes = []\n",
        "    for l in range(len(result[\"hidden_states\"])):\n",
        "        c = activation_change_across_positions(result, l)\n",
        "        changes.append(float(c.mean()) if len(c) > 0 else 0.0)\n",
        "    return changes\n",
        "\n",
        "print(\"activation_change functions ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric 5: Cosine similarity of hidden states across layers\n",
        "\n",
        "Measures how much the representation at a given position changes from layer to layer. Low change late = convergence/stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def layer_to_layer_similarity(result: Dict, pos: int = -1) -> List[float]:\n",
        "    \"\"\"Cosine similarity between consecutive layers at a given position.\n",
        "    \n",
        "    Returns:\n",
        "        sims: [n_layers] similarities (first is embedding -> layer0)\n",
        "    \"\"\"\n",
        "    hidden_states = result[\"hidden_states\"]  # len = n_layers + 1 (emb + layers)\n",
        "    sims = []\n",
        "    \n",
        "    for i in range(len(hidden_states) - 1):\n",
        "        h1 = hidden_states[i][0, pos, :].numpy()\n",
        "        h2 = hidden_states[i + 1][0, pos, :].numpy()\n",
        "        \n",
        "        # Cosine similarity\n",
        "        norm1 = np.linalg.norm(h1) + 1e-10\n",
        "        norm2 = np.linalg.norm(h2) + 1e-10\n",
        "        sim = np.dot(h1, h2) / (norm1 * norm2)\n",
        "        sims.append(float(sim))\n",
        "    \n",
        "    return sims\n",
        "\n",
        "def layer_similarity_to_final(result: Dict, pos: int = -1) -> List[float]:\n",
        "    \"\"\"Cosine similarity between each layer and the final layer representation.\n",
        "    \n",
        "    Returns:\n",
        "        sims: [n_layers+1] similarities to final layer\n",
        "    \"\"\"\n",
        "    hidden_states = result[\"hidden_states\"]\n",
        "    final = hidden_states[-1][0, pos, :].numpy()\n",
        "    final_norm = np.linalg.norm(final) + 1e-10\n",
        "    \n",
        "    sims = []\n",
        "    for i in range(len(hidden_states)):\n",
        "        h = hidden_states[i][0, pos, :].numpy()\n",
        "        h_norm = np.linalg.norm(h) + 1e-10\n",
        "        sim = np.dot(h, final) / (h_norm * final_norm)\n",
        "        sims.append(float(sim))\n",
        "    \n",
        "    return sims\n",
        "\n",
        "print(\"layer_similarity functions ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompts for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = {\n",
        "    # Factual (constrained, high confidence expected)\n",
        "    \"factual_capital\": \"The capital of France is\",\n",
        "    \"factual_sun\": \"The sun rises in the\",\n",
        "    \"factual_math\": \"Two plus two equals\",\n",
        "    \n",
        "    # Technical (specialized vocabulary)\n",
        "    \"technical_quantum\": \"The quantum mechanical wave function describes probability amplitudes\",\n",
        "    \"technical_code\": \"Write a Python function that returns the greatest common divisor\",\n",
        "    \n",
        "    # Open-ended (many valid continuations)\n",
        "    \"open_future\": \"In the distant future,\",\n",
        "    \"open_meaning\": \"The meaning of life is\",\n",
        "    \"open_door\": \"He opened the door and saw\",\n",
        "    \n",
        "    # Ambiguous/contradictory\n",
        "    \"ambiguous_circle\": \"Describe the color of a square circle\",\n",
        "    \"riddle\": \"I speak without a mouth and hear without ears; what am I?\",\n",
        "}\n",
        "\n",
        "print(f\"Loaded {len(prompts)} prompts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run comprehensive analysis on all prompts\n",
        "all_results = {}\n",
        "\n",
        "for name, prompt in prompts.items():\n",
        "    print(f\"Processing: {name}...\")\n",
        "    result = run_inference(prompt)\n",
        "    \n",
        "    # Compute all metrics\n",
        "    attn_entropy = attention_entropy_per_layer(result)\n",
        "    logit_entropy, top_tokens = logit_lens(result)\n",
        "    alignment = head_alignment_per_layer(result)\n",
        "    pos_change = mean_position_change_per_layer(result)\n",
        "    layer_sim = layer_to_layer_similarity(result)\n",
        "    sim_to_final = layer_similarity_to_final(result)\n",
        "    \n",
        "    # Final output\n",
        "    final_logits = result[\"logits\"][0, -1, :]\n",
        "    probs = F.softmax(final_logits, dim=-1)\n",
        "    final_entropy = -(probs * probs.clamp(min=1e-10).log()).sum().item()\n",
        "    top_token = tokenizer.decode([probs.argmax().item()])\n",
        "    \n",
        "    all_results[name] = {\n",
        "        \"prompt\": prompt,\n",
        "        \"tokens\": result[\"tokens\"],\n",
        "        \"top_token\": top_token,\n",
        "        \"final_entropy\": final_entropy,\n",
        "        \"attn_entropy\": attn_entropy,\n",
        "        \"logit_entropy\": logit_entropy,\n",
        "        \"top_tokens_by_layer\": top_tokens,\n",
        "        \"head_alignment\": alignment,\n",
        "        \"position_change\": pos_change,\n",
        "        \"layer_to_layer_sim\": layer_sim,\n",
        "        \"sim_to_final\": sim_to_final,\n",
        "    }\n",
        "\n",
        "print(\"\\nDone. All metrics computed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary table\n",
        "print(\"=\"*100)\n",
        "print(f\"{'Prompt':<30} {'Top Token':>12} {'Entropy':>8} {'Align(L11)':>10} {'SimFinal(L0)':>12}\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for name, r in all_results.items():\n",
        "    prompt_short = r[\"prompt\"][:28]\n",
        "    top = r[\"top_token\"].strip()[:10]\n",
        "    ent = r[\"final_entropy\"]\n",
        "    align = r[\"head_alignment\"][-1]\n",
        "    sim = r[\"sim_to_final\"][0]\n",
        "    print(f\"{prompt_short:<30} {top:>12} {ent:>8.2f} {align:>10.3f} {sim:>12.3f}\")\n",
        "\n",
        "print(\"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization 1: All metrics for a single interesting prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All metrics for the quantum prompt\n",
        "target = \"technical_quantum\"\n",
        "r = all_results[target]\n",
        "\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "gs = GridSpec(3, 2, figure=fig)\n",
        "\n",
        "layers = list(range(n_layers))\n",
        "\n",
        "# Attention entropy\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.plot(layers, r[\"attn_entropy\"], 'o-', color='crimson', linewidth=2)\n",
        "ax1.set_xlabel(\"Layer\")\n",
        "ax1.set_ylabel(\"Entropy (nats)\")\n",
        "ax1.set_title(\"Attention Entropy (lower = more focused)\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Logit lens entropy\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.plot(range(len(r[\"logit_entropy\"])), r[\"logit_entropy\"], 's-', color='darkorange', linewidth=2)\n",
        "ax2.set_xlabel(\"Layer (0=embedding)\")\n",
        "ax2.set_ylabel(\"Output Entropy\")\n",
        "ax2.set_title(\"Logit Lens: Output Sharpening\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Head alignment\n",
        "ax3 = fig.add_subplot(gs[1, 0])\n",
        "ax3.plot(layers, r[\"head_alignment\"], '^-', color='forestgreen', linewidth=2)\n",
        "ax3.set_xlabel(\"Layer\")\n",
        "ax3.set_ylabel(\"Mean Pairwise Cosine Sim\")\n",
        "ax3.set_title(\"Head Alignment (higher = more agreement)\")\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Similarity to final layer\n",
        "ax4 = fig.add_subplot(gs[1, 1])\n",
        "ax4.plot(range(len(r[\"sim_to_final\"])), r[\"sim_to_final\"], 'D-', color='purple', linewidth=2)\n",
        "ax4.set_xlabel(\"Layer (0=embedding)\")\n",
        "ax4.set_ylabel(\"Cosine Sim to Final\")\n",
        "ax4.set_title(\"Convergence to Final Representation\")\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Layer-to-layer similarity\n",
        "ax5 = fig.add_subplot(gs[2, 0])\n",
        "ax5.plot(range(len(r[\"layer_to_layer_sim\"])), r[\"layer_to_layer_sim\"], 'p-', color='teal', linewidth=2)\n",
        "ax5.set_xlabel(\"Transition (L_i -> L_{i+1})\")\n",
        "ax5.set_ylabel(\"Cosine Sim\")\n",
        "ax5.set_title(\"Layer-to-Layer Stability\")\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "# Top tokens by layer\n",
        "ax6 = fig.add_subplot(gs[2, 1])\n",
        "ax6.axis('off')\n",
        "top_tok_str = \"\\n\".join([f\"L{i}: '{t.strip()[:15]}'\" for i, t in enumerate(r[\"top_tokens_by_layer\"])])\n",
        "ax6.text(0.1, 0.9, f\"Top token at each layer:\\n\\n{top_tok_str}\", fontsize=9, va='top', family='monospace')\n",
        "ax6.set_title(f\"Final prediction: '{r['top_token'].strip()}'\")\n",
        "\n",
        "plt.suptitle(f\"Comprehensive Collapse Metrics: '{r['prompt'][:60]}...'\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"01_single_prompt_all_metrics.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization 2: Compare factual vs open-ended prompts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare factual vs open-ended\n",
        "factual_keys = [k for k in all_results.keys() if k.startswith(\"factual\")]\n",
        "open_keys = [k for k in all_results.keys() if k.startswith(\"open\")]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Attention entropy\n",
        "ax1 = axes[0, 0]\n",
        "for k in factual_keys:\n",
        "    ax1.plot(all_results[k][\"attn_entropy\"], 'o-', alpha=0.7, label=k)\n",
        "for k in open_keys:\n",
        "    ax1.plot(all_results[k][\"attn_entropy\"], 's--', alpha=0.7, label=k)\n",
        "ax1.set_xlabel(\"Layer\"); ax1.set_ylabel(\"Entropy\")\n",
        "ax1.set_title(\"Attention Entropy: Factual (solid) vs Open (dashed)\")\n",
        "ax1.legend(fontsize=8); ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Logit lens\n",
        "ax2 = axes[0, 1]\n",
        "for k in factual_keys:\n",
        "    ax2.plot(all_results[k][\"logit_entropy\"], 'o-', alpha=0.7, label=k)\n",
        "for k in open_keys:\n",
        "    ax2.plot(all_results[k][\"logit_entropy\"], 's--', alpha=0.7, label=k)\n",
        "ax2.set_xlabel(\"Layer\"); ax2.set_ylabel(\"Output Entropy\")\n",
        "ax2.set_title(\"Logit Lens: Output Sharpening\")\n",
        "ax2.legend(fontsize=8); ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Head alignment\n",
        "ax3 = axes[1, 0]\n",
        "for k in factual_keys:\n",
        "    ax3.plot(all_results[k][\"head_alignment\"], 'o-', alpha=0.7, label=k)\n",
        "for k in open_keys:\n",
        "    ax3.plot(all_results[k][\"head_alignment\"], 's--', alpha=0.7, label=k)\n",
        "ax3.set_xlabel(\"Layer\"); ax3.set_ylabel(\"Head Alignment\")\n",
        "ax3.set_title(\"Head Alignment\")\n",
        "ax3.legend(fontsize=8); ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Convergence to final\n",
        "ax4 = axes[1, 1]\n",
        "for k in factual_keys:\n",
        "    ax4.plot(all_results[k][\"sim_to_final\"], 'o-', alpha=0.7, label=k)\n",
        "for k in open_keys:\n",
        "    ax4.plot(all_results[k][\"sim_to_final\"], 's--', alpha=0.7, label=k)\n",
        "ax4.set_xlabel(\"Layer\"); ax4.set_ylabel(\"Sim to Final\")\n",
        "ax4.set_title(\"Convergence to Final Representation\")\n",
        "ax4.legend(fontsize=8); ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"Factual (constrained) vs Open-ended (unconstrained) Prompts\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"02_factual_vs_open.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization 3: Correlations and scatter plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots: confidence vs various metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "names = list(all_results.keys())\n",
        "final_entropies = [all_results[n][\"final_entropy\"] for n in names]\n",
        "final_alignments = [all_results[n][\"head_alignment\"][-1] for n in names]\n",
        "final_sim_to_final = [all_results[n][\"sim_to_final\"][0] for n in names]  # embedding sim to final\n",
        "attn_entropy_drop = [all_results[n][\"attn_entropy\"][0] - all_results[n][\"attn_entropy\"][-1] for n in names]\n",
        "\n",
        "# Color by type\n",
        "colors = []\n",
        "for n in names:\n",
        "    if \"factual\" in n: colors.append(\"blue\")\n",
        "    elif \"open\" in n: colors.append(\"green\")\n",
        "    elif \"technical\" in n: colors.append(\"purple\")\n",
        "    else: colors.append(\"red\")\n",
        "\n",
        "# Entropy vs Head Alignment\n",
        "ax1 = axes[0, 0]\n",
        "ax1.scatter(final_entropies, final_alignments, c=colors, s=80, edgecolors='black')\n",
        "for i, n in enumerate(names):\n",
        "    ax1.annotate(n[:8], (final_entropies[i], final_alignments[i]), fontsize=7)\n",
        "ax1.set_xlabel(\"Final Output Entropy\")\n",
        "ax1.set_ylabel(\"Final Layer Head Alignment\")\n",
        "ax1.set_title(\"Confidence vs Head Agreement\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Entropy vs Sim to Final\n",
        "ax2 = axes[0, 1]\n",
        "ax2.scatter(final_entropies, final_sim_to_final, c=colors, s=80, edgecolors='black')\n",
        "ax2.set_xlabel(\"Final Output Entropy\")\n",
        "ax2.set_ylabel(\"Embedding Sim to Final Layer\")\n",
        "ax2.set_title(\"Confidence vs Representation Shift\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Entropy vs Attention entropy drop\n",
        "ax3 = axes[1, 0]\n",
        "ax3.scatter(final_entropies, attn_entropy_drop, c=colors, s=80, edgecolors='black')\n",
        "ax3.set_xlabel(\"Final Output Entropy\")\n",
        "ax3.set_ylabel(\"Attention Entropy Drop (L0 - L11)\")\n",
        "ax3.set_title(\"Confidence vs Attention Focusing\")\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Legend\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "ax4.scatter([], [], c='blue', s=80, label='Factual')\n",
        "ax4.scatter([], [], c='green', s=80, label='Open-ended')\n",
        "ax4.scatter([], [], c='purple', s=80, label='Technical')\n",
        "ax4.scatter([], [], c='red', s=80, label='Ambiguous/Riddle')\n",
        "ax4.legend(loc='center', fontsize=12)\n",
        "ax4.set_title(\"Prompt Types\")\n",
        "\n",
        "plt.suptitle(\"Correlations: Output Entropy vs Collapse Metrics\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"03_correlations.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization 4: Logit lens token evolution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logit lens: show how the top token changes through layers\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "selected = [\"factual_capital\", \"open_meaning\", \"technical_quantum\", \"riddle\"]\n",
        "\n",
        "for idx, name in enumerate(selected):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    r = all_results[name]\n",
        "    \n",
        "    layers_ll = range(len(r[\"logit_entropy\"]))\n",
        "    ax.plot(layers_ll, r[\"logit_entropy\"], 'o-', color='darkorange', linewidth=2)\n",
        "    ax.set_xlabel(\"Layer (0=embedding)\")\n",
        "    ax.set_ylabel(\"Output Entropy\")\n",
        "    ax.set_title(f\"'{r['prompt'][:40]}...'\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Annotate with top tokens\n",
        "    for i, tok in enumerate(r[\"top_tokens_by_layer\"]):\n",
        "        if i % 3 == 0 or i == len(r[\"top_tokens_by_layer\"]) - 1:\n",
        "            ax.annotate(tok.strip()[:8], (i, r[\"logit_entropy\"][i]), fontsize=7, rotation=30)\n",
        "\n",
        "plt.suptitle(\"Logit Lens: Top Token and Entropy Through Layers\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"04_logit_lens_evolution.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization 5: Heatmap of all metrics across all prompts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap: head alignment across all prompts and layers\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Head alignment heatmap\n",
        "alignment_matrix = np.array([all_results[n][\"head_alignment\"] for n in names])\n",
        "ax1 = axes[0]\n",
        "im1 = ax1.imshow(alignment_matrix, aspect='auto', cmap='viridis')\n",
        "ax1.set_yticks(range(len(names)))\n",
        "ax1.set_yticklabels([n[:12] for n in names], fontsize=8)\n",
        "ax1.set_xlabel(\"Layer\")\n",
        "ax1.set_title(\"Head Alignment by Prompt and Layer\")\n",
        "plt.colorbar(im1, ax=ax1)\n",
        "\n",
        "# Logit entropy heatmap\n",
        "logit_matrix = np.array([all_results[n][\"logit_entropy\"] for n in names])\n",
        "ax2 = axes[1]\n",
        "im2 = ax2.imshow(logit_matrix, aspect='auto', cmap='magma')\n",
        "ax2.set_yticks(range(len(names)))\n",
        "ax2.set_yticklabels([n[:12] for n in names], fontsize=8)\n",
        "ax2.set_xlabel(\"Layer (0=embedding)\")\n",
        "ax2.set_title(\"Output Entropy by Prompt and Layer\")\n",
        "plt.colorbar(im2, ax=ax2)\n",
        "\n",
        "plt.suptitle(\"Metric Heatmaps Across All Prompts\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"05_heatmaps.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "summary = {\n",
        "    \"model\": model_name,\n",
        "    \"n_layers\": n_layers,\n",
        "    \"n_heads\": n_heads,\n",
        "    \"prompts\": {\n",
        "        name: {\n",
        "            \"prompt\": r[\"prompt\"],\n",
        "            \"tokens\": r[\"tokens\"],\n",
        "            \"top_token\": r[\"top_token\"],\n",
        "            \"final_entropy\": float(r[\"final_entropy\"]),\n",
        "            \"attn_entropy\": [float(x) for x in r[\"attn_entropy\"]],\n",
        "            \"logit_entropy\": [float(x) for x in r[\"logit_entropy\"]],\n",
        "            \"head_alignment\": [float(x) for x in r[\"head_alignment\"]],\n",
        "            \"position_change\": [float(x) for x in r[\"position_change\"]],\n",
        "            \"layer_to_layer_sim\": [float(x) for x in r[\"layer_to_layer_sim\"]],\n",
        "            \"sim_to_final\": [float(x) for x in r[\"sim_to_final\"]],\n",
        "        }\n",
        "        for name, r in all_results.items()\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(FIG_DIR / \"collapse_results.json\", \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(f\"Results saved to {FIG_DIR / 'collapse_results.json'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What these experiments measure (and why they're valid)\n",
        "\n",
        "| Metric | What it shows | Validity |\n",
        "|--------|---------------|----------|\n",
        "| **Attention entropy** | How focused attention is at each layer | Direct measure, no assumptions |\n",
        "| **Logit lens** | How the output distribution evolves through layers | Uses model's own projection |\n",
        "| **Head alignment** | Whether attention heads agree (cosine similarity) | Pure geometry, no wave assumptions |\n",
        "| **Sim to final** | How early layers relate to final representation | Measures convergence |\n",
        "| **Layer-to-layer similarity** | Stability of representation changes | Measures transformation magnitude |\n",
        "\n",
        "### Key findings\n",
        "\n",
        "1. **Attention entropy** tends to decrease through layers (attention becomes more focused)\n",
        "2. **Output entropy** drops through layers (belief sharpens) - visible in logit lens\n",
        "3. **Head alignment** shows whether heads are computing similar things\n",
        "4. **Similarity to final** shows how quickly representations converge to the output\n",
        "\n",
        "### Figures saved\n",
        "\n",
        "- `01_single_prompt_all_metrics.png`: All metrics for one prompt\n",
        "- `02_factual_vs_open.png`: Compare constrained vs open-ended prompts\n",
        "- `03_correlations.png`: Scatter plots of confidence vs metrics\n",
        "- `04_logit_lens_evolution.png`: Top token evolution through layers\n",
        "- `05_heatmaps.png`: Heatmaps across all prompts\n",
        "\n",
        "### Connection to AKIRA theory\n",
        "\n",
        "These metrics validate the \"belief collapse\" narrative without requiring wave/phase assumptions:\n",
        "- Entropy drop = belief concentration\n",
        "- Head alignment = collective agreement\n",
        "- Convergence to final = representation stabilization\n",
        "\n",
        "The collapse is real. The \"phase\" metaphor is intuition, not mechanism.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
