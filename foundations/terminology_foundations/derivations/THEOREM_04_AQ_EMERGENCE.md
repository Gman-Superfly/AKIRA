# Theorem 04 – AQ Emergence in a Stylized Sparse Factor Model

## 0. Purpose and Scope

This document gives a **precise, stylized theorem and proof sketch** for an "AQ emergence" result:

> Under explicit assumptions about the task, data-generating process, and training objective, the learned representation converges to a **minimal set of factors**, each of which is **irreducible** and **necessary** for solving the task.

We do **not** attempt to prove AQ emergence for arbitrary deep networks and arbitrary tasks. Instead, we:

- Specify a **simple factorized task model** with a well-defined task complexity \(K(T)\).
- Define a **sparse representation learning objective** that penalizes unnecessary factors.
- Prove that any optimal solution uses **exactly \(K(T)\) active factors**, each of which is **irreducible** (removing it increases loss).

These active factors correspond, in this stylized setting, to **Action Quanta** for the task.

This gives a mathematically clean prototype for the claim in `ACTION_QUANTA.md` that:

> "Training naturally finds minimal actionable units (AQ) that match task complexity."

---

## 1. Task and Data Model

### 1.1 Latent Factors and Task Complexity

We assume the task \(T\) depends on a **finite set of latent binary factors** \(s = (s_1, \dots, s_K) \in \{0,1\}^K\).

- \(K\) is the **task complexity** \(K(T)\): the minimal number of independent conditions/attributes needed to determine the output.

Formally, outputs \(y\) are generated as:
\[
 y = g(s),
\]
for some deterministic function \(g: \{0,1\}^K \to \mathcal{Y}\).

### 1.2 Observations

We do not see \(s\) directly. Instead, we observe inputs \(x\) generated by a (possibly noisy) function of \(s\):
\[
 x = h(s, \xi),
\]
where \(\xi\) is noise independent of \(s\).

- Intuition: \(s\) are "true causes" (e.g., object present, motion direction, etc.).
- \(x\) are high-dimensional measurements (pixels, tokens, sensor readings).

We assume the joint distribution \(P(s, x, y)\) is consistent with this generative process, and that **each factor \(s_k\) actually matters** for the task:

**Assumption A1 (Task-Usefulness of Each Factor)**:  
For each \(k \in \{1,\dots,K\}\), there exist \(s, s'\) that differ only in coordinate \(k\) such that \(g(s) \ne g(s')\).

So no factor is redundant for the task.

---

## 2. Representation and Training Objective

### 2.1 Encoder–Decoder Architecture

We consider a simple encoder–decoder model:

- Encoder: \(E_\theta: \mathcal{X} \to \mathbb{R}^m\), with output \(z = E_\theta(x) = (z_1, \dots, z_m)\).
- Decoder: \(f_W: \mathbb{R}^m \to \mathcal{Y}\), for simplicity taken to be **linear** plus a fixed link (e.g., softmax):
  \[
  f_W(z) = \ell(W z),
  \]
  where \(W \in \mathbb{R}^{d_y \times m}\), \(\ell\) is a fixed strictly monotone link (e.g., logistic / softmax).

We will treat each coordinate \(z_j\) as a **candidate factor**. In AQ language, these coordinates are candidate **Action Quanta dimensions**.

We assume the encoder \(E_\theta\) is sufficiently expressive to represent any function of \(x\) we need.

### 2.2 Loss and Regularization

Training minimizes the **regularized risk**:
\[
 \mathcal{J}(\theta, W) = \mathbb{E}_{(x,y)}[\mathcal{L}(f_W(E_\theta(x)), y)] + \lambda \sum_{j=1}^m R(z_j),
\]
where:

- \(\mathcal{L}\) is a standard convex loss in \(f_W(z)\) (e.g., cross-entropy, squared loss).
- \(R(z_j)\) is a sparsity/usage penalty on coordinate \(j\). We choose a strong form:
  \[
  R(z_j) := \mathbb{P}(|z_j(x)| > 0) = \Pr_x[z_j(x) \ne 0],
  \]
  i.e., the **probability of being used**. This is an \(\ell_0\)-type penalty.
- \(\lambda > 0\) controls the cost of using a coordinate.

This objective says:

- We want **low prediction error**.
- We pay a fixed cost \(\lambda\) each time a coordinate is active over the data distribution.

This is an explicit formalization of "use as few factors as possible while solving the task".

### 2.3 AQ-like Coordinates

We say coordinate \(z_j\) is **task-relevant** if ablating it increases risk:
\[
 \Delta \mathcal{R}_j := \mathcal{R}_{\text{ablated}, j} - \mathcal{R}_{\text{full}} > 0,
\]
where \(\mathcal{R}\) denotes the unregularized expected loss and "ablated" means setting \(z_j \equiv 0\) for all inputs and allowing optimal retraining of \(W\) but not \(E_\theta\) on the remaining coordinates.

A coordinate \(z_j\) is **irreducible** if:\
- It is task-relevant; and
- No strictly simpler representation (using a proper subset of the active coordinates) can achieve the same risk.

These irreducible coordinates, under the assumptions below, will correspond to **Action Quanta** for the task.

---

## 3. Assumptions for the Emergence Theorem

We now list the key assumptions. They are strong but explicit.

**Assumption A2 (Realizability)**:  
There exists an encoder–decoder pair \((E^*, W^*)\) such that for all \((x,y)\) from the data distribution,
\[
 \mathcal{L}(f_{W^*}(E^*(x)), y) = 0.
\]
That is, the architecture can represent a **perfect predictor**.

**Assumption A3 (Factorization through Latent s)**:  
There exists a representation of the form:
\[
 z = E^*(x) = A s,
\]
where \(A \in \mathbb{R}^{m \times K}\) has full column rank \(K\) and \(s\) are the true latent factors from Section 1.

Intuitively: the encoder can recover \(K\) independent factors (up to an invertible linear transform), and the decoder only needs those to compute \(y\).

**Assumption A4 (Minimality of Latent Factors)**:  
There is no representation with fewer than \(K\) independent coordinates that achieves zero risk. Formally, for any representation \(z' = B s\) with rank \(B < K\), there is no decoder \(W'\) such that \(\mathcal{L}(f_{W'}(z'), y) = 0\) almost surely.

This encodes the idea that **all K latent factors are necessary**; the task complexity \(K(T) = K\) is minimal.

**Assumption A5 (Strong Usage Penalty)**:  
The regularization weight \(\lambda\) is chosen such that:

1. Any additional always-active coordinate adds cost at least \(\lambda\).
2. The gain in risk from adding a truly redundant coordinate (one that does not reduce risk) is less than \(\lambda\).

This means the optimizer prefers **fewer active coordinates** whenever possible without increasing prediction error.

**Assumption A6 (Global Optimum)**:  
Optimization finds a **global minimizer** \((E^{\mathrm{opt}}, W^{\mathrm{opt}})\) of \(\mathcal{J}\).

---

## 4. Theorem Statement

> **Theorem 04 (Emergence of Minimal Irreducible Factors)**  
> Under Assumptions A1–A6, any global minimizer \((E^{\mathrm{opt}}, W^{\mathrm{opt}})\) of the regularized risk \(\mathcal{J}\) has the following properties:
>
> 1. (**Existence and Count**) There exist exactly \(K\) active coordinates \(z_{j_1}, \dots, z_{j_K}\) such that all other coordinates are identically zero almost surely. That is, the representation has **exactly \(K = K(T)\) active factors**.
> 2. (**Task-Sufficiency**) The predictor \(f_{W^{\mathrm{opt}}}(E^{\mathrm{opt}}(x))\) depends only on these \(K\) coordinates and achieves zero risk: \(\mathcal{L} = 0\) almost surely.
> 3. (**Irreducibility**) For each active coordinate \(z_{j_k}\), ablating it (setting it to zero and optimally readjusting the decoder) strictly increases unregularized risk: \(\Delta \mathcal{R}_{j_k} > 0\). No strict subset of the \(K\) active coordinates suffices to achieve zero risk.
> 4. (**Minimality**) Any alternative representation achieving zero risk must have at least \(K\) active coordinates (under the same usage penalty). Thus the learned representation is **minimal** in the sense of the chosen regularization.
>
> In this stylized setting, the \(K\) active, irreducible coordinates play the role of **Action Quanta**: they are minimal actionable factors that are necessary and sufficient for the task.

---

## 5. Proof Sketch

We prove each part at a high level, emphasizing the logical structure.

### 5.1 Existence of a K-Factor, Zero-Risk Solution

By A2 and A3, there exists an encoder–decoder pair \((E^*, W^*)\) such that:

- \(z^*(x) = E^*(x) = A s\) with \(\mathrm{rank}(A) = K\),
- \(f_{W^*}(z^*(x)) = y\) with zero loss.

Thus the **infimum** of \(\mathcal{J}\) is at most:
\[
 \mathcal{J}(E^*, W^*) = 0 + \lambda \sum_j R(z^*_j).
\]

Because \(z^*(x)\) lives in a \(K\)-dimensional subspace spanned by columns of \(A\), we can choose a basis for this subspace such that exactly \(K\) coordinates are used. Concretely, consider a change of basis \(U \in \mathbb{R}^{m \times m}\) such that:
\[
 U A = \begin{bmatrix} I_K \\ 0 \end{bmatrix},
\]
where \(I_K\) is the \(K \times K\) identity.

Redefine the encoder as \(\tilde{E}(x) = U E^*(x)\) and adjust the decoder accordingly. Then:

- The first \(K\) coordinates of \(\tilde{E}(x)\) are exactly \(s\) (up to permutation),
- The remaining \(m-K\) coordinates are identically zero.

Thus there exists a zero-risk representation with exactly \(K\) always-active coordinates and \(m-K\) always-zero coordinates. Its regularization cost is \(K \lambda\).

### 5.2 At Least K Active Coordinates Are Needed

Suppose there exists another representation with fewer than \(K\) active coordinates that achieves zero risk. That would mean there is a representation of the form:
\[
 z'(x) = B s
\]
with \(\mathrm{rank}(B) < K\), and a decoder \(W'\) such that \(f_{W'}(z'(x)) = y\) almost surely.

But by A4 (minimality of latent factors), this is impossible: **no representation with fewer than K independent coordinates can achieve zero risk**.

Hence any zero-risk representation must have **at least K active coordinates**.

### 5.3 At Most K Active Coordinates at Optimum (Minimality)

Let \((E^{\mathrm{opt}}, W^{\mathrm{opt}})\) be a global minimizer of \(\mathcal{J}\). Let \(K_{\text{act}}\) be the number of active coordinates in \(z^{\mathrm{opt}}(x) = E^{\mathrm{opt}}(x)\), i.e., the number of \(j\) with \(R(z^{\mathrm{opt}}_j) > 0\).

We show that \(K_{\text{act}} = K\).

1. By definition of \(\mathcal{J}\):
   \[
   \mathcal{J}(E^{\mathrm{opt}}, W^{\mathrm{opt}}) \le \mathcal{J}(E^*, W^*).
   \]

2. The zero-risk, K-active representation \((\tilde{E}, \tilde{W})\) constructed in 5.1 has regularized cost \(K \lambda\):
   \[
   \mathcal{J}(\tilde{E}, \tilde{W}) = 0 + K \lambda.
   \]

3. Therefore:
   \[
   \mathcal{J}(E^{\mathrm{opt}}, W^{\mathrm{opt}}) \le K \lambda.
   \]

4. On the other hand, since zero risk is achievable and \(\lambda > 0\), any solution with risk strictly greater than zero can be improved (risk reduced) while keeping the same number of active coordinates, so at optimum we must also have **zero risk** (or as small as possible, but we take the idealized case as exactly zero for clarity).

5. Let \(K_{\text{act}}\) be the number of active coordinates in \(z^{\mathrm{opt}}\). The regularization term is then at least \(K_{\text{act}} \lambda\), since each always-active coordinate contributes \(\lambda\) to the expected penalty.

6. Therefore,
   \[
   \mathcal{J}(E^{\mathrm{opt}}, W^{\mathrm{opt}}) \ge 0 + K_{\text{act}} \lambda.
   \]

Combining upper and lower bounds:
\[
 K_{\text{act}} \lambda \le \mathcal{J}(E^{\mathrm{opt}}, W^{\mathrm{opt}}) \le K \lambda.
\]

Since \(\lambda > 0\), we conclude:
\[
 K_{\text{act}} \le K.
\]

But from 5.2, we already know any zero-risk solution must have **at least K active coordinates**. Thus:
\[
 K_{\text{act}} = K.
\]

This proves that any global minimizer uses exactly K active coordinates.

### 5.4 Irreducibility of Active Coordinates

We must show that each active coordinate is **irreducible**: ablating it increases unregularized risk.

Suppose, for contradiction, that there exists an active coordinate \(z_{j_*}\) such that ablating it (setting it to zero, re-optimizing \(W\) on the remaining coordinates) does **not** increase risk:
\[
 \mathcal{R}_{\text{ablated}, j_*} = \mathcal{R}_{\text{full}}.
\]

Then we could construct a new encoder \(E'\) where \(z'_{j_*} \equiv 0\) and all other coordinates are as in \(E^{\mathrm{opt}}\), with decoder \(W'\) achieving the same risk.

- The risk term in \(\mathcal{J}\) would be unchanged.
- The regularization term would **decrease by at least \(\lambda\)**, since one active coordinate is removed (A5).

Thus:
\[
 \mathcal{J}(E', W') < \mathcal{J}(E^{\mathrm{opt}}, W^{\mathrm{opt}}),
\]
contradicting global optimality.

Therefore, each of the \(K\) active coordinates must be **necessary** for achieving minimal risk: ablating any one of them strictly worsens the (unregularized) risk. This is precisely the **irreducibility** property.

---

## 6. Interpretation as AQ Emergence

Under A1–A6, we have shown:

- **Exactly K active coordinates** emerge at optimum.
- Each is **necessary** (irreducible) for perfect prediction.
- No **simpler representation** with fewer than K coordinates can achieve zero risk.

This matches the conceptual definition of **Action Quanta** in `ACTION_QUANTA.md`:

- They are **minimal patterns** (here: coordinates) that:
  - are **necessary** for correct action (prediction);
  - are collectively **sufficient** for the task;
  - cannot be simplified further without losing performance.

In this stylized model, the learned coordinates \(z_{j_1}, \dots, z_{j_K}\) are **AQ-like units** for task \(T\).

---

## 7. Limitations and Connections to Experiments

### 7.1 Limitations

This theorem is intentionally narrow:

- It assumes the task truly depends on a finite set of binary latent factors \(s\).
- It assumes realizability and a **linear decoder** with a very strong \(\ell_0\)-style penalty.
- It assumes **global optimization** of a non-convex objective (in practice hard).

Real LLMs and AKIRA-like systems are much more complex:

- Factors may be continuous, hierarchical, and partially redundant.
- Encoders are deep and non-linear; decoders are not strictly linear.
- Optimization is approximate (SGD) and may find local minima.

Thus, Theorem 04 should be read as:

> A **proof-of-concept** that, under reasonable but strong assumptions, a regularized learning objective naturally produces a minimal set of irreducible factors whose count matches task complexity.

### 7.2 Relation to 035 Experiments

The 035 AQ excitation and bonding experiments (`035_EXP_AQ_EXCITATION_FIELDS`) provide **empirical analogs** to this stylized result:

- 035A / 035D / 035F show that certain **interpretable components** recur as stable, compositional units across prompts and models.
- 035G (Belief Crystallization) shows that, as evidence accumulates, the system converges to a **small number of dominant patterns** (low-entropy regime), consistent with a limited set of AQ.

While those experiments do not satisfy the clean assumptions A1–A6, they are consistent with the **qualitative picture**:

- Training + architecture pressure (attention, bottlenecks, sparsity) → emergence of a **small, stable set of factors** that carry the task-relevant information.

### 7.3 Path to Stronger Results

To move from this stylized theorem toward more realistic AQ emergence results, one could:

1. **Relax linearity**: extend the proof to non-linear decoders under suitable convexity assumptions.
2. **Replace \(\ell_0\) by \(\ell_1\)**: use known results about sparsity-inducing \(\ell_1\) norms to approximate the \(\ell_0\) argument.
3. **Introduce noise and robustness**: prove that the active coordinates remain stable under small perturbations of the data distribution.
4. **Connect to AQ definitions**: add constraints matching the four AQ properties (magnitude, phase, frequency, coherence) and show the same minimality result holds in that richer space.

---

## 8. Summary

> **Theorem 04 (Stylized AQ Emergence)**  
> In a factorized task model where outputs depend on \(K\) essential latent factors, and under a strong sparsity penalty on representation coordinates, any global minimizer of the regularized risk uses **exactly \(K\) active coordinates**, each of which is **irreducible** for achieving zero risk. These active coordinates form a minimal, task-sufficient representation and thus serve as a stylized instance of **Action Quanta**.

This provides a concrete mathematical example of AQ emergence and a template for more realistic, less constrained derivations.

---

**Oscar Goldman — Shogu Research Group @ Datamutant.ai**

*This theorem shows, in a simplified setting, that "minimal actionable factors" are not just a metaphor: they are the natural outcome of optimizing a sparse representation for a factorized task. The general AQ claims in the main documents should be read as extensions and conjectures built on top of this kind of structure.*
